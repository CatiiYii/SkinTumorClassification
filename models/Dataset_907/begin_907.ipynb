{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-06-01T20:51:22.615766Z",
          "iopub.status.busy": "2025-06-01T20:51:22.615576Z",
          "iopub.status.idle": "2025-06-01T20:52:25.840744Z",
          "shell.execute_reply": "2025-06-01T20:52:25.839758Z",
          "shell.execute_reply.started": "2025-06-01T20:51:22.615749Z"
        },
        "id": "hMZiJtBxxQAl",
        "outputId": "bb9cfff2-4637-486a-979d-0364376d2296",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-01 20:51:25.549097: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748811085.731848      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748811085.785467      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n",
            "Collecting git+https://github.com/lucasb-eyer/pydensecrf.git\n",
            "  Cloning https://github.com/lucasb-eyer/pydensecrf.git to /tmp/pip-req-build-zh48zg15\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lucasb-eyer/pydensecrf.git /tmp/pip-req-build-zh48zg15\n",
            "  Resolved https://github.com/lucasb-eyer/pydensecrf.git to commit 2723c7fa4f2ead16ae1ce3d8afe977724bb8f87f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pydensecrf\n",
            "  Building wheel for pydensecrf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydensecrf: filename=pydensecrf-1.0-cp311-cp311-linux_x86_64.whl size=3440329 sha256=e352892916e4a464fcd74bea117b4d9f056b5df1a84fbd6ccd1033a69cf5567e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u8womb2j/wheels/ce/8e/34/6dcfa200a9e2ae3627d8009b8bd1ca9b24512bec50a93304de\n",
            "Successfully built pydensecrf\n",
            "Installing collected packages: pydensecrf\n",
            "Successfully installed pydensecrf-1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import shutil\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, ReLU, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Layer, Input, Conv2D, BatchNormalization, Lambda, Concatenate\n",
        "print(tf.__version__)\n",
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:52:25.843385Z",
          "iopub.status.busy": "2025-06-01T20:52:25.842443Z",
          "iopub.status.idle": "2025-06-01T20:52:25.853752Z",
          "shell.execute_reply": "2025-06-01T20:52:25.852850Z",
          "shell.execute_reply.started": "2025-06-01T20:52:25.843357Z"
        },
        "id": "x0MtYSRMxQAr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_isic_dataset(image_path, mask_path, binary_path, csv_file, img_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Đọc và xử lý dữ liệu từ ISIC 2017 dataset\n",
        "\n",
        "    Args:\n",
        "        image_path: Đường dẫn đến thư mục chứa ảnh gốc\n",
        "        mask_path: Đường dẫn đến thư mục chứa mask\n",
        "        binary_path: Đường dẫn đến thư mục chứa mask nhị phân\n",
        "        csv_file: Đường dẫn đầy đủ đến file CSV chứa nhãn\n",
        "        label_name: Tên cột chứa nhãn trong file CSV\n",
        "        img_size: Kích thước ảnh đầu ra (width, height)\n",
        "\n",
        "    Returns:\n",
        "        images: Numpy array chứa các ảnh đã xử lý\n",
        "        masks: Numpy array chứa các mask đã xử lý\n",
        "        binary_masks: Dict chứa mask nhị phân của từng ảnh đã xử lý\n",
        "        image_ids: List các ID của ảnh\n",
        "        labels: List các nhãn tương ứng với ảnh\n",
        "    \"\"\"\n",
        "\n",
        "    # Lấy danh sách các file ảnh\n",
        "    image_files = sorted(glob(os.path.join(image_path, \"ISIC_*.jpg\")))\n",
        "\n",
        "    # Khởi tạo lists để lưu dữ liệu\n",
        "    images = []\n",
        "    masks = []\n",
        "    binary_masks = {}\n",
        "    image_ids = []\n",
        "    labels = []\n",
        "\n",
        "    # Đọc file CSV\n",
        "    csv_data = pd.read_csv(csv_file)\n",
        "    mel_label = csv_data['melanoma'].astype(\"int64\")\n",
        "\n",
        "    print(\"Đang đọc và xử lý dữ liệu...\")\n",
        "    for index, img_path in enumerate(tqdm(image_files)):\n",
        "        # Lấy image ID\n",
        "        img_id = os.path.basename(img_path).split('.')[0]\n",
        "        mask_file = os.path.join(mask_path, f\"{img_id}_segmentation.png\")\n",
        "        binary_file = os.path.join(binary_path, f\"{img_id}_features.json\")\n",
        "\n",
        "        # Kiểm tra file mask có tồn tại\n",
        "        if not os.path.exists(mask_file):\n",
        "            print(f\"Không tìm thấy mask cho ảnh mặt nạ {img_id}_segmentation.png\")\n",
        "            continue\n",
        "        if not os.path.exists(binary_file):\n",
        "            print(f\"Không tìm thấy mask nhị phân cho ảnh {img_id}_features.json\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "\n",
        "\n",
        "            # Đọc ảnh gốc\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Chuyển từ BGR sang RGB\n",
        "\n",
        "\n",
        "            # Đọc mask\n",
        "            mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Resize ảnh và mask\n",
        "            img = cv2.resize(img, img_size)\n",
        "            mask = cv2.resize(mask, img_size)\n",
        "\n",
        "            # Normalize\n",
        "            img = img / 255.0\n",
        "            mask = mask / 255.0\n",
        "\n",
        "            # Đọc mask nhị phân\n",
        "            with open(binary_file, 'r') as f:\n",
        "                binary_masks[img_id] = json.load(f)\n",
        "\n",
        "            # Lấy nhãn tương ứng\n",
        "            label = mel_label[index]\n",
        "\n",
        "            # Thêm vào lists\n",
        "            images.append(img)\n",
        "            masks.append(mask)\n",
        "            image_ids.append(img_id)\n",
        "            labels.append(label.astype(\"long\"))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Lỗi khi xử lý ảnh {img_id}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Chuyển sang numpy arrays\n",
        "    images = np.array(images)\n",
        "    masks = np.array(masks)[..., np.newaxis]  # Thêm channel dimension cho masks\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    print(f\"\\nĐã đọc thành công {len(images)} ảnh\")\n",
        "    print(f\"Shape của images: {images.shape}\")\n",
        "    print(f\"Shape của masks: {masks.shape}\")\n",
        "    print(f\"Shape của labels: {labels.shape}\")\n",
        "\n",
        "    return images, masks, binary_masks, image_ids, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:52:25.855113Z",
          "iopub.status.busy": "2025-06-01T20:52:25.854731Z",
          "iopub.status.idle": "2025-06-01T20:54:31.737528Z",
          "shell.execute_reply": "2025-06-01T20:54:31.736860Z",
          "shell.execute_reply.started": "2025-06-01T20:52:25.855089Z"
        },
        "id": "mSmWSLvExQAx",
        "outputId": "7901cb1e-3ecd-43e9-f457-2cd36d8c3320",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang đọc và xử lý dữ liệu...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 635/635 [02:05<00:00,  5.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Đã đọc thành công 635 ảnh\n",
            "Shape của images: (635, 256, 256, 3)\n",
            "Shape của masks: (635, 256, 256, 1)\n",
            "Shape của labels: (635,)\n"
          ]
        }
      ],
      "source": [
        "# Đọc tập training\n",
        "train_images, train_masks, train_binarys, train_image_ids, train_labels = load_isic_dataset(\n",
        "    image_path='/kaggle/input/isic-2017-melanoma/Train_Data',\n",
        "    mask_path='/kaggle/input/isic-2017-melanoma/Train_GroundTruth_1',\n",
        "    binary_path='/kaggle/input/isic-2017-melanoma/Train_GroundTruth_2',\n",
        "    csv_file='/kaggle/input/isic-2017-melanoma/Train_GroundTruth_3.csv',\n",
        "    img_size=(256, 256)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:54:31.738729Z",
          "iopub.status.busy": "2025-06-01T20:54:31.738419Z",
          "iopub.status.idle": "2025-06-01T20:55:20.535786Z",
          "shell.execute_reply": "2025-06-01T20:55:20.535095Z",
          "shell.execute_reply.started": "2025-06-01T20:54:31.738709Z"
        },
        "id": "GGZzlaZ-xQA0",
        "outputId": "488e471d-0a4e-4293-9b3f-a628085ee88b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang đọc và xử lý dữ liệu...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 272/272 [00:48<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Đã đọc thành công 272 ảnh\n",
            "Shape của images: (272, 256, 256, 3)\n",
            "Shape của masks: (272, 256, 256, 1)\n",
            "Shape của labels: (272,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_images, test_masks, test_binarys, test_image_ids, test_labels = load_isic_dataset(\n",
        "    image_path='/kaggle/input/isic-2017-melanoma/Test_Data',\n",
        "    mask_path='/kaggle/input/isic-2017-melanoma/Test_GroundTruth_1',\n",
        "    binary_path='/kaggle/input/isic-2017-melanoma/Test_GroundTruth_2',\n",
        "    csv_file='/kaggle/input/isic-2017-melanoma/Test_GroundTruth_3.csv',\n",
        "     # label_name=\"melanoma\",\n",
        "    img_size=(256, 256)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:55:20.537650Z",
          "iopub.status.busy": "2025-06-01T20:55:20.537430Z",
          "iopub.status.idle": "2025-06-01T20:55:20.542182Z",
          "shell.execute_reply": "2025-06-01T20:55:20.541656Z",
          "shell.execute_reply.started": "2025-06-01T20:55:20.537633Z"
        },
        "id": "FSrCOwI1xQA1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def iou_metric(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
        "    iou = (intersection + 1e-7) / (union + 1e-7)\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:55:20.543149Z",
          "iopub.status.busy": "2025-06-01T20:55:20.542888Z",
          "iopub.status.idle": "2025-06-01T20:55:20.562207Z",
          "shell.execute_reply": "2025-06-01T20:55:20.561528Z",
          "shell.execute_reply.started": "2025-06-01T20:55:20.543123Z"
        },
        "id": "hMvMlmm9xQA3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def compute_metric(y_true, y_pred, metric='dice_coefficient', smooth=1e-6, is_numpy=False):\n",
        "    \"\"\"Tính Dice hoặc Jaccard coefficient/loss cho TensorFlow hoặc NumPy.\"\"\"\n",
        "    y_true_f = y_true.flatten() if is_numpy else K.flatten(y_true)\n",
        "    y_pred_f = y_pred.flatten() if is_numpy else K.flatten(y_pred)\n",
        "    intersection = np.sum(y_true_f * y_pred_f) if is_numpy else K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "    if 'dice' in metric:\n",
        "        sum_fn = np.sum if is_numpy else K.sum\n",
        "        score = (2. * intersection + smooth) / (sum_fn(y_true_f) + sum_fn(y_pred_f) + smooth)\n",
        "    elif 'jaccard' in metric:\n",
        "        sum_fn = np.sum if is_numpy else K.sum\n",
        "        union = sum_fn(y_true_f) + sum_fn(y_pred_f) - intersection\n",
        "        score = (intersection + smooth) / (union + smooth)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported metric: {metric}\")\n",
        "\n",
        "    return score if 'coefficient' in metric else 1 - score\n",
        "\n",
        "# Hàm TensorFlow\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    return compute_metric(y_true, y_pred, 'dice_coefficient', smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    return compute_metric(y_true, y_pred, 'dice_loss', smooth)\n",
        "\n",
        "def jaccard_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    return compute_metric(y_true, y_pred, 'jaccard_coefficient', smooth)\n",
        "\n",
        "def jaccard_loss(y_true, y_pred, smooth=1e-6):\n",
        "    return compute_metric(y_true, y_pred, 'jaccard_loss', smooth)\n",
        "\n",
        "# Hàm NumPy\n",
        "def np_accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true.flatten() == y_pred.flatten())\n",
        "\n",
        "def np_dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    return compute_metric(y_true, y_pred, 'dice_coefficient', smooth, is_numpy=True)\n",
        "\n",
        "def np_jaccard_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    return compute_metric(y_true, y_pred, 'jaccard_coefficient', smooth, is_numpy=True)\n",
        "\n",
        "def np_dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    return compute_metric(y_true, y_pred, 'dice_loss', smooth, is_numpy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:55:20.563229Z",
          "iopub.status.busy": "2025-06-01T20:55:20.562983Z",
          "iopub.status.idle": "2025-06-01T20:55:23.264967Z",
          "shell.execute_reply": "2025-06-01T20:55:23.264248Z",
          "shell.execute_reply.started": "2025-06-01T20:55:20.563203Z"
        },
        "id": "XpaOp9aWxQA6",
        "outputId": "8db35ede-8589-4437-8bcf-66f3d72f063f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1748811321.619211      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,078,400</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_19    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_20    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ re_lu_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_21    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_22    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_23    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ re_lu_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_24    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_25    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ re_lu_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_26    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_27    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ re_lu_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │      \u001b[38;5;34m9,438,208\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │      \u001b[38;5;34m9,438,208\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1536\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ up_sampling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m7,078,400\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ up_sampling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_19    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_20    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_20 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,179,904\u001b[0m │ re_lu_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_21    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_21 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ re_lu_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ up_sampling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_22    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_22 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ re_lu_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_23    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_23 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m295,040\u001b[0m │ re_lu_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_24    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_24 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ re_lu_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ up_sampling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_25    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_25 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ re_lu_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_26    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_26 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ up_sampling2d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ re_lu_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ up_sampling2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_27    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_27 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m65\u001b[0m │ re_lu_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,918,145</span> (232.38 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,918,145\u001b[0m (232.38 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,896,129</span> (232.30 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,896,129\u001b[0m (232.30 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,016</span> (86.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m22,016\u001b[0m (86.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def CustomSegUNet(input_size=(256, 256, 1)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = Conv2D(64, (3, 3), padding='same')(inputs)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    c1 = tf.keras.layers.ReLU()(c1)\n",
        "    c1 = Conv2D(64, (3, 3), padding='same')(c1)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    c1 = tf.keras.layers.ReLU()(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), padding='same')(p1)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    c2 = tf.keras.layers.ReLU()(c2)\n",
        "    c2 = Conv2D(128, (3, 3), padding='same')(c2)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    c2 = tf.keras.layers.ReLU()(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), padding='same')(p2)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    c3 = tf.keras.layers.ReLU()(c3)\n",
        "    c3 = Conv2D(256, (3, 3), padding='same')(c3)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    c3 = tf.keras.layers.ReLU()(c3)\n",
        "    c3 = Conv2D(256, (3, 3), padding='same')(c3)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    c3 = tf.keras.layers.ReLU()(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(512, (3, 3), padding='same')(p3)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    c4 = tf.keras.layers.ReLU()(c4)\n",
        "    c4 = Conv2D(512, (3, 3), padding='same')(c4)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    c4 = tf.keras.layers.ReLU()(c4)\n",
        "    c4 = Conv2D(512, (3, 3), padding='same')(c4)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    c4 = tf.keras.layers.ReLU()(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(512, (3, 3), padding='same')(p4)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    c5 = tf.keras.layers.ReLU()(c5)\n",
        "    c5 = Conv2D(512, (3, 3), padding='same')(c5)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    c5 = tf.keras.layers.ReLU()(c5)\n",
        "    c5 = Conv2D(512, (3, 3), padding='same')(c5)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    c5 = tf.keras.layers.ReLU()(c5)\n",
        "    p5 = MaxPooling2D((2, 2))(c5)\n",
        "\n",
        "    # bottleneck\n",
        "    c6 = Conv2D(1024, (3, 3), padding='same')(p5)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = tf.keras.layers.ReLU()(c6)\n",
        "    c6 = Conv2D(1024, (3, 3), padding='same')(c6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = tf.keras.layers.ReLU()(c6)\n",
        "    c6 = Conv2D(1024, (3, 3), padding='same')(c6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = tf.keras.layers.ReLU()(c6)\n",
        "\n",
        "    # Decoder\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    u7 = Concatenate()([u7, c5])\n",
        "    c7 = Conv2D(512, (3, 3), padding='same')(u7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = tf.keras.layers.ReLU()(c7)\n",
        "    c7 = Conv2D(512, (3, 3), padding='same')(c7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = tf.keras.layers.ReLU()(c7)\n",
        "    c7 = Conv2D(512, (3, 3), padding='same')(c7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = tf.keras.layers.ReLU()(c7)\n",
        "\n",
        "    u8 = UpSampling2D((2, 2))(c7)\n",
        "    u8 = Concatenate()([u8, c4])\n",
        "    c8 = Conv2D(512, (3, 3), padding='same')(u8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = tf.keras.layers.ReLU()(c8)\n",
        "    c8 = Conv2D(512, (3, 3), padding='same')(c8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = tf.keras.layers.ReLU()(c8)\n",
        "    c8 = Conv2D(256, (3, 3), padding='same')(c8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = tf.keras.layers.ReLU()(c8)\n",
        "\n",
        "    u9 = UpSampling2D((2, 2))(c8)\n",
        "    u9 = Concatenate()([u9, c3])\n",
        "    c9 = Conv2D(256, (3, 3), padding='same')(u9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = tf.keras.layers.ReLU()(c9)\n",
        "    c9 = Conv2D(256, (3, 3), padding='same')(c9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = tf.keras.layers.ReLU()(c9)\n",
        "    c9 = Conv2D(128, (3, 3), padding='same')(c9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = tf.keras.layers.ReLU()(c9)\n",
        "\n",
        "    u10 = UpSampling2D((2, 2))(c9)\n",
        "    u10 = Concatenate()([u10, c2])\n",
        "    c10 = Conv2D(128, (3, 3), padding='same')(u10)\n",
        "    c10 = BatchNormalization()(c10)\n",
        "    c10 = tf.keras.layers.ReLU()(c10)\n",
        "    c10 = Conv2D(64, (3, 3), padding='same')(c10)\n",
        "    c10 = BatchNormalization()(c10)\n",
        "    c10 = tf.keras.layers.ReLU()(c10)\n",
        "\n",
        "    u11 = UpSampling2D((2, 2))(c10)\n",
        "    u11 = Concatenate()([u11, c1])\n",
        "    c11 = Conv2D(64, (3, 3), padding='same')(u11)\n",
        "    c11 = BatchNormalization()(c11)\n",
        "    c11 = tf.keras.layers.ReLU()(c11)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c11)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Khởi tạo và kiểm tra mô hình\n",
        "if __name__ == \"__main__\":\n",
        "    model = CustomSegUNet()\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:55:23.266564Z",
          "iopub.status.busy": "2025-06-01T20:55:23.266230Z",
          "iopub.status.idle": "2025-06-01T20:55:23.273089Z",
          "shell.execute_reply": "2025-06-01T20:55:23.272399Z",
          "shell.execute_reply.started": "2025-06-01T20:55:23.266537Z"
        },
        "id": "8TOxAUhZxQA_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class EarlyStoppingByAccuracyChange(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, monitor='accuracy', threshold=0.00001, patience=3, verbose=0):\n",
        "        super(EarlyStoppingByAccuracyChange, self).__init__()\n",
        "        self.monitor = monitor\n",
        "        self.threshold = threshold\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best_accuracy = -float('inf')  # Khởi tạo giá trị accuracy tốt nhất là âm vô cực\n",
        "        self.consecutive_stops = 0  # Đếm số lần dừng liên tiếp\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        current_accuracy = logs.get(self.monitor)\n",
        "        if current_accuracy is None:\n",
        "            tf.get_logger().warning(\n",
        "                'Early stopping requires %s available!', self.monitor\n",
        "            )\n",
        "            return\n",
        "\n",
        "        if current_accuracy > self.best_accuracy:\n",
        "            self.best_accuracy = current_accuracy\n",
        "            self.wait = 0\n",
        "            self.consecutive_stops = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            accuracy_change = current_accuracy - self.best_accuracy\n",
        "            if abs(accuracy_change) < self.threshold:\n",
        "                self.consecutive_stops += 1\n",
        "                if self.consecutive_stops >= self.patience:\n",
        "                    if self.verbose > 0:\n",
        "                        print(f\"Epoch {epoch+1}: Early stopping triggered due to minimal accuracy change for {self.patience} epochs.\")\n",
        "                    self.model.stop_training = True\n",
        "            else:\n",
        "                self.consecutive_stops = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:55:23.274373Z",
          "iopub.status.busy": "2025-06-01T20:55:23.273859Z",
          "iopub.status.idle": "2025-06-01T20:55:24.063958Z",
          "shell.execute_reply": "2025-06-01T20:55:24.063333Z",
          "shell.execute_reply.started": "2025-06-01T20:55:23.274348Z"
        },
        "id": "_j_aLe8SxQBB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def convert_to_gray_clahe(images):\n",
        "    grays = []\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))  # tạo đối tượng CLAHE\n",
        "\n",
        "    for img in images:\n",
        "        if img.dtype != np.uint8:\n",
        "            img = (img * 255).astype(np.uint8)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)  # chuyển sang ảnh xám\n",
        "\n",
        "        img_clahe = clahe.apply(gray)  # áp dụng CLAHE\n",
        "        grays.append(img_clahe)\n",
        "\n",
        "\n",
        "    return np.array(grays)\n",
        "\n",
        "# Gọi hàm\n",
        "train_images_gray_clahe = convert_to_gray_clahe(train_images)\n",
        "test_images_gray_clahe = convert_to_gray_clahe(test_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:55:24.065080Z",
          "iopub.status.busy": "2025-06-01T20:55:24.064720Z",
          "iopub.status.idle": "2025-06-01T20:55:24.070003Z",
          "shell.execute_reply": "2025-06-01T20:55:24.069475Z",
          "shell.execute_reply.started": "2025-06-01T20:55:24.065059Z"
        },
        "id": "34v5WgdtxQBD",
        "outputId": "faed8b1a-2d00-4be5-8f5e-79d28a701114",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images shape: (635, 256, 256)\n",
            "Train masks shape: (635, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train images shape:\", train_images_gray_clahe.shape)\n",
        "print(\"Train masks shape:\", train_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T20:55:24.071263Z",
          "iopub.status.busy": "2025-06-01T20:55:24.071005Z",
          "iopub.status.idle": "2025-06-01T21:23:48.000666Z",
          "shell.execute_reply": "2025-06-01T21:23:48.000028Z",
          "shell.execute_reply.started": "2025-06-01T20:55:24.071246Z"
        },
        "id": "jusOcUTgxQBF",
        "outputId": "07e3bed4-4d12-4982-bca0-42714c631a6b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1748811351.214668     185 service.cc:148] XLA service 0x7c06ac004140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1748811351.215379     185 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "I0000 00:00:1748811353.634393     185 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "2025-06-01 20:56:22.156070: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=3,k3=0} for conv (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,256,256]{3,2,1,0}, f32[64,128,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
            "2025-06-01 20:56:22.158226: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.002291951s\n",
            "Trying algorithm eng2{k2=3,k3=0} for conv (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,256,256]{3,2,1,0}, f32[64,128,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
            "I0000 00:00:1748811423.733995     185 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.7467 - jaccard_coefficient: 0.3675 - loss: 0.4700"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1748811443.707248     185 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "E0000 00:00:1748811443.947704     185 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "E0000 00:00:1748811445.162619     185 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "E0000 00:00:1748811445.427738     185 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "E0000 00:00:1748811453.439757     185 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "E0000 00:00:1748811453.680123     185 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7488 - jaccard_coefficient: 0.3706 - loss: 0.4668   \n",
            "Epoch 1: loss improved from inf to 0.40521, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 4s/step - accuracy: 0.7507 - jaccard_coefficient: 0.3733 - loss: 0.4639 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - accuracy: 0.8435 - jaccard_coefficient: 0.5200 - loss: 0.3179\n",
            "Epoch 2: loss improved from 0.40521 to 0.31144, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 829ms/step - accuracy: 0.8440 - jaccard_coefficient: 0.5204 - loss: 0.3176 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.8646 - jaccard_coefficient: 0.5647 - loss: 0.2796\n",
            "Epoch 3: loss improved from 0.31144 to 0.28138, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 831ms/step - accuracy: 0.8647 - jaccard_coefficient: 0.5646 - loss: 0.2797 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.8843 - jaccard_coefficient: 0.6085 - loss: 0.2443\n",
            "Epoch 4: loss improved from 0.28138 to 0.25618, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 828ms/step - accuracy: 0.8841 - jaccard_coefficient: 0.6077 - loss: 0.2449 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.8809 - jaccard_coefficient: 0.6035 - loss: 0.2484\n",
            "Epoch 5: loss improved from 0.25618 to 0.25584, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 831ms/step - accuracy: 0.8809 - jaccard_coefficient: 0.6030 - loss: 0.2487 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.8833 - jaccard_coefficient: 0.6185 - loss: 0.2370\n",
            "Epoch 6: loss improved from 0.25584 to 0.23914, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 832ms/step - accuracy: 0.8835 - jaccard_coefficient: 0.6184 - loss: 0.2371 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.8852 - jaccard_coefficient: 0.6208 - loss: 0.2347\n",
            "Epoch 7: loss did not improve from 0.23914\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.8853 - jaccard_coefficient: 0.6205 - loss: 0.2350 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.8737 - jaccard_coefficient: 0.5878 - loss: 0.2610\n",
            "Epoch 8: loss improved from 0.23914 to 0.23493, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 835ms/step - accuracy: 0.8743 - jaccard_coefficient: 0.5894 - loss: 0.2598 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.8869 - jaccard_coefficient: 0.6150 - loss: 0.2395\n",
            "Epoch 9: loss improved from 0.23493 to 0.22762, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 831ms/step - accuracy: 0.8871 - jaccard_coefficient: 0.6157 - loss: 0.2389 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9046 - jaccard_coefficient: 0.6594 - loss: 0.2058\n",
            "Epoch 10: loss improved from 0.22762 to 0.20636, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 831ms/step - accuracy: 0.9046 - jaccard_coefficient: 0.6594 - loss: 0.2058 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9079 - jaccard_coefficient: 0.6827 - loss: 0.1890\n",
            "Epoch 11: loss improved from 0.20636 to 0.19988, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 837ms/step - accuracy: 0.9077 - jaccard_coefficient: 0.6820 - loss: 0.1895 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9105 - jaccard_coefficient: 0.6687 - loss: 0.1991\n",
            "Epoch 12: loss improved from 0.19988 to 0.19140, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 833ms/step - accuracy: 0.9106 - jaccard_coefficient: 0.6692 - loss: 0.1988 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9116 - jaccard_coefficient: 0.6879 - loss: 0.1852\n",
            "Epoch 13: loss did not improve from 0.19140\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 710ms/step - accuracy: 0.9115 - jaccard_coefficient: 0.6874 - loss: 0.1856 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9110 - jaccard_coefficient: 0.6719 - loss: 0.1975\n",
            "Epoch 14: loss improved from 0.19140 to 0.18901, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 833ms/step - accuracy: 0.9111 - jaccard_coefficient: 0.6726 - loss: 0.1971 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9244 - jaccard_coefficient: 0.7196 - loss: 0.1637\n",
            "Epoch 15: loss improved from 0.18901 to 0.17643, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 826ms/step - accuracy: 0.9241 - jaccard_coefficient: 0.7187 - loss: 0.1643 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9193 - jaccard_coefficient: 0.7107 - loss: 0.1698\n",
            "Epoch 16: loss did not improve from 0.17643\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9191 - jaccard_coefficient: 0.7100 - loss: 0.1703 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9237 - jaccard_coefficient: 0.7235 - loss: 0.1609\n",
            "Epoch 17: loss improved from 0.17643 to 0.16592, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 830ms/step - accuracy: 0.9236 - jaccard_coefficient: 0.7231 - loss: 0.1611 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9218 - jaccard_coefficient: 0.7149 - loss: 0.1668\n",
            "Epoch 18: loss did not improve from 0.16592\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9217 - jaccard_coefficient: 0.7147 - loss: 0.1668 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9187 - jaccard_coefficient: 0.7085 - loss: 0.1712\n",
            "Epoch 19: loss did not improve from 0.16592\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9187 - jaccard_coefficient: 0.7086 - loss: 0.1712 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9277 - jaccard_coefficient: 0.7432 - loss: 0.1477\n",
            "Epoch 20: loss improved from 0.16592 to 0.15960, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 832ms/step - accuracy: 0.9276 - jaccard_coefficient: 0.7423 - loss: 0.1482 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9298 - jaccard_coefficient: 0.7408 - loss: 0.1498\n",
            "Epoch 21: loss improved from 0.15960 to 0.15351, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 834ms/step - accuracy: 0.9297 - jaccard_coefficient: 0.7405 - loss: 0.1500 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9230 - jaccard_coefficient: 0.7198 - loss: 0.1641\n",
            "Epoch 22: loss did not improve from 0.15351\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 710ms/step - accuracy: 0.9231 - jaccard_coefficient: 0.7201 - loss: 0.1638 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9242 - jaccard_coefficient: 0.7130 - loss: 0.1688\n",
            "Epoch 23: loss did not improve from 0.15351\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9242 - jaccard_coefficient: 0.7137 - loss: 0.1682 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9337 - jaccard_coefficient: 0.7528 - loss: 0.1418\n",
            "Epoch 24: loss improved from 0.15351 to 0.14835, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 835ms/step - accuracy: 0.9335 - jaccard_coefficient: 0.7523 - loss: 0.1421 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9308 - jaccard_coefficient: 0.7368 - loss: 0.1520\n",
            "Epoch 25: loss did not improve from 0.14835\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 710ms/step - accuracy: 0.9307 - jaccard_coefficient: 0.7368 - loss: 0.1520 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9297 - jaccard_coefficient: 0.7514 - loss: 0.1424\n",
            "Epoch 26: loss did not improve from 0.14835\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9296 - jaccard_coefficient: 0.7509 - loss: 0.1427 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9349 - jaccard_coefficient: 0.7429 - loss: 0.1480\n",
            "Epoch 27: loss improved from 0.14835 to 0.14782, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 836ms/step - accuracy: 0.9346 - jaccard_coefficient: 0.7429 - loss: 0.1480 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9341 - jaccard_coefficient: 0.7498 - loss: 0.1435\n",
            "Epoch 28: loss improved from 0.14782 to 0.14475, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 829ms/step - accuracy: 0.9340 - jaccard_coefficient: 0.7497 - loss: 0.1435 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9312 - jaccard_coefficient: 0.7514 - loss: 0.1424\n",
            "Epoch 29: loss improved from 0.14475 to 0.14092, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 833ms/step - accuracy: 0.9313 - jaccard_coefficient: 0.7515 - loss: 0.1423 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9372 - jaccard_coefficient: 0.7705 - loss: 0.1302\n",
            "Epoch 30: loss improved from 0.14092 to 0.13394, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 833ms/step - accuracy: 0.9372 - jaccard_coefficient: 0.7702 - loss: 0.1304 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9407 - jaccard_coefficient: 0.7746 - loss: 0.1276\n",
            "Epoch 31: loss improved from 0.13394 to 0.13167, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 833ms/step - accuracy: 0.9405 - jaccard_coefficient: 0.7743 - loss: 0.1278 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9403 - jaccard_coefficient: 0.7734 - loss: 0.1281\n",
            "Epoch 32: loss did not improve from 0.13167\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9400 - jaccard_coefficient: 0.7727 - loss: 0.1286 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9405 - jaccard_coefficient: 0.7768 - loss: 0.1259\n",
            "Epoch 33: loss improved from 0.13167 to 0.12595, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 833ms/step - accuracy: 0.9404 - jaccard_coefficient: 0.7768 - loss: 0.1259 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9398 - jaccard_coefficient: 0.7628 - loss: 0.1352\n",
            "Epoch 34: loss did not improve from 0.12595\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 710ms/step - accuracy: 0.9398 - jaccard_coefficient: 0.7633 - loss: 0.1349 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9380 - jaccard_coefficient: 0.7707 - loss: 0.1297\n",
            "Epoch 35: loss did not improve from 0.12595\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9380 - jaccard_coefficient: 0.7705 - loss: 0.1299 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9353 - jaccard_coefficient: 0.7645 - loss: 0.1336\n",
            "Epoch 36: loss did not improve from 0.12595\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 710ms/step - accuracy: 0.9355 - jaccard_coefficient: 0.7647 - loss: 0.1335 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9446 - jaccard_coefficient: 0.7903 - loss: 0.1174\n",
            "Epoch 37: loss improved from 0.12595 to 0.11990, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 830ms/step - accuracy: 0.9446 - jaccard_coefficient: 0.7901 - loss: 0.1175 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9399 - jaccard_coefficient: 0.7818 - loss: 0.1226\n",
            "Epoch 38: loss did not improve from 0.11990\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9400 - jaccard_coefficient: 0.7817 - loss: 0.1227 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9402 - jaccard_coefficient: 0.7827 - loss: 0.1220\n",
            "Epoch 39: loss did not improve from 0.11990\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9402 - jaccard_coefficient: 0.7824 - loss: 0.1222 - learning_rate: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9398 - jaccard_coefficient: 0.7757 - loss: 0.1266\n",
            "Epoch 40: loss did not improve from 0.11990\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9398 - jaccard_coefficient: 0.7756 - loss: 0.1267 - learning_rate: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9467 - jaccard_coefficient: 0.7922 - loss: 0.1161\n",
            "Epoch 41: loss improved from 0.11990 to 0.11771, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 833ms/step - accuracy: 0.9466 - jaccard_coefficient: 0.7920 - loss: 0.1162 - learning_rate: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9470 - jaccard_coefficient: 0.7963 - loss: 0.1135\n",
            "Epoch 42: loss improved from 0.11771 to 0.11300, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 838ms/step - accuracy: 0.9470 - jaccard_coefficient: 0.7963 - loss: 0.1135 - learning_rate: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9502 - jaccard_coefficient: 0.8170 - loss: 0.1011\n",
            "Epoch 43: loss improved from 0.11300 to 0.11210, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 833ms/step - accuracy: 0.9500 - jaccard_coefficient: 0.8161 - loss: 0.1016 - learning_rate: 0.0010\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9484 - jaccard_coefficient: 0.8061 - loss: 0.1077\n",
            "Epoch 44: loss did not improve from 0.11210\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9483 - jaccard_coefficient: 0.8056 - loss: 0.1080 - learning_rate: 0.0010\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9507 - jaccard_coefficient: 0.8045 - loss: 0.1087\n",
            "Epoch 45: loss improved from 0.11210 to 0.10971, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 831ms/step - accuracy: 0.9506 - jaccard_coefficient: 0.8044 - loss: 0.1087 - learning_rate: 0.0010\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9457 - jaccard_coefficient: 0.7944 - loss: 0.1152\n",
            "Epoch 46: loss did not improve from 0.10971\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9456 - jaccard_coefficient: 0.7941 - loss: 0.1154 - learning_rate: 0.0010\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9510 - jaccard_coefficient: 0.8101 - loss: 0.1052\n",
            "Epoch 47: loss did not improve from 0.10971\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9509 - jaccard_coefficient: 0.8097 - loss: 0.1055 - learning_rate: 0.0010\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9476 - jaccard_coefficient: 0.7977 - loss: 0.1127\n",
            "Epoch 48: loss did not improve from 0.10971\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9475 - jaccard_coefficient: 0.7975 - loss: 0.1128 - learning_rate: 0.0010\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9336 - jaccard_coefficient: 0.7645 - loss: 0.1341\n",
            "Epoch 49: loss did not improve from 0.10971\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9336 - jaccard_coefficient: 0.7642 - loss: 0.1343 - learning_rate: 0.0010\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9424 - jaccard_coefficient: 0.7864 - loss: 0.1199\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 50: loss did not improve from 0.10971\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9425 - jaccard_coefficient: 0.7864 - loss: 0.1199 - learning_rate: 0.0010\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9516 - jaccard_coefficient: 0.8057 - loss: 0.1078\n",
            "Epoch 51: loss improved from 0.10971 to 0.10891, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 829ms/step - accuracy: 0.9514 - jaccard_coefficient: 0.8057 - loss: 0.1079 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9481 - jaccard_coefficient: 0.7953 - loss: 0.1143\n",
            "Epoch 52: loss did not improve from 0.10891\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9481 - jaccard_coefficient: 0.7957 - loss: 0.1141 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9533 - jaccard_coefficient: 0.8253 - loss: 0.0959\n",
            "Epoch 53: loss improved from 0.10891 to 0.09889, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 817ms/step - accuracy: 0.9533 - jaccard_coefficient: 0.8250 - loss: 0.0961 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9595 - jaccard_coefficient: 0.8400 - loss: 0.0872\n",
            "Epoch 54: loss improved from 0.09889 to 0.09352, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 831ms/step - accuracy: 0.9593 - jaccard_coefficient: 0.8395 - loss: 0.0875 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9555 - jaccard_coefficient: 0.8312 - loss: 0.0924\n",
            "Epoch 55: loss improved from 0.09352 to 0.09201, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 825ms/step - accuracy: 0.9555 - jaccard_coefficient: 0.8313 - loss: 0.0923 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9580 - jaccard_coefficient: 0.8408 - loss: 0.0866\n",
            "Epoch 56: loss improved from 0.09201 to 0.08899, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 820ms/step - accuracy: 0.9579 - jaccard_coefficient: 0.8407 - loss: 0.0867 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9566 - jaccard_coefficient: 0.8364 - loss: 0.0892\n",
            "Epoch 57: loss did not improve from 0.08899\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9566 - jaccard_coefficient: 0.8363 - loss: 0.0893 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9578 - jaccard_coefficient: 0.8308 - loss: 0.0927\n",
            "Epoch 58: loss did not improve from 0.08899\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9578 - jaccard_coefficient: 0.8309 - loss: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9548 - jaccard_coefficient: 0.8387 - loss: 0.0879\n",
            "Epoch 59: loss improved from 0.08899 to 0.08648, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 832ms/step - accuracy: 0.9550 - jaccard_coefficient: 0.8388 - loss: 0.0879 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9574 - jaccard_coefficient: 0.8353 - loss: 0.0900\n",
            "Epoch 60: loss improved from 0.08648 to 0.08617, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 828ms/step - accuracy: 0.9575 - jaccard_coefficient: 0.8356 - loss: 0.0898 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9626 - jaccard_coefficient: 0.8485 - loss: 0.0821\n",
            "Epoch 61: loss did not improve from 0.08617\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9623 - jaccard_coefficient: 0.8480 - loss: 0.0824 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9596 - jaccard_coefficient: 0.8359 - loss: 0.0898\n",
            "Epoch 62: loss did not improve from 0.08617\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9596 - jaccard_coefficient: 0.8361 - loss: 0.0897 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9592 - jaccard_coefficient: 0.8521 - loss: 0.0801\n",
            "Epoch 63: loss did not improve from 0.08617\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 710ms/step - accuracy: 0.9592 - jaccard_coefficient: 0.8515 - loss: 0.0805 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9611 - jaccard_coefficient: 0.8478 - loss: 0.0825\n",
            "Epoch 64: loss improved from 0.08617 to 0.08553, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 826ms/step - accuracy: 0.9610 - jaccard_coefficient: 0.8476 - loss: 0.0826 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9595 - jaccard_coefficient: 0.8452 - loss: 0.0841\n",
            "Epoch 65: loss improved from 0.08553 to 0.08011, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 822ms/step - accuracy: 0.9596 - jaccard_coefficient: 0.8455 - loss: 0.0839 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9624 - jaccard_coefficient: 0.8499 - loss: 0.0813\n",
            "Epoch 66: loss did not improve from 0.08011\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9624 - jaccard_coefficient: 0.8498 - loss: 0.0813 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9630 - jaccard_coefficient: 0.8465 - loss: 0.0833\n",
            "Epoch 67: loss did not improve from 0.08011\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9628 - jaccard_coefficient: 0.8464 - loss: 0.0834 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9621 - jaccard_coefficient: 0.8581 - loss: 0.0765\n",
            "Epoch 68: loss improved from 0.08011 to 0.07960, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 828ms/step - accuracy: 0.9621 - jaccard_coefficient: 0.8578 - loss: 0.0767 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9604 - jaccard_coefficient: 0.8495 - loss: 0.0817\n",
            "Epoch 69: loss improved from 0.07960 to 0.07908, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 817ms/step - accuracy: 0.9605 - jaccard_coefficient: 0.8497 - loss: 0.0815 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9643 - jaccard_coefficient: 0.8604 - loss: 0.0752\n",
            "Epoch 70: loss improved from 0.07908 to 0.07648, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 830ms/step - accuracy: 0.9642 - jaccard_coefficient: 0.8603 - loss: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9638 - jaccard_coefficient: 0.8621 - loss: 0.0743\n",
            "Epoch 71: loss did not improve from 0.07648\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9637 - jaccard_coefficient: 0.8619 - loss: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9651 - jaccard_coefficient: 0.8678 - loss: 0.0710\n",
            "Epoch 72: loss improved from 0.07648 to 0.07334, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 833ms/step - accuracy: 0.9651 - jaccard_coefficient: 0.8676 - loss: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9652 - jaccard_coefficient: 0.8644 - loss: 0.0728\n",
            "Epoch 73: loss did not improve from 0.07334\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9651 - jaccard_coefficient: 0.8643 - loss: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9654 - jaccard_coefficient: 0.8658 - loss: 0.0721\n",
            "Epoch 74: loss improved from 0.07334 to 0.07210, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 834ms/step - accuracy: 0.9654 - jaccard_coefficient: 0.8658 - loss: 0.0721 - learning_rate: 5.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9675 - jaccard_coefficient: 0.8700 - loss: 0.0696\n",
            "Epoch 75: loss improved from 0.07210 to 0.07073, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 819ms/step - accuracy: 0.9675 - jaccard_coefficient: 0.8699 - loss: 0.0696 - learning_rate: 5.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9666 - jaccard_coefficient: 0.8728 - loss: 0.0681\n",
            "Epoch 76: loss did not improve from 0.07073\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9666 - jaccard_coefficient: 0.8725 - loss: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9623 - jaccard_coefficient: 0.8508 - loss: 0.0808\n",
            "Epoch 77: loss did not improve from 0.07073\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9623 - jaccard_coefficient: 0.8512 - loss: 0.0806 - learning_rate: 5.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9652 - jaccard_coefficient: 0.8686 - loss: 0.0705\n",
            "Epoch 78: loss did not improve from 0.07073\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9652 - jaccard_coefficient: 0.8684 - loss: 0.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9678 - jaccard_coefficient: 0.8746 - loss: 0.0669\n",
            "Epoch 79: loss improved from 0.07073 to 0.06938, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 832ms/step - accuracy: 0.9677 - jaccard_coefficient: 0.8744 - loss: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9654 - jaccard_coefficient: 0.8703 - loss: 0.0694\n",
            "Epoch 80: loss improved from 0.06938 to 0.06487, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 824ms/step - accuracy: 0.9656 - jaccard_coefficient: 0.8707 - loss: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9684 - jaccard_coefficient: 0.8785 - loss: 0.0648\n",
            "Epoch 81: loss did not improve from 0.06487\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9683 - jaccard_coefficient: 0.8780 - loss: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9675 - jaccard_coefficient: 0.8728 - loss: 0.0681\n",
            "Epoch 82: loss did not improve from 0.06487\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9675 - jaccard_coefficient: 0.8728 - loss: 0.0680 - learning_rate: 5.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9686 - jaccard_coefficient: 0.8800 - loss: 0.0639\n",
            "Epoch 83: loss improved from 0.06487 to 0.06473, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 832ms/step - accuracy: 0.9686 - jaccard_coefficient: 0.8800 - loss: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9710 - jaccard_coefficient: 0.8858 - loss: 0.0606\n",
            "Epoch 84: loss improved from 0.06473 to 0.06096, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 822ms/step - accuracy: 0.9710 - jaccard_coefficient: 0.8858 - loss: 0.0606 - learning_rate: 5.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9709 - jaccard_coefficient: 0.8871 - loss: 0.0598\n",
            "Epoch 85: loss did not improve from 0.06096\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9708 - jaccard_coefficient: 0.8869 - loss: 0.0600 - learning_rate: 5.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9669 - jaccard_coefficient: 0.8708 - loss: 0.0692\n",
            "Epoch 86: loss did not improve from 0.06096\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9669 - jaccard_coefficient: 0.8709 - loss: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9678 - jaccard_coefficient: 0.8775 - loss: 0.0653\n",
            "Epoch 87: loss did not improve from 0.06096\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9678 - jaccard_coefficient: 0.8775 - loss: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9674 - jaccard_coefficient: 0.8798 - loss: 0.0641\n",
            "Epoch 88: loss did not improve from 0.06096\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9674 - jaccard_coefficient: 0.8795 - loss: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9651 - jaccard_coefficient: 0.8676 - loss: 0.0710\n",
            "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 89: loss did not improve from 0.06096\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9652 - jaccard_coefficient: 0.8678 - loss: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9705 - jaccard_coefficient: 0.8798 - loss: 0.0640\n",
            "Epoch 90: loss did not improve from 0.06096\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.9705 - jaccard_coefficient: 0.8800 - loss: 0.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9728 - jaccard_coefficient: 0.8965 - loss: 0.0546\n",
            "Epoch 91: loss improved from 0.06096 to 0.05461, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 821ms/step - accuracy: 0.9729 - jaccard_coefficient: 0.8965 - loss: 0.0546 - learning_rate: 2.5000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.9748 - jaccard_coefficient: 0.8986 - loss: 0.0534\n",
            "Epoch 92: loss improved from 0.05461 to 0.05337, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 824ms/step - accuracy: 0.9748 - jaccard_coefficient: 0.8986 - loss: 0.0534 - learning_rate: 2.5000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9774 - jaccard_coefficient: 0.9088 - loss: 0.0478\n",
            "Epoch 93: loss improved from 0.05337 to 0.05109, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 825ms/step - accuracy: 0.9773 - jaccard_coefficient: 0.9085 - loss: 0.0480 - learning_rate: 2.5000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9752 - jaccard_coefficient: 0.9009 - loss: 0.0522\n",
            "Epoch 94: loss improved from 0.05109 to 0.05048, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 830ms/step - accuracy: 0.9752 - jaccard_coefficient: 0.9010 - loss: 0.0521 - learning_rate: 2.5000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9757 - jaccard_coefficient: 0.9053 - loss: 0.0498\n",
            "Epoch 95: loss did not improve from 0.05048\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9757 - jaccard_coefficient: 0.9051 - loss: 0.0499 - learning_rate: 2.5000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9748 - jaccard_coefficient: 0.8991 - loss: 0.0532\n",
            "Epoch 96: loss did not improve from 0.05048\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9748 - jaccard_coefficient: 0.8993 - loss: 0.0531 - learning_rate: 2.5000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9757 - jaccard_coefficient: 0.9055 - loss: 0.0496\n",
            "Epoch 97: loss improved from 0.05048 to 0.04796, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 818ms/step - accuracy: 0.9758 - jaccard_coefficient: 0.9056 - loss: 0.0496 - learning_rate: 2.5000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9763 - jaccard_coefficient: 0.9067 - loss: 0.0490\n",
            "Epoch 98: loss did not improve from 0.04796\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9763 - jaccard_coefficient: 0.9066 - loss: 0.0490 - learning_rate: 2.5000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9764 - jaccard_coefficient: 0.9064 - loss: 0.0492\n",
            "Epoch 99: loss did not improve from 0.04796\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.9764 - jaccard_coefficient: 0.9064 - loss: 0.0492 - learning_rate: 2.5000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.9771 - jaccard_coefficient: 0.9137 - loss: 0.0451\n",
            "Epoch 100: loss improved from 0.04796 to 0.04626, saving model to model/begin.weights.h5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 835ms/step - accuracy: 0.9771 - jaccard_coefficient: 0.9136 - loss: 0.0452 - learning_rate: 2.5000e-04\n",
            "SegUNet output shape: (None, 256, 256, 1)\n",
            "⏱️ Thời gian huấn luyện: 1703.52 giây\n",
            "✅ Accuracy trung bình: 94.26%\n",
            "🔗 Jaccard trung bình: 79.08%\n"
          ]
        }
      ],
      "source": [
        "initial_lr = 0.001\n",
        "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_lr, decay_steps=100000, decay_rate=0.96, staircase=True)\n",
        "\n",
        "optimizer = Adam(learning_rate=initial_lr)\n",
        "\n",
        "\n",
        "segunet = CustomSegUNet(input_size=(256, 256, 1))\n",
        "segunet.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=dice_loss,\n",
        "    metrics=['accuracy', jaccard_coefficient]\n",
        ")\n",
        "\n",
        "# Thiết lập thư mục lưu mô hình\n",
        "model_checkpoint_dir = 'model'\n",
        "# os.makedirs(model_checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_path = os.path.join(model_checkpoint_dir, 'cp.ckpt')\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=os.path.join(model_checkpoint_dir, 'begin.weights.h5'),\n",
        "    save_weights_only=True,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Callback theo dõi train accuracy thay vì validation loss/accuracy\n",
        "early_stopping = EarlyStoppingByAccuracyChange(\n",
        "    monitor='accuracy',\n",
        "    threshold=0.00001,\n",
        "    patience=10,\n",
        "    verbose=1\n",
        ")\n",
        "# ReduceLROnPlateau Callback\n",
        "lr_reduction = ReduceLROnPlateau(monitor='loss',\n",
        "                                  patience=5,\n",
        "                                  verbose=1,\n",
        "                                  factor=0.5,\n",
        "                                  min_lr=0.00001)\n",
        "\n",
        "\n",
        "# --- Tính thời gian huấn luyện ---\n",
        "start_time = time.time()\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "history = segunet.fit(\n",
        "    train_images_gray_clahe, train_masks,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    callbacks=[early_stopping, lr_reduction, checkpoint_callback]\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# --- Tính trung bình Accuracy và Jaccard ---\n",
        "avg_accuracy = np.mean(history.history['accuracy'])\n",
        "avg_jaccard = np.mean(history.history['jaccard_coefficient'])\n",
        "\n",
        "# --- In kết quả ---\n",
        "print(\"SegUNet output shape:\", segunet.output_shape)\n",
        "print(f\"⏱️ Thời gian huấn luyện: {training_time:.2f} giây\")\n",
        "print(f\"✅ Accuracy trung bình: {avg_accuracy*100:.2f}%\")\n",
        "print(f\"🔗 Jaccard trung bình: {avg_jaccard*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T21:23:48.008019Z",
          "iopub.status.busy": "2025-06-01T21:23:48.007742Z",
          "iopub.status.idle": "2025-06-01T21:23:48.952656Z",
          "shell.execute_reply": "2025-06-01T21:23:48.951923Z",
          "shell.execute_reply.started": "2025-06-01T21:23:48.007999Z"
        },
        "id": "KSiFFPffxQBH",
        "outputId": "341921af-11cb-4e1d-e8bb-b7e2f9173e4c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAADJGUlEQVR4nOzdeVxU1f/H8dewg4IbIOIumriiuaBparlgmuVSmi2uablURuW+ZZapaVaalrkvZab5TSsTKbfcd3Mr9xVwQxQEBmZ+f/BjkgAFBS7o+/l98IC5c+6Zzz1Tfe985pzPMVmtVisiIiIiIiIiIiI5yM7oAERERERERERE5OGjpJSIiIiIiIiIiOQ4JaVERERERERERCTHKSklIiIiIiIiIiI5TkkpERERERERERHJcUpKiYiIiIiIiIhIjlNSSkREREREREREcpySUiIiIiIiIiIikuOUlBIRERERERERkRynpJSIGKZbt26UKVPmns4dPXo0JpMpawMSERERecDp/ktEchMlpUQkFZPJlKGfdevWGR2q4Tp27IjJZGLQoEFGhyIiIiJ5mO6/7qxbt27kz5/f6DBEJIuZrFar1eggRCR3WbhwYYrH8+fPJyQkhAULFqQ43rx5c4oWLXrPr2M2m7FYLDg7O2f63ISEBBISEnBxcbnn179fUVFRFC1aFB8fHxITEzl9+rS+PRQREZF7ovuvO+vWrRs//PADN2/ezPHXFpHs42B0ACKS+7z88sspHm/dupWQkJBUx/8rJiYGNze3DL+Oo6PjPcUH4ODggIODsf8JW7ZsGYmJicyePZsnn3ySDRs20LhxY0NjSovVaiU2NhZXV1ejQxEREZF06P5LRB5GWr4nIvekSZMmVK1alV27dtGoUSPc3NwYOnQoAP/73/9o3bo1vr6+ODs74+fnxwcffEBiYmKKPv5b0+DUqVOYTCY++eQTvv76a/z8/HB2dqZOnTrs2LEjxblp1TQwmUz079+fFStWULVqVZydnalSpQqrV69OFf+6deuoXbs2Li4u+Pn58dVXX2W6TsKiRYto3rw5TzzxBJUqVWLRokVptjty5AgdO3bEy8sLV1dXKlasyLBhw1K0OX/+PD179rSNWdmyZenTpw/x8fHpXi/A3LlzMZlMnDp1ynasTJkyPP300/z222/Url0bV1dXvvrqKwDmzJnDk08+ibe3N87OzlSuXJnp06enGfevv/5K48aNcXd3x8PDgzp16rB48WIARo0ahaOjI5cuXUp1Xu/evSlYsCCxsbF3H0QRERHJMN1/3d3SpUupVasWrq6ueHp68vLLL3P+/PkUbcLCwujevTslSpTA2dmZYsWK8eyzz6a4n9q5cydBQUF4enri6upK2bJl6dGjR5bFKSJJlOYWkXt25coVnnrqKV544QVefvll21TyuXPnkj9/foKDg8mfPz+///47I0eOJCoqiokTJ96138WLF3Pjxg1ee+01TCYTEyZMoH379pw4ceKu3+5t2rSJ5cuX07dvX9zd3fn888/p0KEDZ86coUiRIgDs2bOHli1bUqxYMd5//30SExMZM2YMXl5eGb72Cxcu8McffzBv3jwAOnfuzKeffsrUqVNxcnKytdu/fz+PP/44jo6O9O7dmzJlynD8+HFWrlzJhx9+aOurbt26REZG0rt3b/z9/Tl//jw//PADMTExKfrLqKNHj9K5c2dee+01evXqRcWKFQGYPn06VapU4ZlnnsHBwYGVK1fSt29fLBYL/fr1s50/d+5cevToQZUqVRgyZAgFCxZkz549rF69mhdffJFXXnmFMWPGsGTJEvr37287Lz4+nh9++IEOHToYurRSRETkQfUw33/dzdy5c+nevTt16tRh3LhxhIeH89lnn/Hnn3+yZ88eChYsCECHDh04ePAgb7zxBmXKlCEiIoKQkBDOnDlje9yiRQu8vLwYPHgwBQsW5NSpUyxfvjzLYhWR/2cVEbmLfv36Wf/7n4vGjRtbAeuMGTNStY+JiUl17LXXXrO6ublZY2Njbce6du1qLV26tO3xyZMnrYC1SJEi1qtXr9qO/+9//7MC1pUrV9qOjRo1KlVMgNXJycl67Ngx27F9+/ZZAesXX3xhO9amTRurm5ub9fz587Zj//zzj9XBwSFVn+n55JNPrK6urtaoqCir1Wq1/v3331bA+uOPP6Zo16hRI6u7u7v19OnTKY5bLBbb3126dLHa2dlZd+zYkep1ktuldb1Wq9U6Z84cK2A9efKk7Vjp0qWtgHX16tWp2qf13gQFBVnLlStnexwZGWl1d3e3BgYGWm/dupVu3PXr17cGBgameH758uVWwPrHH3+keh0RERHJON1/pdS1a1drvnz50n0+Pj7e6u3tba1atWqK+5dVq1ZZAevIkSOtVqvVeu3aNStgnThxYrp9/fjjj1YgzXszEclaWr4nIvfM2dmZ7t27pzp+e+2iGzducPnyZR5//HFiYmI4cuTIXfvt1KkThQoVsj1+/PHHAThx4sRdz23WrBl+fn62x9WrV8fDw8N2bmJiImvXrqVt27b4+vra2pUvX56nnnrqrv0nW7RoEa1bt8bd3R2AChUqUKtWrRRL+C5dusSGDRvo0aMHpUqVSnF+8jR1i8XCihUraNOmDbVr1071Ovc6nb1s2bIEBQWlOn77e3P9+nUuX75M48aNOXHiBNevXwcgJCSEGzduMHjw4FSznW6Pp0uXLmzbto3jx4/bji1atIiSJUvmytpaIiIiD4KH+f7rTnbu3ElERAR9+/ZNcf/SunVr/P39+fnnn4GkcXJycmLdunVcu3Ytzb6SZ1StWrUKs9mcJfGJSNqUlBKRe1a8ePE0l5YdPHiQdu3aUaBAATw8PPDy8rIV6UxOfNzJfxM4yTdI6d043Onc5POTz42IiODWrVuUL18+Vbu0jqXl8OHD7NmzhwYNGnDs2DHbT5MmTVi1ahVRUVHAvzdxVatWTbevS5cuERUVdcc296Js2bJpHv/zzz9p1qwZ+fLlo2DBgnh5edlqUSS/N8lJprvF1KlTJ5ydnW2JuOvXr7Nq1Speeukl7UIoIiKSTR7W+6+7OX36NICtZMHt/P39bc87Ozszfvx4fv31V4oWLUqjRo2YMGECYWFhtvaNGzemQ4cOvP/++3h6evLss88yZ84c4uLisiRWEfmXklIics/S2s0tMjKSxo0bs2/fPsaMGcPKlSsJCQlh/PjxQNLMoLuxt7dP87jVas3WczMqecvmt99+mwoVKth+Jk2aRGxsLMuWLcuy10qWXpLnv8VLk6X13hw/fpymTZty+fJlJk+ezM8//0xISAhvv/02kLH35naFChXi6aeftiWlfvjhB+Li4u66S5CIiIjcu4f1/isrDRgwgL///ptx48bh4uLCiBEjqFSpEnv27AGS7rt++OEHtmzZQv/+/Tl//jw9evSgVq1a3Lx50+DoRR4sKnQuIllq3bp1XLlyheXLl9OoUSPb8ZMnTxoY1b+8vb1xcXHh2LFjqZ5L69h/Wa1WFi9ezBNPPEHfvn1TPf/BBx+waNEiunfvTrly5QD466+/0u3Py8sLDw+PO7aBf7+tjIyMtE0ph3+/FcyIlStXEhcXx08//ZTiG80//vgjRbvk6fd//fXXXb+97NKlC88++yw7duxg0aJF1KxZkypVqmQ4JhEREbl/D/r9V0aULl0aSNrs5cknn0zx3NGjR23PJ/Pz8+Odd97hnXfe4Z9//qFGjRpMmjTJ9uUjQL169ahXrx4ffvghixcv5qWXXuK7777j1VdfzZKYRUQzpUQkiyV/U3b7N2Px8fF8+eWXRoWUgr29Pc2aNWPFihVcuHDBdvzYsWP8+uuvdz3/zz//5NSpU3Tv3p3nnnsu1U+nTp34448/uHDhAl5eXjRq1IjZs2dz5syZFP0kj4+dnR1t27Zl5cqV7Ny5M9XrJbdLThRt2LDB9lx0dLRt97+MXvvtfULSdP45c+akaNeiRQvc3d0ZN24csbGxacaT7KmnnsLT05Px48ezfv16zZISERExwIN+/5URtWvXxtvbmxkzZqRYZvfrr79y+PBhWrduDUBMTEyq+xs/Pz/c3d1t5127di3VPU+NGjUAtIRPJItpppSIZKnHHnuMQoUK0bVrV958801MJhMLFizIVdO3R48ezZo1a2jQoAF9+vQhMTGRqVOnUrVqVfbu3XvHcxctWoS9vb3txua/nnnmGYYNG8Z3331HcHAwn3/+OQ0bNuTRRx+ld+/elC1bllOnTvHzzz/bXuujjz5izZo1NG7cmN69e1OpUiUuXrzI0qVL2bRpEwULFqRFixaUKlWKnj178t5772Fvb8/s2bPx8vJKlfBKT4sWLXBycqJNmza89tpr3Lx5k5kzZ+Lt7c3Fixdt7Tw8PPj000959dVXqVOnDi+++CKFChVi3759xMTEpEiEOTo68sILLzB16lTs7e3p3LlzhmIRERGRrPOg338lM5vNjB07NtXxwoUL07dvX8aPH0/37t1p3LgxnTt3Jjw8nM8++4wyZcrYyhX8/fffNG3alI4dO1K5cmUcHBz48ccfCQ8P54UXXgBg3rx5fPnll7Rr1w4/Pz9u3LjBzJkz8fDwoFWrVlk2JiKipJSIZLEiRYqwatUq3nnnHYYPH06hQoV4+eWXadq0aZq7wRmhVq1a/Prrr7z77ruMGDGCkiVLMmbMGA4fPnzH3WnMZjNLly7lscceo3Dhwmm2qVq1KmXLlmXhwoUEBwcTEBDA1q1bGTFiBNOnTyc2NpbSpUvTsWNH2znFixdn27ZtjBgxgkWLFhEVFUXx4sV56qmncHNzA5KSPz/++CN9+/ZlxIgR+Pj4MGDAAAoVKpTmDjxpqVixIj/88APDhw/n3XffxcfHhz59+uDl5UWPHj1StO3Zsyfe3t58/PHHfPDBBzg6OuLv72+7obtdly5dmDp1Kk2bNqVYsWIZikVERESyzoN8/3W7+Ph4RowYkeq4n58fffv2pVu3bri5ufHxxx8zaNAg8uXLR7t27Rg/fryt/EHJkiXp3LkzoaGhLFiwAAcHB/z9/fn+++/p0KEDkFTofPv27Xz33XeEh4dToEAB6taty6JFi9LdTEZE7o3JmpvS5yIiBmrbti0HDx7kn3/+MTqUPGXfvn3UqFGD+fPn88orrxgdjoiIiOQhuv8SebipppSIPJRu3bqV4vE///zDL7/8QpMmTYwJKA+bOXMm+fPnp3379kaHIiIiIrmY7r9E5L+0fE9EHkrlypWjW7dulCtXjtOnTzN9+nScnJwYOHCg0aHlGStXruTQoUN8/fXX9O/fn3z58hkdkoiIiORiuv8Skf/S8j0ReSh1796dP/74g7CwMJydnalfvz4fffQRjz76qNGh5RllypQhPDycoKAgFixYgLu7u9EhiYiISC6m+y8R+S8lpUREREREREREJMepppSIiIiIiIiIiOQ4JaVERERERERERCTHqdD5PbJYLFy4cAF3d3dMJpPR4YiIiEgOsVqt3LhxA19fX+zs9P3eneh+SURE5OGU0fslJaXu0YULFyhZsqTRYYiIiIhBzp49S4kSJYwOI1fT/ZKIiMjD7W73S0pK3aPkXabOnj2Lh4fHPfdjNptZs2YNLVq0wNHRMavCkwzQ2BtD424MjbsxNO7Gyc6xj4qKomTJktpxMgOy6n4J9O+TUTTuxtC4G0PjbgyNu3Fyw/2SklL3KHkKuoeHx30npdzc3PDw8NC/gDlMY28MjbsxNO7G0LgbJyfGXsvR7i6r7pdA/z4ZReNuDI27MTTuxtC4Gyc33C+pEIKIiIiIiIiIiOQ4JaVERERERERERCTHKSklIiIiIiIiIiI5TjWlslliYiJmsznd581mMw4ODsTGxpKYmJiDkUl6Y+/o6Ii9vb2BkYmIiIiIiEhOuttn9wfR/eQjsupzs5JS2cRqtRIWFkZkZORd2/n4+HD27FkVTM1hdxr7ggUL4uPjo/dERERERETkAZbRz+4PovvNR2TF52YlpbJJ8j/U3t7euLm5pfsmWSwWbt68Sf78+bGz02rKnJTW2FutVmJiYoiIiACgWLFiRoYoIiIiIiIi2Sijn90fRPeaj8jKz81KSmWDxMRE2z/URYoUuWNbi8VCfHw8Li4uSkrlsPTG3tXVFYCIiAi8vb21lE9EREREROQBlJnP7g+i+8lHZNXnZmVBskHyOlQ3NzeDI5F7lfzePWxrikVERERERB4W+ux+f7Lic7OSUtnoYZr296DReyciIiIiIvJw0Oe/e5MV46aklIiIiIiIiIiI5DglpUREREREREREJMcpKSWpbNmyBXt7e1q3bm10KCIiIiIiIiLyH926daNt27ZGh3HflJSSVGbNmsUbb7zBhg0buHDhgmFxxMfHG/baIiIiIiIiIpK9lJSSFG7evMmSJUvo06cPrVu3Zu7cuSmeX7lyJXXq1MHFxQVPT0/atWtney4uLo5BgwZRsmRJnJ2dKV++PLNmzQJg7ty5FCxYMEVfK1asSFEYbfTo0dSoUYNvvvmGsmXL4uLiAsDq1atp2LAhBQsWpEiRIjz99NMcP348RV/nzp2jc+fOFC5cmHz58lG7dm22bdvGqVOnsLOzY+fOnSnaT5kyhbJly2KxWO53yERERERERERyjfXr11O3bl2cnZ0pVqwYgwcPJiEhwfb8Dz/8QLVq1ciXLx/lypWjRYsWREdHA7Bu3Trq1q1Lvnz5KFiwIA0aNOD06dPZFqtDtvUsNlarlRhzTJrPWSwWos3R2MfbY2eX9TlCN0e3TFXE//777/H396dixYq8/PLLDBgwgCFDhmAymfj5559p164dw4YNY/78+cTHx/PLL7/Yzu3SpQtbtmzh888/JyAggJMnT3L58uVMxXvs2DGWLVvG8uXLsbe3ByA6Oprg4GCqV6/OzZs3GTlyJO3atWPv3r3Y2dlx8+ZNGjduTPHixfnpp5/w8fFh9+7dWCwWypQpQ7NmzZgzZw61a9e2vc6cOXPo2rVrtoy5iIgYKzo+mgV7F5AQm3D3xpJ3/f47RETAk0+Ct7fR0YiIyIPAaoWYtD+7Zzs3N8iC3ezOnz9Pq1at6NatG/Pnz+fIkSP06tULFxcXRo8ezcWLF+ncuTMTJkzg2Wef5eLFi+zduxer1UpCQgJt27alV69efPvtt8THx7N9+/Zs3Z1QSakcEGOOIf+4/Ia89s0hN8nnlC/D7WfNmsXLL78MQMuWLbl+/Trr16+nSZMmfPjhh7zwwgu8//77tvYBAQEA/P3333z//feEhITQrFkzAMqVK5fpeOPj45k/fz5eXl62Yx06dEjRZvbs2Xh5eXHo0CGqVq3K4sWLuXTpEjt27KBw4cIAlC9f3tb+1Vdf5fXXX2fy5Mk4Ozuze/duDhw4wI8//pjp+EREJPc6dOkQ03dMZ/7++UTFRdGySEte4zWjw5Ls8sYbcOgQhIYmJaZERETuV0wM5Dfmszs3b0K+jH92T8+XX35JyZIlmTp1KiaTCX9/fy5cuMCgQYMYOXIkFy9eJCEhgfbt21OyZEkKFy5M/fr1sbOz4+rVq1y/fp2nn34aPz8/ACpVqnTfMd2J4dNEpk2bRpkyZXBxcSEwMJDt27en29ZsNjNmzBj8/PxwcXEhICCA1atXp2hTpkwZTCZTqp9+/frZ2jRp0iTV86+//nq2XWNecfToUbZv307nzp0BcHBwoFOnTrYleHv37qVp06Zpnrt3717s7e1p3LjxfcVQunTpFAkpgH/++YfOnTtTrlw5PDw8KFOmDABnzpyxvXbNmjVtCan/atu2Lfb29rYk1Ny5c3niiSds/YiISO5zPfY6H6z/gAazG9Dph06MWT+GZYeWcfjSYa7EXOHvK3+z5ewWVv29iq92fkXjuY2p8mUVpu6YSlRcFOULlae0a2mjL0Oyk7t70u+bN42NQ0REJBc5fPgw9evXTzG7qUGDBty8eZNz584REBBA06ZNqVatGh07dmTevHlcu3YNgMKFC9OtWzeCgoJo06YNn332GRcvXszWeA2dKbVkyRKCg4OZMWMGgYGBTJkyhaCgII4ePYp3GtOwhw8fzsKFC5k5cyb+/v789ttvtGvXjs2bN1OzZk0AduzYQWJiou2cv/76i+bNm/P888+n6KtXr16MGTPG9tjNzS2brjJpCd3NIWnfMFksFqJuROHh7pFty/cyatasWSQkJODr62s7ZrVacXZ2ZurUqbi6uqZ77p2eA7Czs8NqtaY4ZjabU7XLl0ZmuE2bNpQuXZqZM2fi6+uLxWKhatWqtkLod3ttJycnunTpwpw5c2jfvj2LFy/ms88+u+M5IiJijMjYSD7b+hlTtk0hMjYyU+famex4puIz9K3dl0YlG7H619V3P+kBMm3aNCZOnEhYWBgBAQF88cUX1K1b967nfffdd3Tu3Jlnn32WFStW2I5brVZGjRrFzJkziYyMpEGDBkyfPp0KFSpk41VkQvI32TduGBuHiIg8ONzcjPuyIxtzErezt7cnJCSEzZs389tvv/H111/z4Ycfsm3bNsqWLcucOXN48803Wb16NUuWLGH48OGEhIRQr169bInH0KTU5MmT6dWrF927dwdgxowZ/Pzzz8yePZvBgwenar9gwQKGDRtGq1atAOjTpw9r165l0qRJLFy4ECDVLJuPP/4YPz+/VDN43Nzc8PHxyY7LSsVkMqW7hM5isZDomEg+p3yG1jdKSEhg/vz5TJo0iRYtWqR4rm3btnz77bdUr16d0NBQ2/t1u2rVqmGxWFi/fr1t+d7tvLy8uHHjBtHR0bbE0969e+8a15UrVzh69CgzZ87k8ccfB2DTpk0p2lSvXp1vvvmGq1evpjtb6tVXX6Vq1ap8+eWXtqmKIiKS9axWKwciDvD3lb85ce0EJ6+d5GTkSW7E36C6d3Vq+daitm9tqnhVwcHOgau3rnIy8iQnr51k98XdTN85netx1wGo7FWZN+u+SVRcFIcuH+JgxEEOXTpEtDkadyd3irgVwdPNkyKuRahXoh6vPvoqJTxKAGl/8fEgy+wXfclOnTrFu+++a/v/2NtNmDCBzz//nHnz5lG2bFlGjBhBUFAQhw4dsm1GYijNlBIRkaxmMmXJEjojVapUiWXLlmG1Wm2zpf7880/c3d0pUSLpPslkMtGgQQPq16/PW2+9RUBAAD/++CPBwcEA1KxZk5o1azJkyBDq16/P4sWLH7ykVHx8PLt27WLIkCG2Y3Z2djRr1owtW7akeU5cXFyqmyBXV9dUSYrbX2PhwoUEBwenKsy1aNEiFi5ciI+PD23atGHEiBF3nC0VFxdHXFyc7XFUVBSQdNP73xtfs9mM1WrFYrHcdXe35NlDye2N8tNPP3Ht2jW6d+9OgQIFUjzXvn17Zs2axfjx42nevDnlypWjU6dOJCQk8OuvvzJw4EBKlSpFly5d6NGjB1OmTCEgIIDTp08TERFBx44dqVOnDm5ubgwZMoQ33niDbdu22Xb2S77u5LG4fRwKFChAkSJF+OqrryhatChnzpxh6NChtnYWi4VOnTrx0Ucf0bZtWz788EOKFSvGnj178PX1pX79+gBUrFiRevXqMWjQILp3746zs/Mdx95isWC1WjGbzbaC65I1kv99edg+MBpN426Mh2ncLVYLP/39Ex//+TG7w3an2Wbz2c2wK+lvZ3tnnB2ciYqLStWusmdlhjUcRodKHbAzpfzCxmK1kGBJwMneKc3X+O+YZ8fY58b3M7Nf9AEkJiby0ksv8f7777Nx40YiIyNtz1mtVqZMmcLw4cN59tlnAZg/fz5FixZlxYoVvPDCC9l+TXelmVIiIvKQu379eqrJHr1792bKlCm88cYb9O/fn6NHjzJq1CiCg4Oxs7Nj27ZthIaG0qJFCzw9PVm3bh2XLl2iUqVKnDx5kq+//ppnnnkGX19fjh49yj///EOXLl2y7RoMS0pdvnyZxMREihYtmuJ40aJFOXLkSJrnBAUFMXnyZBo1aoSfnx+hoaEsX748xXK9261YsYLIyEi6deuW4viLL75I6dKl8fX1Zf/+/QwaNIijR4+yfPnydOMdN25cigLfydasWZMqmeXg4ICPjw83b960LTG7mxsG31B9/fXXNG7cGJPJZEu4JQsKCmLixIk4OTkxd+5cJk6cyPjx43F3d+exxx6ztf/444/54IMP6NevH1evXqVEiRIEBwcTFRWFg4MDX331FSNHjuSbb76hUaNGDBw4kAEDBtjOj4uLIzExMdXrf/PNNwwePJjq1atTvnx5xo8fz9NPP82tW7dsbZcuXcqIESNo3bo1iYmJVKxYkYkTJ6boq3PnzmzevJmOHTumOJ7W2MfHx3Pr1i02bNiQYutMyTohISFGh/BQ0rgb40Ee90RrIn9G/skP4T9wJjap1p+TyYmyrmUp6lyUok5F8XbyxsnOiZO3TnI85jjHY44TkxhDXGLSlz2FHArZ2gYWCKRegXrYnbJj9an7X36XHWMfY9SuPOm4ly/6AMaMGYO3tzc9e/Zk48aNKZ47efIkYWFhKWY/FyhQgMDAQLZs2ZJuUiozX+Jl1n8TjXb58mEPJEZGYsmFicIHxcOUXM9NNO7G0Lgbw8hxz8yEktzGarWybt06WymjZD169GDVqlUMGjSIgIAAChcuTI8ePRg6dCgWi4X8+fOzfv16pkyZQlRUFCVLlmTixIkEBQURHh7O4cOHmTdvHleuXKFYsWL07duXXr16pTk+d5rMkdH302T9b6GfHHLhwgWKFy/O5s2bbbNZAAYOHMj69evZtm1bqnMuXbpEr169WLlyJSaTCT8/P5o1a8bs2bO5detWqvZBQUE4OTmxcuXKO8by+++/07RpU44dO2arMP9fad1klSxZksuXL+Ph4ZGibWxsLGfPnrUVcL8Tq9XKjRs3cHd3z9ZtFgXGjh3LDz/8YMsk32nsY2NjOXXqFCVLlswdSxQeIGazmZCQEJo3b46jo6PR4Tw0NO7GeBDH3WK1cOjSIbac28Kf5/5kw+kNnLtxDgAPZw/61urLm3XfxNPN8459nIw8SXxiPGUKlMHV8c61Ae9Fdo59VFQUnp6eXL9+PdU9gBHu5Z5q06ZNvPDCC+zduxdPT0+6detGZGSkrabU5s2badCgARcuXKBYsWK28zp27IjJZGLJkiVpxjJ69Og0v8RbvHhxltfvrDx3LhVWrODYM89wsEePLO1bREQeDskTSkqWLImTU9qzsCV98fHxnD17lrCwsFSTOWJiYnjxxRfver9k2EwpT09P7O3tCQ8PT3E8PDw83VpPXl5erFixgtjYWK5cuYKvry+DBw+mXLlyqdqePn2atWvX3nH2U7LAwECAOyalnJ2dcXZ2TnXc0dEx1c1uYmIiJpMJOzu7u9aJSs42JreXrHfz5k1OnTrFtGnTGDt2rG2c7zT2dnZ2mEymNN9fyRoaW2No3I3xIIy71Wpl9LrRfL7981QFyIu4FuHtem/Tr24/CroUzFB//t7+WR9kGrJj7PP6e3njxg1eeeUVZs6ciadn+snDezFkyBBbPQr490u8Fi1a3HcC77+JRrs9e2DFCsp5eVH6/+uNStZ7EJPreYHG3Rgad2MYOe7JE0ry58//UE5GuN9JMrGxsbi6utKoUaNU4/ffFVDpMSwp5eTkRK1atQgNDaVt27ZAUpIgNDSU/v373/FcFxcXihcvjtlsZtmyZXTs2DFVmzlz5uDt7U3r1q3vGkvyzJnbvwmUB0f//v359ttvadu2LT30TaqIyD35etfXjNmQtGttPsd8BJYIpGHJhjQo1YCGpRpmardXyVqZ/aLv+PHjnDp1ijZt2tiOJX9R4+DgwNGjR23nhYeHp7g/Cg8Pp0aNGunGkpkv8e6Vra//r4FpFxODnT48ZrsHIbmeF2ncjaFxN4YR456ZCSUPovudJHOnyRwZfS8N3X0vODiYrl27Urt2berWrcuUKVOIjo62Fens0qULxYsXZ9y4cQBs27aN8+fPU6NGDc6fP8/o0aOxWCwMHDgwRb8Wi4U5c+bQtWtXHBxSXuLx48dZvHgxrVq1okiRIuzfv5+3336bRo0aUb169Zy5cMlRc+fOtRVVFxGRzNt2bhtv/PoGAB888QGDGw7Gwc7QWwi5TWa/6PP39+fAgQMpjg0fPpwbN27w2WefUbJkSRwdHfHx8SE0NNSWhIqKimLbtm306dMnuy8pY5J331OhcxERkTzL0DvKTp06cenSJUaOHElYWBg1atRg9erVtuLnZ86cSZGti42NZfjw4Zw4cYL8+fPTqlUrFixYQMGCBVP0u3btWs6cOZPmrBgnJyfWrl1rS4CVLFmSDh06MHz48Gy9VhERkbwoIjqC55Y+h9lipp1/O4Y9Pkw1EHOhzHzR5+LiQtWqVVOcn3wvdfvxAQMGMHbsWCpUqEDZsmUZMWIEvr6+tsSX4ZKTUjdvGhuHiIiI3DPDv+bs379/usv11q1bl+Jx48aNOXTo0F37bNGiBenVby9ZsiTr16/PdJwiIiIPmwRLAi/88ALnos5RsUhF5radq4RULpXZL/oyYuDAgURHR9O7d28iIyNp2LAhq1evzj01N/LnT/qtmVIiIiJ5luFJqQdZXttSUv6l905EBIb/Ppw/Tv1BPsd8LO+0HA9n43eak/Rl5ou+/0prmbvJZGLMmDGMGTMmC6LLBlq+JyIiWUSf/+5NVoybklLZwMnJCTs7Oy5cuICXlxdOTk7pfrNssViIj48nNjb2oSysZqS0xt5qtRIfH8+lS5ews7PTtqAikitcir7EW6vfYm/YXp4o8wTPVHyGJmWa4OyQuqB0Vvnx8I+M/3M8ALOfnU1lr8rZ9loi9yR5ppSW74mIyD3KzGf3B9G95iOy8nOzklLZwM7OjrJly3Lx4kUuXLhwx7ZWq5Vbt27h6ur6UP3Dnxvcaezd3NwoVaqUEoUiYrg/Tv7BS8tf4uLNiwAcvnyYL3d+SX6n/LQs35I+tfvwZNkns/Q1z1w/Q4+fkuoyvl3vbTpWSb3LrYjhNFNKRETuU2Y+uz+I7jcfkRWfm5WUyiZOTk6UKlWKhIQEEhMT021nNpvZsGEDjRo10rajOSy9sbe3t8fBwUFJQhExVIIlgdHrRvPRxo+wYqWSZyWGPj6Ujac3svLvlVy8eZEfDv3A8sPL+erpr3j10Vez7HVfWv4SkbGR1C1el/HNxmdJvyJZ7vaZUlYr6P+3RUTkHmT0s/uD6H7yEVn1uVlJqWxkMplwdHS845trb29PQkICLi4uSkrlMI29iORWB8IP8PrPr7P57GYAej3ai0+DPiWfUz5erv4y063T2XVhF59t+4xFBxbRa2UvLsdcZlCDQSluDGITYpmxcwb7w/fToVIHnqrwFHamO3+TNXbDWDad2YS7kzuL2y/G0V7/fZRcKnmmlNUKMTGQL5+x8YiISJ6Vkc/uD6Lc8JlYa5NERESyQYIlgQG/DaDnwZ7M2zcv3V1hk1mtVkJPhPLUoqeoPqM6m89upoBzAZY8t4Sv23xNPqd/P3DbmeyoU7wOC9otYHCDwQAMCR3Cu2vexWK1YLFaWLh/If5T/Xn7t7eZs3cOT3/7NNWmV2POnjnEJcSlGcPG0xv5YMMHAMx4egZ+hf2yaDREsoGb27+zo1RXSkREJE/STCkREZEsFmOOodMPnVj19yoAev3ci5BTIcxoPYNCroVStI1NiGX54eV8svkT9oTtAZKSTs9Vfo7xzcZTpmCZdF/HZDIxrtk4PN08eTfkXSZvnczp66c5fu04e8P2AuDr7kur8q1YcnAJhy4dosdPPRj2+zB6PdqLluVbUqd4HRzsHLh66yovLX8Ji9VC14CuvFjtxWwZG5EsY2eXNDvq5s2kulJFixodkYiIiGSSklIiIiJZ6ErMFdp824Yt57bg4uBCowKN+P3a73x/8Hu2ntvKwnYLaViqIVvPbWXevnksObiEyNhIAFwdXOlZsydv13+bcoXKZfg133nsHTzdPOn5U0+WHV4GgIezB4MbDOatem/h5ujGJy0+4etdXzNl2xQu3LjAmA1jGLNhDAWcC/BE2Se4dusaZ6POUqFwBb546ovsGBqRrOfunpSU0kwpERGRPElJKRERkSxyOvI0LRe15MjlIxR0KciPz//I9QPXGd1mNF1+6sKxq8doMq8JpQuU5mTkSdt5JTxK0OvRXvSt0xdPN897eu2uNbpS2LUwQ0KH0Lxcc4Y1GpairwIuBXivwXu8Ve8tvj/4Pf87+j9CT4RyLfYaK46sAMDRzpFvO3yLu7P7/QyDSM5JLnauHfhERETyJCWlRERE/l98YjzhN8MBKFmgZIbPuxl/k+/++o5R60Zx4cYFSniUYPVLq3mk0CP8cuAXavvWZnfv3by5+k3m7p3LyciTuDm60aFSB7oGdKVJmSbY29nfd/xtKrahTcU2d2zjZO/Ey9Vf5uXqL5NoSWT3xd2EnAhh89nNdK7amVq+te47DpEck1zsXEkpERGRPElJKREReahYrVZORp5k14Vd7L64mz1hezgbdZawm2FcvXXV1u7tem8zqcWkdLe5tVqt7Lywk5m7Z/LtX99yMz5p+VAVryqsfnk1JTxKYDabbe3dnd2Z8+wcOlbuyNVbV3mm4jOGz0iyt7OnTvE61Clex9A4RO5Z8kwpLd8TERHJk5SUEhGRh8KpyFMMDR3Kr8d+tdVwSouDnQMJlgQ+3fopnm6eDH18aKo2J66d4MVlL7Lt/DbbsQqFK9Dr0V68Vvs1PJw90u3/qQpP3dd1iMhtNFNKREQkT1NSSkRE8jSr1cq3f33L2A1jebTYo/R6tBeNSjeyzXC6Zb7FhD8n8PGfHxObEAskLWGrXrQ6j/o8yqPFHqV84fL45PfBJ78PhVwLMXX7VN5a/RbDfh+Gl5sXvWr1sr3eHyf/4Lmlz3H11lWc7Z15rvJzqV5TRHJIclJKM6VERETyJCWlREQkz7oSc4U+P/dh6aGlABy+fJhFBxZRoXAFXn30VUp6lGRI6BBOXz8NQJMyTfjwyQ+p7VsbJ3undPt9M/BNIqIj+HDjh7z+8+sUcStCO/92fLnjS95a/RaJ1kTq+NZheafllPAokSPXKiJpUKFzERGRPE1JKRERyZN++ecXev7Uk7CbYTjYOTDwsYFcjrnM4r8W88/Vfxi0dpCtbQmPEkxqMYnnKz+f4dlMHzzxARHREczcPZMXl71I60das/zwcgBerv4yXz/9Na6OrtlybSKSQZopJSIikqcpKSUiIrmWxWoh9EQo289vJ8YcQ4w5hmhzNBduXODnf34GoJJnJRa0W2DbNW5S0CSW/LWEmbtncuLaCXrX6s2QhkPI55QvU69tMpn4svWXXI65zI9HfmT54eWYMDG+2XjefexdLdUTyQ00U0pERCRPU1JKRERynbPXzzJn7xxm75ltW3qXlgGBA/io6UcpZizld8pPz0d70vPRnvcdh4OdA4s7LOb5pc+z4/wOZj87m1YVWt13vyKSRVToXEREJE9TUkpERAxjsVq4eOMiJ66d4Pi14xy/epwdF3aw5vgarFgBKOhSkKcfeZrCLoXJ55QPN0c3XB1caViqIYElArM9RhcHF1Z2XonFasHOZJftrycimZA8U0rL90RERPIkJaVEROS+WKwW1hxfg3c+b6p5V8PR3jFD5+28sJN2S9pxLupcms8/UeYJetbsSftK7XNF7SYlpERyIc2UEhERydOUlBIRkXuWaEmkx089mL9vPpA0q+jRYo8SWDyQhqUa8mzFZ7G3s0913v7w/bRY0IJrsdewN9lTqkAp/Ar74VfIjwqFK/Cs/7OUL1w+py9HRPIaFToXERHJ05SUEhGRe3J7QsreZE9+p/xcj7vO5rOb2Xx2M59u/ZTHSj7G/Lbz8SvsZzvvyOUjNJvfjGux1wgsHsiaV9bg4exh4JWISJ6lQuciIiJ5mtYiiIhIpv03IbXkuSVcHXSVI/2OML/tfPrV6Ye7kzubz24mYEYAX+/6GqvVyvGrx2k6vymXYi5R06cmq19erYSUiNw7zZQSERHJ0zRTSkREMiWthFSHyh0AqOhZkYqeFXkl4BXee+w9uv2vG+tOreO1Va+x4sgKDl06xIUbF6jsVZk1r6yhoEtBYy9GRPI2zZQSERHJ05SUEhGRuzInmjl8+TC7Luxi+ZHlrPp7VaqE1H+VLlia0C6hfLb1M4aEDuHXY78CUKFwBda+shZPN8+cvAQReRCp0LmIiEiepqSUiMgDxGq18s3ub5i9dzYJlgTsTHaY/v9/iTcS2f/nfh4v8zh1fOuQzykfAFdirrDzwk52XNjBwUsHiU+Mx2K12H4ioiPYH76f2IRY2+vcLSGVzM5kx9v136aFXwteW/Ua0eZofnrhJ4q5F8vWcRCRh0TyTCmzGeLjwcnJ2HhEREQkU5SUEhF5QETFRdFrZS++P/h9um12rN8B65OSStWLVicyNpKTkScz1L+HswePFnuUWsVq8Vzl56hXol6GY6viXYVNPTZluL2ISIYkJ6UgabZUkSLGxSIiIiKZpqSUiMgDYM/FPXT8oSPHrh7Dwc6B0Y1HU7NYTdtspzhzHKu3rOa6x3W2nN/ChRsX2BO2x3Z+hcIVqFO8DjWK1iC/U37sTHbY29ljZ7Ijv1N+avrUxK+wH3Ym7Y8hIrmIoyM4O0NcXFKxcyWlRERE8hQlpUREchmr1UroyVA+2PABuy7s4pEij1C9aHWqF61ONe9qeOfzJj4xHrPFjDnRzK6LuxgSOoT4xHhKFSjFkueWpJrFZDabcTruRKtWrXBwcOBs1Fl2nN9BQZeC1PKtpYLjIpJ3ubsnJaVUV0pERCTPUVJKRCSXsFqtrD2xlvfXv8+fZ/+0Hd8TtifFrKb0tHmkDXPbzqWwa+E7tjOZTJQqUIpSBUrdd8wiIoZzd4fLl5NmSomIiEieoqSUiIgBLFYL56POc/zacY5dPcbxq8dZd3odW89tBcDZ3pnXar1G1xpdOR15mgMRB9gfvp8DEQeIiovCyd4JRztHnOydcHV0pWtAV96o+wYmk8ngKxMRyWHJdaU0U0pERCTPUVJKRCSHHb50mKcWPcXp66dTPefi4MJrtV5jYIOB+Lr7AvBosUdpV6ldTocpIpI3uLsn/dZMKRERkTxHSSkRkRwUER1Bq8WtOH39NA52DpQpWIbyhctTvlB5KhSpwPOVn6eYezGjwxQRyTs0U0pERCTPUlJKRCSH3DLf4tnvnuVU5Cn8CvmxpecWvPJ5GR2WiEjeljxTSkkpERGRPEd7e4uI5ACL1ULXFV3Zem4rhVwK8fOLPyshJSKSFZJnSmn5noiISJ6jpJSISA4Y/vtwlh5aiqOdI8s7LaeiZ0WjQxIReTBoppSIiEiepaSUiEg2m7NnDuM2jQPgm2e+oUmZJsYGJCLyIFGhcxERkTxLSSkRkWwUER1B/1/7AzD88eF0CehicEQiIg8YFToXERHJs5SUEhHJRhP/nEiMOYY6vnV4/4n3jQ5HROTBo5lSIiIieZbhSalp06ZRpkwZXFxcCAwMZPv27em2NZvNjBkzBj8/P1xcXAgICGD16tUp2owePRqTyZTix9/fP0Wb2NhY+vXrR5EiRcifPz8dOnQgPDw8W65PRB5eEdERTNsxDYDRTUZjZzL8P7kiIg8ezZQSERHJswz9hLRkyRKCg4MZNWoUu3fvJiAggKCgICIiItJsP3z4cL766iu++OILDh06xOuvv067du3Ys2dPinZVqlTh4sWLtp9NmzaleP7tt99m5cqVLF26lPXr13PhwgXat2+fbdcpIg+niX9O5FbCLer41uGp8k8ZHY6IyINJhc5FRETyLEOTUpMnT6ZXr150796dypUrM2PGDNzc3Jg9e3aa7RcsWMDQoUNp1aoV5cqVo0+fPrRq1YpJkyalaOfg4ICPj4/tx9PT0/bc9evXmTVrFpMnT+bJJ5+kVq1azJkzh82bN7N169ZsvV4ReXj8d5aUyWQyOCIRkQdU8kwpLd8TERHJcxyMeuH4+Hh27drFkCFDbMfs7Oxo1qwZW7ZsSfOcuLg4XFxcUhxzdXVNNRPqn3/+wdfXFxcXF+rXr8+4ceMoVaoUALt27cJsNtOsWTNbe39/f0qVKsWWLVuoV69euq8dFxdnexwVFQUkLSk0m82ZuPKUks+9nz7k3mjsjfGwjPv4jeO5lXCL2sVq06x0M8Ov92EZ99xG426c7Bz73Pp+Tps2jYkTJxIWFkZAQABffPEFdevWTbPt8uXL+eijjzh27Bhms5kKFSrwzjvv8Morr9jadOvWjXnz5qU4LygoKFXpBMNpppSIiEieZVhS6vLlyyQmJlK0aNEUx4sWLcqRI0fSPCcoKIjJkyfTqFEj/Pz8CA0NZfny5SQmJtraBAYGMnfuXCpWrMjFixd5//33efzxx/nrr79wd3cnLCwMJycnChYsmOp1w8LC0o133LhxvP9+6iLFa9aswc3NLRNXnraQkJD77kPujcbeGA/yuEeaI5l6aCoALV1b8uuvvxoc0b8e5HHPzTTuxsmOsY+JicnyPu9XckmEGTNmEBgYyJQpUwgKCuLo0aN4e3unal+4cGGGDRuGv78/Tk5OrFq1iu7du+Pt7U1QUJCtXcuWLZkzZ47tsbOzc45cT6ao0LmIiEieZVhS6l589tln9OrVC39/f0wmE35+fnTv3j3Fcr+nnvq3bkv16tUJDAykdOnSfP/99/Ts2fOeX3vIkCEEBwfbHkdFRVGyZElatGiBh4fHPfdrNpsJCQmhefPmODo63nM/knkae2M8DOM+OHQw8dZ4aherzYhOI3LF0r2HYdxzI427cbJz7JNnS+cmt5dEAJgxYwY///wzs2fPZvDgwanaN2nSJMXjt956i3nz5rFp06YUSSlnZ2d8fHyyNfb7pkLnIiIieZZhSSlPT0/s7e1T7XoXHh6e7s2Pl5cXK1asIDY2litXruDr68vgwYMpV65cuq9TsGBBHnnkEY4dOwaAj48P8fHxREZGppgtdafXhaSbsrS+HXR0dMySm92s6kcyT2NvDCPHfcf5HRRzL0YJjxJZ3nf4zXCm75oOwPtPvI+Tk1OWv8b90D/vxtC4Gyc7xj63vZf3UhLhdlarld9//52jR48yfvz4FM+tW7cOb29vChUqxJNPPsnYsWMpUqRIun1lV7mD5D5u/23j4oIjQEwM5thYsLe/r9eRlLQM2Rgad2No3I2hcTdObih3YFhSysnJiVq1ahEaGkrbtm0BsFgshIaG0r9//zue6+LiQvHixTGbzSxbtoyOHTum2/bmzZscP37cViOhVq1aODo6EhoaSocOHQA4evQoZ86coX79+llzcSJiiJ0XdvLT0Z94K/Atiril/aFp/an1PDHvCbzyebGz105KFih5z6939dZV3v7tbY5fPc6lmEtcjrnM1VtXAbTjnojkmHspiQBJm78UL16cuLg47O3t+fLLL2nevLnt+ZYtW9K+fXvKli3L8ePHGTp0KE899RRbtmzBPp3ET3aXO4DUSzLt4uJok/w6P/5IQha9jqSkZcjG0LgbQ+NuDI27cYwsd2Do8r3g4GC6du1K7dq1qVu3LlOmTCE6Oto29bxLly4UL16ccePGAbBt2zbOnz9PjRo1OH/+PKNHj8ZisTBw4EBbn++++y5t2rShdOnSXLhwgVGjRmFvb0/nzp0BKFCgAD179iQ4OJjChQvj4eHBG2+8Qf369dMtci4iud/Xu76m/y/9MVvMHLp0iB86/pCqjdVq5b2Q97BiJSI6gnZL2rGx+0ZcHV3v6TVH/jGS+fvmpzru5ujGhOYTcsWyPRGR9Li7u7N3715u3rxJaGgowcHBlCtXzra074UXXrC1rVatGtWrV8fPz49169bRtGnTNPvMrnIHcIclmVYrVnt7TImJtHjsMfD1va/XkZS0DNkYGndjaNyNoXE3Tm4od2BoUqpTp05cunSJkSNHEhYWRo0aNVi9erXtm74zZ85gZ2dnax8bG8vw4cM5ceIE+fPnp1WrVixYsCDFMrxz587RuXNnrly5gpeXFw0bNmTr1q14eXnZ2nz66afY2dnRoUMH4uLiCAoK4ssvv8yx6xaRjEu0JHL82nEOhB8gn1M+nijzBM4O/y6ljUuI441f32Dm7pm2Y8sOLyPkeAjN/Zqn6GvpoaXsuLCDfI75cHFwYdfFXfRe1Zv5bednOoF04toJvtr1FQBTgqYQ4BOAl5sXXvm8KOJaBHs7LR8RkZxxLyURIGmJX/ny5QGoUaMGhw8fZty4canqTSUrV64cnp6eHDt2LN2kVHaXO0i3r/z54fp1HGNjQR9osoWWIRtD424MjbsxNO7GMbLcgeGFzvv375/ucr1169aleNy4cWMOHTp0x/6+++67u76mi4sL06ZNY9q0aRmOU0Ryzuazm5m7dy77wvfxV8RfxJj/nfrp4ezB0488TXv/9lQvWp1XfnyFbee3YcLEh09+yMWbF/li+xe8ufpN9r2+Dyf7pJpO8YnxDAlNqrcysMFAGpVuRLP5zVi4fyE1fWoSXD84zVjSM2rdKBIsCbTwa8Fb9d7KuosXEcmk+ymJcDuLxZKiHtR/nTt3jitXrlCsWLH7DTnrubvD9esqdi4iIpLHGJ6UEhFJFp8Yz6g/RjH+z/FYsdqOuzq4UtW7KudvnOfCjQssPrCYxQcW254v5FKIbzt8S1D5ICJjI1lycAlHLh/hs62f8V6D9wD4audXnLh2gqL5ihJcP5j8Tvn5NOhT3lz9Ju+FvEdV76q08GuRoTgPhB9g0f5FAHz05EdZOAIiIvcmsyURxo0bR+3atfHz8yMuLo5ffvmFBQsWMH160kYNN2/e5P3336dDhw74+Phw/PhxBg4cSPny5VPszpdruLsn/b5509g4REREJFOUlBKRXOHQpUO8vPxl9oTtAeClai/xTMVnCCgaQPnC5bG3s8ditbDt3DaWHV7GssPLOBV5iupFq/Njpx8pVyhpF86CLgUZ32w83f/XnTEbxvBitRdxd3ZnzIYxAIxuMpr8Tknbh/ev25+9YXuZvXc2L/zwAjt67cCvsN9dYx32+zCsWHm+8vPU8q2VTSMiIpJxmS2JEB0dTd++fTl37hyurq74+/uzcOFCOnXqBIC9vT379+9n3rx5REZG4uvrS4sWLfjggw/SXJ5nuPxJ/13XTCkREZG8RUkpETGU1Wpl6vapDFw7kNiEWIq4FmFmm5m0q9QuVVs7kx31S9anfsn6TGw+kePXjlO6QGkc7VOuV+4S0IWvdn3F1nNbGbh2IGULluVyzGUqFqlIz5o9be1MJhNftv6SQ5cPsfXcVsZtGsc3z3xzx3j/PPMnK/9eib3Jng+e+CBrBkFEJAtkpiTC2LFjGTt2bLp9ubq68ttvv2VleNlLM6VERETyJLu7NxERyT7Td07nzdVvEpsQS8vyLTnQ50CaCan/MplMlC9cPlVCCpKSV1OfmooJE4sPLGbi5okAjGs6LlV7ZwdnRjQaAcD60+vv+JpWq9VWl6pHzR5U9KyYoWsUEZFspplSIiIieZKSUiJimERLoi1hNPzx4fzy4i8Uc8+aArq1fGvRu1ZvIKlW1WMlH6Otf9s02zYo2QATJo5dPcbFGxfT7XP1sdVsPLMRZ3tnRjYemSVxiohIFtBMKRERkTxJSSkRyTSr1cpPR3/ifNT5++rnp6M/cSryFEVcizD08aGYTKYsijDJh09+SBHXIpgwMbH5xHT7L+BSgBo+NQDYeGZjmm2sVitDfx8KwBt136CER4ksjVVERO6DZkqJiIjkSUpKiUimLTqwiGe/e5ZaX9fiYMTBe+7ns22fAdC7Vm9cHV2zKjybIm5F2PrqVjb33MxjJR+7Y9vHSz0OwIbTG9J8fm/YXvaG7cXN0Y3BDQdneawiInIfkmdKKSklIiKSpygpJSKZYrVamfDnBADCo8NpMq8J+8L2ZbqfPWF7WH96PQ52DvSt0zeLo/xX+cLlqVei3l3bNSrdCEg/KbXy75UABPkFUcStSNYFKCIi90/L90RERPIkJaVEJFNCToRwIOIA+Rzz8WixR7kcc5kn5z/J7ou7M9XP1B1TAXi+8vO5Yinc46WTZkodiDjA1VtXUz2/6u9VADz9yNM5GpeIiGSAlu+JiIjkSUpKiUimfLL5EwBeffRVQruEElg8kKu3rtJ0flN2nN+RoT6uma+x5NASAAbUG5BdoWaKdz5v/D39Adh0ZlOK58JuhrHjQtK1tarQKsdjExGRu9BMKRERkTxJSSkRybB9YfsIORGCncmOAfUGUNClIGteWUODkg2IjI2k2YJm9PqpF1/t/IpdF3YRlxCXZj+rL68mPjGe+iXqU7d43Ry+ivQl15XaeDplsfOf//4ZgLrF6+KT3yfH4xIRkbvQTCkREZE8SUkpkYdI2M0wLt64eM/nT9oyCUhaclemYBkAPJw9WP3yahqXbkxUXBTf7PmG139+ndoza+M+zp3Gcxvz6z+/YrVaAYhNiGX1ldVA7pkllcxWV+pMyrpSq/75/6V7FbR0T0QkV9JMKRERkTzJwegARCRnnLx2kmrTqxFtjqZ84fI0Kd2ExmUa07h0Y0oWKHnX889FnePbv74F4N3H3k3xXH6n/IS8EsLP//zMjvM72HlxJzsv7OTqratsOL2BDac3UK9EPd5v8j5nrp3hesJ1SnqUpH2l9tlyrfcqOSm168IubsbfJL9TfmITYgk5HgKonpSISK6lmVIiIiJ5kpJSIg+J6TunE22OBuDY1WMcu3qMb/Z8A8B7j73H+GbjMZlM6Z7/+bbPSbAk0Lh0Y2r71k71vKO9I23929LWvy2QtEvfyciTTN8xnWk7prH13FaCFgbhZO8EQJ9afXCwy13/CSpVoBSlC5Tm9PXTbDm7heZ+zVl3ah3R5miKuxenhk8No0MUEZG0JM+UUlJKREQkT9HyPZGHQGxCLLP3zAZgftv5rOy8knfrv0sd3zoATNw8kdHrRqd7flRcFF/t+gpIPUsqPSaTiXKFyjGxxUROvHWCAYEDcHFwIT4xHieTEz1q9Li/i8omybvwbTidtITv9l337pS0ExERAyXPlNLyPRERkTwld01TEJFssfTgUq7cukKpAqV4sdqL2NvZ25aifbHtC95c/SZjNoyhgEsBgusHpzr/m93fEBUXhb+n/z3tPueT34dPW37Kew3e4+udX2M5Z6Gwa+H7vq7s0KhUIxbuX8jGMxuxWq2s/HsloKV7IiK52u0zpaxW0JcIIiIieYJmSonkcVdirjB+03ie/e5Z/or4K802X+78EoDXar2GvZ19iufeCHyDsU+MBeCdNe/wze5vbM9FREfw0caPGLvh/5+v/w52pnv/z4avuy/DGg6jlkete+4juyXXldp6biu7Lu7izPUzuDi48GTZJw2OTERE0pWclLJYIDbW2FhEREQkwzRTSiSP2he2jy+2f8GiA4uITUi6Af/nyj/sfm03Lg4utnZ7Lu5h67mtONo50rNmzzT7Gvr4UK7HXWfi5on0Xtmbq7eusi98H0sPLsVsMQNQ1bsqL1d/OfsvzGCPFHkE73zeRERHMGrdKACalWuGm6ObwZGJiEi68uX79+8bN8DV1bhYREREJMM0U0okj7kcc5nmC5pT46sazNozi9iEWGr61KRovqIcvnyYEb+PSNF++s7pAHSo3IGi+Yum2afJZGJ8s/G8Xut1rFgZtHYQiw8sxmwxE1g8kHlt57Gj144Uya4Hlclk4vFSSXWlfvnnFwCerqCleyIiuZqd3b+JKdWVEhERyTOUlBLJY/r+3Je1J9Zib7KnY5WObOy+kV29dzGzzUwAJm2ZxJ9n/gQgMjaSRQcWJZ1Xu+8d+zWZTExrPY1Xa75Kfqf89KjRg529drL11a10CejyUCSkkiUv4UvW+pHWBkUiIiIZllzsXDvwiYiI5BlavieShyw9uJSlh5Zib7JnS88t1Clex/Zcm4pt6BrQlXn75tHtf93Y+9pe5u+bT4w5hipeVWhYquFd+7cz2THzmZl83ebrh3qnuduTUjV9alLCo4SB0YiISIa4u0N4uGZKiYiI5CGaKSWSR0RER9D3l6TZTkMfH5oiIZVsSssplPAowbGrxxi8drBt6V7fOn0zlWR6mBNSANW8q1HAuQCgXfdERPIMzZQSERHJc5SUEskj+v3Sj8sxl6letDrDGw1Ps01Bl4LMemYWAFN3TOXI5SPkd8r/UBQoz0r2dvZ0q9GNgi4FeaX6K0aHIyIiGZG8A5+SUiIiInmGklIiecD3B7/nh0M/4GDnwNxn5+Jk75Ru2xZ+LXit1mu2xy9XexkPZ4+cCPOBMqXlFK4NukaFIhWMDkVERDIiOSml5XsiIiJ5hpJSIrlcRHQE/X7pB8DQhkOpWazmXc+Z2Hwi5QuXx8neif51+2d3iCIiIsbT8j0REZE8R4XORXKxyzGX6bqiK5djLhNQNIBhjYZl6Dx3Z3e2v7qda7HXKFeoXDZHKSIikgtoppSIiEieo6SUSC4UmxDL59s+56ONH3E97nrSsr22d16291+FXAtRyLVQNkYpIiKSi2imlIiISJ6jpJRILmKxWvjur+8YEjqEM9fPAFDDpwaftfyMGj41jA1OREQkN9NMKRERkTxHSSmRXGLdqXW8F/IeOy/sBKCERwk+fPJDXq7+MnYmlX8TERG5I82UEhERyXOUlBIx2KFLhxgYMpCf//kZAHcndwY3HMyAegNwc3QzODoREZE8InmmlJJSIiIieYaSUiJZwGq1YjKZMnXO6cjTfLjxQ2btmYXFasHBzoHXar3GyMYj8c7nnU2RioiIPKC0fE9ERCTP0Zogkfu0cP9CCnxcgDd/fZPo+Oi7tj906RBdV3Sl/Bflmbl7JharhXb+7TjY9yBTW01VQkpEROReaPmeiIhInqOZUiL3IT4xnsFrB3Mj/gZfbP+CX/75hTnPzuHx0o+naGexWvjzzJ9M2jKJ/x39n+1407JNGd1kNA1LNczp0EVERB4smiklIiKS5ygpJXIfvj/4PedvnMfLzQsXBxeOXztO47mNeSvwLQY1HMSmM5tY9fcqfvnnFy7FXALAhIl2ldoxqMEg6hava/AViIiIPCA0U0pERCTPUVJK5B5ZrVY+2fwJAAPqDaBfnX68s+YdZu2ZxZRtU5iybUqK9h7OHnSo1IH3HnuPSl6VDIhYRETkAaaZUiIiInmOklIi/2/FkRUsP7ycsU+OpVSBUndt//vJ39kXvg83Rzder/06BVwK8M0z39ChUgdeXfkqF25c4JEij/B0had5+pGnaViqIY72jjlwJSIiIg+h5JlSUVFgtUImNyARERGRnKeklAiw5K8lvLj8RSxWC3vC9rC5x2bcnd3veM4nW5JmSfWo0YPCroVtx5+q8BQn3zrJlZgrFHMvlq1xi4iIyP8rVgzs7SE+Hi5cgOLFjY5IRERE7sLw3femTZtGmTJlcHFxITAwkO3bt6fb1mw2M2bMGPz8/HBxcSEgIIDVq1enaDNu3Djq1KmDu7s73t7etG3blqNHj6Zo06RJE0wmU4qf119/PVuuT3K//x39Hy8tfwmL1YKDnQN/RfxF52WdSbQkpnvOXxF/sfrYakyYGFBvQKrnneydlJASERHJSU5OULZs0t//ufcTERGR3MnQpNSSJUsIDg5m1KhR7N69m4CAAIKCgoiIiEiz/fDhw/nqq6/44osvOHToEK+//jrt2rVjz549tjbr16+nX79+bN26lZCQEMxmMy1atCA6OjpFX7169eLixYu2nwkTJmTrtUrutDNqJy/++CKJ1kReqf4KG7tvxMXBhZ//+ZlBawele97kLZMBaF+pPX6F/XIqXBEREbkTf/+k30eOGBuHiIiIZIihSanJkyfTq1cvunfvTuXKlZkxYwZubm7Mnj07zfYLFixg6NChtGrVinLlytGnTx9atWrFpEmTbG1Wr15Nt27dqFKlCgEBAcydO5czZ86wa9euFH25ubnh4+Nj+/Hw8MjWa5Xc5/eTvzP+5HjMFjMdq3Rk9rOzqVeiHnOfnQvApC2TmLV7VqrzLt64yKIDiwB4p/47ORmyiIiI3EnFikm/NVNKREQkTzAsKRUfH8+uXbto1qzZv8HY2dGsWTO2bNmS5jlxcXG4uLikOObq6sqmTZvSfZ3r168DULhw4RTHFy1ahKenJ1WrVmXIkCHExMTc66VIHrQ/fD/tlrbDbDXT5pE2LGy3EAe7pBJrnap2YnTj0QC8/vPrhBwPwWK12M6dun0q8Ynx1C9Rn/ol6xsRvoiIiKRFSSkREZE8xbBC55cvXyYxMZGiRYumOF60aFGOpDPlOigoiMmTJ9OoUSP8/PwIDQ1l+fLlJCamXfvHYrEwYMAAGjRoQNWqVW3HX3zxRUqXLo2vry/79+9n0KBBHD16lOXLl6cbb1xcHHFxcbbHUVFRQFKdK7PZnOHr/q/kc++nD8m8jzd+zK2EW1TPX515reeBBcyWf9+DIY8N4WDEQZYeXkqLhS1wtHOkuHtxSniUYF/4PgAG1B2g9+0e6J95Y2jcjaFxN052jr3ez1xMSSkREZE8JU/tvvfZZ5/Rq1cv/P39MZlM+Pn50b1793SX+/Xr14+//vor1Uyq3r172/6uVq0axYoVo2nTphw/fhw/v7TrA40bN473338/1fE1a9bg5uZ2H1eVJCQk5L77kIyJSojih0M/ANDFtwsb/tiQZrvnHJ/jlMcpdkbtxGwxc+r6KU5dPwVAMadiOBx34JcTv+RU2A8c/TNvDI27MTTuxsmOsdfs6lwsOSl1+jTcugWursbGIyIiIndkWFLK09MTe3t7wsPDUxwPDw/Hx8cnzXO8vLxYsWIFsbGxXLlyBV9fXwYPHky5cuVSte3fvz+rVq1iw4YNlChR4o6xBAYGAnDs2LF0k1JDhgwhODjY9jgqKoqSJUvSokWL+6pHZTabCQkJoXnz5jg6Ot5zP5Jxn277FPNfZmoUrUF5t/J3HPt2tMOcaObizYucv3Ges1FnCb8ZTvNyzfH39M/hyB8M+mfeGBp3Y2jcjZOdY588Wzq3mTZtGhMnTiQsLIyAgAC++OIL6tatm2bb5cuX89FHH3Hs2DHMZjMVKlTgnXfe4ZVXXrG1sVqtjBo1ipkzZxIZGUmDBg2YPn06FSpUyKlLyjxvbyhQAK5fh2PHoFo1oyMSERGROzAsKeXk5EStWrUIDQ2lbdu2QNJyu9DQUPr373/Hc11cXChevDhms5lly5bRsWNH23NWq5U33niDH3/8kXXr1lE2eWvgO9i7dy8AxYoVS7eNs7Mzzs7OqY47Ojpmyc1uVvUjd2a1Wpm1N6l4ee9He8PFu4+9o6Mjfi5++Hlql72spH/mjaFxN4bG3TjZMfa58b1M3tF4xowZBAYGMmXKFIKCgjh69Cje3t6p2hcuXJhhw4bh7++Pk5MTq1atonv37nh7exMUFATAhAkT+Pzzz5k3bx5ly5ZlxIgRBAUFcejQoVQ1PnMNkylpB75t25J24FNSSkREJFczdPe94OBgZs6cybx58zh8+DB9+vQhOjqa7t27A9ClSxeGDBlia79t2zaWL1/OiRMn2LhxIy1btsRisTBw4EBbm379+rFw4UIWL16Mu7s7YWFhhIWFcevWLQCOHz/OBx98wK5duzh16hQ//fQTXbp0oVGjRlSvXj1nB0By3LpT6/j7yt/kd8pPp8qdjA5HREQkS2R2R+MmTZrQrl07KlWqhJ+fH2+99RbVq1e3lTywWq1MmTKF4cOH8+yzz1K9enXmz5/PhQsXWLFiRQ5e2T1QXSkREZE8w9CaUp06deLSpUuMHDmSsLAwatSowerVq23Fz8+cOYOd3b95s9jYWIYPH86JEyfInz8/rVq1YsGCBRQsWNDWZvr06UDSzdbt5syZQ7du3XBycmLt2rVMmTKF6OhoSpYsSYcOHRg+fHi2X68Y76tdXwHwUrWXcHd2NzgaERGR+5e8o/HtX+TdbUfj21mtVn7//XeOHj3K+PHjATh58iRhYWEpdkkuUKAAgYGBbNmyhRdeeCHNvrJrY5jkPm7/nR678uWxByyHD5OoovT3TRs2GEPjbgyNuzE07sbJDRvDGF7ovH///uku11u3bl2Kx40bN+bQoUN37M9qtd7x+ZIlS7J+/fpMxSgPhojoCJYfTtph8bVarxkcjYiISNa4lx2NAa5fv07x4sWJi4vD3t6eL7/8kubNmwMQFhZm6+O/fSY/l5bs3hgG7l68vtjNm9QFru/YwYZftCFJVtGGDcbQuBtD424MjbtxjNwYxvCklEhWsVqtnI06y7Zz23Cwc+CZis9gb2dve37u3rmYLWbq+NahZrGaysSLiMhDzd3dnb1793Lz5k1CQ0MJDg6mXLlyqWabZ0Z2bQwDmSheX6oUTJhAwfBwWj31VFKdKbln2rDBGBp3Y2jcjaFxN05u2BhGSSnJ0yJjI/lq51dsObeFbee3EXbz329vG5RswPx28ylXqBwWq8W2dE+zpERE5EFyLzsaQ9ISv/LlywNQo0YNDh8+zLhx42jSpIntvPDw8BQbwYSHh1OjRo10+8zujWEy1FelSmBnhykqCserV+EOYyAZpw0bjKFxN4bG3Rgad+MYuTGMoYXORe7X0NChDA4dzP+O/o+wm2HYm+yp6VMTdyd3/jz7JwEzApi1exahJ0I5ce0EHs4evFA17ToYIiIiedHtOxonS97RuH79+hnux2Kx2OpBlS1bFh8fnxR9RkVFsW3btkz1aQgXFyhTJulvFTsXERHJ1TRTSvKsW+ZbLD6wGIAhDYfQukJrahariZujG6ciT9F1RVc2nN7AqytfxcM5acnAK9VfIZ9TPiPDFhERyXLBwcF07dqV2rVrU7duXduGLrfvaFy8eHHGjRsHJNV+ql27Nn5+fsTFxfHLL7+wYMEC24YxJpOJAQMGMHbsWCpUqEDZsmUZMWIEvr6+tG3b1qjLzLiKFeHECThyBBo3NjoaERERSYeSUpJnrTiygutx1ylVoBRjnxyLnenfiX9lCpbh9y6/8+nWTxn2+zCi4pLWs2rpnoiIPIgyu6NxdHQ0ffv25dy5c7i6uuLv78/ChQvp1KmTrc3AgQOJjo6md+/eREZG0rBhQ1avXo2Li0uOX1+mVawIv/6qmVIiIiK5nJJSkmfN3TcXgK4BXVMkpJLZ29nz7mPv0sKvBQNDBlLJsxLVilbL4ShFRERyRmZ2NB47dixjx469Y38mk4kxY8YwZsyYrAox51SsmPRbSSkREZFcTUkpyZPORZ0j5HjStpVdA7resW31otVZ/fLqnAhLREREcgMlpURERPIEFTqXPGnBvgVYsdKodCP8CvsZHY6IiIjkJv7+Sb9PnoT/L94uIiIiuY+SUpJrDQwZSJcfuxCbEJviuNVqZc7eOQB0C+hmQGQiIiKSq/n4gLs7WCxw/LjR0YiIiEg6tHxPcqU/Tv7BxM0TgaTaULOfmY3JZAJgy7kt/HP1H/I55uP5Ks8bGaaIiIjkRiZT0hK+nTuTduCrXNnoiERERCQNmikluY7VamXUulG2x3P3zuXLHV+meAzwXOXnyO+UP6fDExERkbxAdaVERERyPSWlJNcJPRnKxjMbcbZ35t367wIw4LcBbDy9kRhzDEsOLgGgW41uBkYpIiIiuZqSUiIiIrmeklKSq9w+S+q1Wq8xofkEOlftTIIlgeeWPscX274gKi6KsgXL0qh0I4OjFRERkVwrudi5klIiIiK5lpJSkqusOb6GzWc34+LgwuCGgzGZTHzzzDcEFA0gIjqCwaGDAega0BU7k/7xFRERkXTcPlPKajU2FhEREUmTPtVLrmG1Whm5biQAfWr3oZh7MQDcHN34sdOPFHYtbGvbJaCLITGKiIhIHlGhQlLB82vX4PJlo6MRERGRNCgpJbnGr8d+Zfv57bg6uDKowaAUz5UtVJbvOnyHs70zbf3bUrZQWYOiFBERkTzB1RVKlUr6W0v4REREciUHowMQgf+fJfVH0iyp/nX7UzR/0VRtmvs15+I7F3F3ds/p8ERERCQvqlgRTp+GI0egYUOjoxEREZH/0EwpyRVW/r2SXRd3kc8xH+899l667Qq5FsLBTrlUERERyQDtwCciIpKrKSklhrtlvsW7a94F4I26b+CVz8vgiEREROSBkLwD3+HDxsYhIiIiaVJSSgw3at0o/rn6D8XdizO44WCjwxEREZEHRbVqSb/37zc2DhEREUmTklKSraxWKx+s/4ApW6dgTWM75h3ndzBpyyQAZjw9gwIuBXI6RBEREXlQVa+e9Pvs2aRd+ERERCRXUVJKstX60+sZuW4kb//2Nr1X9ibRkmh7Lj4xnh4/9cBitfBitRd5+pGnDYxUREREHjgFCkDp0kl/a7aUiIhIrqOklGSrr3d9bfv7mz3f0HlZZ+IS4gD4aONH/BXxF15uXnzW8jOjQhQREZEHWUBA0u99+4yNQ0RERFJRUkqyzZWYKyw7vAyAkY1G4mTvxNJDS2nzbRu2nN3Chxs/BGBqq6l4unkaGaqIiIg8qJKTUpopJSIikusoKSXZZsH+BcQnxlPTpybvP/E+P7/4M/kc8xFyIoSGcxqSYEmgrX9bnq/8vNGhioiIyINKM6VERERyLSWlJFtYrVZm7p4JQO9avQFoVq4ZoV1CKeRSCIvVQkGXgnzZ6ktMJpORoYqIiMiDLLnY+V9/QUKCsbGIiIhICkpKSbbYfHYzhy4dws3RjRervWg7HlgikI3dN/JC1Rf44fkfKOZezMAoRURE5IHn5wf58kFsLPzzj9HRiIiIyG2UlJJskTxLqlOVTng4e6R4rop3Fb7t8C1NyzU1IjQRERF5mNjZQbVqSX+rrpSIiEiuoqSUZLnI2Ei+P/g9AL0e7WVwNCIiIvLQS17Cp7pSIiIiuYqSUpLlFu1fxK2EW1T1rkq9EvWMDkdEREQedip2LiIikispKSVZ6vYC570e7aUi5iIiImI8JaVERERyJSWlJEvtvLCTfeH7cLZ35uXqLxsdjoiIiMi/NaXOn4crV4yNRURERGyUlJIsc+jSIYb+PhSA5yo/R2HXwgZHJCIiIgJ4eEDZskl/q9i5iIhIrqGklNyXuIQ4Fh9YTOO5janyZRXWnliLncmOfnX6GR2aiIiIyL+0hE9ERCTXcTA6AMm7/jzzJ22XtOVyzGUA7E32tKnYhgGBA6hfsr7B0YmIiIjcJiAAVqzQTCkREZFcREkpuWez9szicsxlfN196f1ob3o+2pMSHiWMDktEREQkNc2UEhERyXWUlJJ7ti886abui6e+oH2l9gZHIyIiInIH1asn/T54EBISwEG3wSIiIkZTTSm5J+ZEMwcjDgIQUDTA4GhERERE7qJsWcifH+Li4OhRo6MRERERckFSatq0aZQpUwYXFxcCAwPZvn17um3NZjNjxozBz88PFxcXAgICWL16dab7jI2NpV+/fhQpUoT8+fPToUMHwsPDs/zaHmRHrxwlLjGO/E75KVuorNHhiIiIiNyZnd2/s6VUV0pERCRXMDQptWTJEoKDgxk1ahS7d+8mICCAoKAgIiIi0mw/fPhwvvrqK7744gsOHTrE66+/Trt27dizZ0+m+nz77bdZuXIlS5cuZf369Vy4cIH27bX8LDP2hSUt3QsoGoCdyfDcpoiIiMjdqa6UiIhIrmJoNmHy5Mn06tWL7t27U7lyZWbMmIGbmxuzZ89Os/2CBQsYOnQorVq1oly5cvTp04dWrVoxadKkDPd5/fp1Zs2axeTJk3nyySepVasWc+bMYfPmzWzdujVHrvtBkFxPSkv3REREJM9InimlpJSIiEiuYFhSKj4+nl27dtGsWbN/g7Gzo1mzZmzZsiXNc+Li4nBxcUlxzNXVlU2bNmW4z127dmE2m1O08ff3p1SpUum+rqRmS0r5KCklIiIieUTyTCkt3xMREckVDNt25PLlyyQmJlK0aNEUx4sWLcqRI0fSPCcoKIjJkyfTqFEj/Pz8CA0NZfny5SQmJma4z7CwMJycnChYsGCqNmFhYenGGxcXR1xcnO1xVFQUkFTnymw2Z+yi05B87v30YYTk5XtVilTJc7Eny6tjn9dp3I2hcTeGxt042Tn2ej/zsGrVwGSCCxfg8mXw9DQ6IhERkYdantoL97PPPqNXr174+/tjMpnw8/Oje/fu6S73y0rjxo3j/fffT3V8zZo1uLm53Xf/ISEh991HTrlmvkZ4dDh22HF+z3l+2feL0SHdl7w09g8SjbsxNO7G0LgbJzvGPiYmJsv7lBySPz/4+cGxY9CrF1SoAIULQ5EiULs21KxpdIQiIiIPFcOSUp6entjb26fa9S48PBwfH580z/Hy8mLFihXExsZy5coVfH19GTx4MOXKlctwnz4+PsTHxxMZGZlittSdXhdgyJAhBAcH2x5HRUVRsmRJWrRogYeHR6au/XZms5mQkBCaN2+Oo6PjPfeTk9acWAMHoXzh8rR7up3R4dyzvDj2DwKNuzE07sbQuBsnO8c+eba05FH16iUlpVasSHncyQlOnYJixYyISkRE5KFkWFLKycmJWrVqERoaStu2bQGwWCyEhobSv3//O57r4uJC8eLFMZvNLFu2jI4dO2a4z1q1auHo6EhoaCgdOnQA4OjRo5w5c4b69eun+5rOzs44OzunOu7o6JglN7tZ1U9OOHj5IAA1itXIMzHfSV4a+weJxt0YGndjaNyNkx1jr/cyj5syBRo1gkuX4MqVpJ/ffoOwsKTf3boZHaGIiMhDI9OFzsuUKcOYMWM4c+bMfb94cHAwM2fOZN68eRw+fJg+ffoQHR1N9+7dAejSpQtDhgyxtd+2bRvLly/nxIkTbNy4kZYtW2KxWBg4cGCG+yxQoAA9e/YkODiYP/74g127dtG9e3fq169PvXr17vuaHgbaeU9ERCT3mTZtGmXKlMHFxYXAwEC2b9+ebtuZM2fy+OOPU6hQIQoVKkSzZs1Ste/WrRsmkynFT8uWLbP7MrJfkSJJS/eGDoVJk2DuXOjZM+m5334zNDQREZGHTaaTUgMGDGD58uWUK1eO5s2b891336UoAJ4ZnTp14pNPPmHkyJHUqFGDvXv3snr1aluh8jNnznDx4kVb+9jYWIYPH07lypVp164dxYsXZ9OmTSmW4d2tT4BPP/2Up59+mg4dOtCoUSN8fHxYvnz5PV3Dwyi5yLmSUiIiIrnDkiVLCA4OZtSoUezevZuAgACCgoKIiIhIs/26devo3Lkzf/zxB1u2bLGVJDh//nyKdi1btuTixYu2n2+//TYnLifnBQUl/Q4JAYvF2FhEREQeIveUlNq7dy/bt2+nUqVKvPHGGxQrVoz+/fuze/fuTAfQv39/Tp8+TVxcHNu2bSMwMND23Lp165g7d67tcePGjTl06BCxsbFcvnyZ+fPn4+vrm6k+IWn537Rp07h69SrR0dEsX778jvWk5F+xCbEcuZy0k2ENnxrGBiMiIiIATJ48mV69etG9e3cqV67MjBkzcHNzS3czmEWLFtG3b19q1KiBv78/33zzja3kwe2cnZ3x8fGx/RQqVCgnLifn1asH7u5JS/n27DE6GhERkYdGppNSyR599FE+//xzLly4wKhRo/jmm2+oU6cONWrUYPbs2Vit1qyMU3KJgxEHSbQmUsS1CL7uqROCIiIikrPi4+PZtWsXzZo1sx2zs7OjWbNmbNmyJUN9xMTEYDabKVy4cIrj69atw9vbm4oVK9KnTx+uXLmSpbHnGo6O8OSTSX9rCZ+IiEiOuedC52azmR9//JE5c+YQEhJCvXr16NmzJ+fOnWPo0KGsXbuWxYsXZ2WskgvY6kn5BGAymQyORkRERC5fvkxiYmKKUgUARYsW5ciRIxnqY9CgQfj6+qZIbLVs2ZL27dtTtmxZjh8/ztChQ3nqqafYsmUL9vb2afYTFxeXoqxD8k6FZrMZs9mc2UtLIfn8++0nPXZNm2L/v/9h+e03Et97L1teIy/K7nGXtGncjaFxN4bG3TjZOfYZ7TPTSandu3czZ84cvv32W+zs7OjSpQuffvop/v7+tjbt2rWjTp06me1a8gDVkxIREXmwfPzxx3z33XesW7cOFxcX2/EXXnjB9ne1atWoXr06fn5+rFu3jqZNm6bZ17hx43j//fdTHV+zZg1ubm5ZEm9ISEiW9PNfbo6ONAf480/WLFtGgqtrtrxOXpVd4y53pnE3hsbdGBp342TH2MfExGSoXaaTUnXq1KF58+ZMnz6dtm3bprktctmyZVPcyMiDI3mmlOpJiYiI5A6enp7Y29sTHh6e4nh4ePhda2Z+8sknfPzxx6xdu5bq1avfsW25cuXw9PTk2LFj6SalhgwZQnBwsO1xVFSUrYi6h4dHBq8obWazmZCQEJo3b57m/WdWsE6ciN2JEwQ5O2Nt1SpbXiOvyYlxl9Q07sbQuBtD426c7Bz75NnSd5PppNSJEycoXbr0Hdvky5ePOXPmZLZryeWsVit7w/YCmiklIiKSWzg5OVGrVi1CQ0Np27YtgK1oef/+/dM9b8KECXz44Yf89ttv1K5d+66vc+7cOa5cuUKxYsXSbePs7Iyzs3Oq446Ojll2s5uVfaUSFATTp+MQGgrt2mXPa+RR2Truki6NuzE07sbQuBsnO8Y+o/1lutB5REQE27ZtS3V827Zt7Ny5M7PdSR5y5voZrsddx9HOkUpelYwOR0RERP5fcHAwM2fOZN68eRw+fJg+ffoQHR1N9+7dAejSpQtDhgyxtR8/fjwjRoxg9uzZlClThrCwMMLCwrh58yYAN2/e5L333mPr1q2cOnWK0NBQnn32WcqXL09QUJAh15gjWrRI+r1mjbFxiIiIPCQynZTq168fZ8+eTXX8/Pnz9OvXL0uCktwpeeleJa9KONk7GRyNiIiIJOvUqROffPIJI0eOpEaNGuzdu5fVq1fbip+fOXOGixcv2tpPnz6d+Ph4nnvuOYoVK2b7+eSTTwCwt7dn//79PPPMMzzyyCP07NmTWrVqsXHjxjRnQj0wnnwS7O3hn3/g5EmjoxEREXngZXr53qFDh3j00UdTHa9ZsyaHDh3KkqAkd0oucq56UiIiIrlP//79012ut27duhSPT506dce+XF1d+e2337IosjzEwwPq14dNm5JmS732mtERiYiIPNAyPVPK2dk5VSFNgIsXL+LgkOkcl+Qhe8P3AqonJSIiIg+w5OWJD2NSTkREJIdlOinVokULhgwZwvXr123HIiMjGTp0KM2bN8/S4CR3SZ4ppaSUiIiIPLCS60qFhkJCgrGxiIiIPOAynZT65JNPOHv2LKVLl+aJJ57giSeeoGzZsoSFhTFp0qTsiFFygRtxNzh+7TgAAT5KSomIiMgDqlYtKFwYoqJg2zawWuHQIRg7Ftq2hV27jI5QRETkgZHp9XbFixdn//79LFq0iH379uHq6kr37t3p3Lmztm98gK07tQ4AX3dfPN08jQ1GREREJLvY20OzZvD99/Dee3D1Khw9+u/z27bBzp1QvLhxMYqIiDwg7qkIVL58+ejdu3dWxyK5VKIlkWG/DwPghSovGByNiIiISDZr0SIpKbVlS9JjJ6ekY8ePw+HD0L49rF8PLi7GxikiIpLH3XNl8kOHDnHmzBni4+NTHH/mmWfuOyjJXebtm8eBiAMUcinEsEbDjA5HREREJHt17AgrVyYlo9q3h1atknbmO34c6tSB7duhTx+YPRtMJqOjFRERybMynZQ6ceIE7dq148CBA5hMJqxWKwCm//8/5MTExKyNUAwVHR/N8N+HAzC80XAKuxY2OCIRERGRbObuDitWpD7u55c0gyooCObOhZo14c03czo6ERGRB0amC52/9dZblC1bloiICNzc3Dh48CAbNmygdu3arFu3LhtCFCNN2jKJizcvUrZgWfrV6Wd0OCIiIg+Us2fPcu7cOdvj7du3M2DAAL7++msDo5I7atYMPvkk6e/g4KRd+kREROSeZDoptWXLFsaMGYOnpyd2dnbY2dnRsGFDxo0bx5v6puiBcvHGRSb8OQGAj5t9jLODs8ERiYiIPFhefPFF/vjjDwDCwsJo3rw527dvZ9iwYYwZM8bg6CRdAwbAK69AYmLSUr/bEosiIiKScZlOSiUmJuLu7g6Ap6cnFy5cAKB06dIcvX1nEskTrFYrX+/6mlaLWjFz10yi46Ntz41aN4poczSBxQN5vvLzBkYpIiLyYPrrr7+oW7cuAN9//z1Vq1Zl8+bNLFq0iLlz5xobnKTPZIKvvoJatZJ253vjDaMjEhERyZMyXVOqatWq7Nu3j7JlyxIYGMiECRNwcnLi66+/ply5ctkRo2STizcu0vOnnvx67FcAfj32K++FvEe3Gt14oswTzNozC4BJLSbZaoaJiIhI1jGbzTg7J81EXrt2rW3DGH9/fy5evGhkaHI3rq7/1pVasSLpp21bY2MSERHJYzI9U2r48OFYLBYAxowZw8mTJ3n88cf55Zdf+Pzzz7M8QMkeSw8uper0qvx67Fec7Z3pW7svfoX8uB53nc+2fUbbJW2xWC10qNSBBqUaGB2uiIjIA6lKlSrMmDGDjRs3EhISQsuWLQG4cOECRYoUMTg6uauqVeG995L+7t8foqKMjUdERCSPyfRMqaCgINvf5cuX58iRI1y9epVChQppNk0eEJcQx6srX2Xh/oUA1PSpyYJ2C6jiXQWL1cKa42v4cseXrPp7Fa6OroxrOs7giEVERB5c48ePp127dkycOJGuXbsSEBAAwE8//WRb1ie53IgRSTvyHT8Ow4eDvqQVERHJsEwlpcxmM66uruzdu5eqVavajhcuXDjLA5PsMWXrFBbuX4idyY4hDYcwsvFInOydALAz2dGyfEtalm/J+ajzWKwWShYoaXDEIiIiD64mTZpw+fJloqKiKFSokO147969cXNzMzAyyTBXV5gxA5o3h6lT4aWXIDDQ6KhERETyhEwt33N0dKRUqVIkJiZmVzySjRIsCUzbMQ2A6a2nM/bJsbaE1H8V9yiuhJSIiEg2u3XrFnFxcbaE1OnTp5kyZQpHjx7F29vb4Ogkw5o1g5dfBqsVevcGs9noiERERPKETNeUGjZsGEOHDuXq1avZEY9ko5+O/sTZqLN4unnSJaCL0eGIiIg89J599lnmz58PQGRkJIGBgUyaNIm2bdsyffp0g6OTTJk8GQoXhv374dNPjY5GREQkT8h0Umrq1Kls2LABX19fKlasyKOPPpriR3KvL7Z/AUCvR3vh4uBicDQiIiKye/duHn/8cQB++OEHihYtyunTp5k/f742kMlrvLzgk0+S/v7wQ9DKAhERkbvKdKHzttrqNk86EH6AdafWYW+yp0/tPkaHIyIiIkBMTAzu7u4ArFmzhvbt22NnZ0e9evU4ffq0wdFJpnXpAm++mbQL38GDUL260RGJiIjkaplOSo0aNSo74pBsNnX7VADa+rdVrSgREZFconz58qxYsYJ27drx22+/8fbbbwMQERGBh4eHwdFJptnbQ9268PvvsG2bklIiIiJ3kenle5L3XL11lQX7FwDwZuCbBkcjIiIiyUaOHMm7775LmTJlqFu3LvXr1weSZk3VrFnT4OjkniTvvLd1q7FxiIiI5AGZnillZ2eHyWRK93ntzJf7zN4zm1sJt6hetDqPl3rc6HBERETk/z333HM0bNiQixcvEhAQYDvetGlT2rVrZ2Bkcs+Sk1Lbthkbh4iISB6Q6aTUjz/+mOKx2Wxmz549zJs3j/fffz/LApOskWhJZNqOaQC8UfeNOyYURUREJOf5+Pjg4+PDuXPnAChRogR169Y1OCq5Z8lJqUOHkmpLaRmmiIhIujKdlHr22WdTHXvuueeoUqUKS5YsoWfPnlkSmGSNn//5mVORpyjkUogXq71odDgiIiJyG4vFwtixY5k0aRI3b94EwN3dnXfeeYdhw4ZhZ6dKC3mOjw+ULg2nT8OOHdC0qdERiYiI5FqZTkqlp169evTu3TurupN7sPTgUr7e/TX5nfJT0KUgBZ0L8vup3wF49dFXcXN0MzhCERERud2wYcOYNWsWH3/8MQ0aNABg06ZNjB49mtjYWD788EODI5R7Uq9eUlJq2zYlpURERO4gS5JSt27d4vPPP6d48eJZ0Z3coyGhQzh+7Xiq43YmO/rW6WtARCIiInIn8+bN45tvvuGZZ56xHatevTrFixenb9++SkrlVYGBsGSJip2LiIjcRaaTUoUKFUpRl8hqtXLjxg3c3NxYuHBhlgYnGXcz/qYtITUlaAqxCbFExkYSGRvJ46Ufp0zBMsYGKCIiIqlcvXoVf3//VMf9/f25evWqARFJlqhXL+n3tm1gtYJqeoqIiKQp00mpTz/9NEVSys7ODi8vLwIDAylUqFCWBicZdzDiIAA++X14q95bBkcjIiIiGREQEMDUqVP5/PPPUxyfOnUq1atXNygquW81a4KjI0REJC3jK1PG6IhERERypUwnpbp165YNYcj9OhBxAIBq3tUMjkREREQyasKECbRu3Zq1a9dSv359ALZs2cLZs2f55ZdfDI5O7pmLCwQEwM6dSUv4lJQSERFJU6a3dJkzZw5Lly5NdXzp0qXMmzcvS4KSzDsQrqSUiIhIXtO4cWP+/vtv2rVrR2RkJJGRkbRv356DBw+yYMECo8OT+3H7Ej4RERFJU6aTUuPGjcPT0zPVcW9vbz766KMsCUoyzzZTqqiSUiIiInmJr68vH374IcuWLWPZsmWMHTuWa9euMWvWLKNDk/sRGJj0W0kpERGRdGU6KXXmzBnKli2b6njp0qU5c+ZMpgOYNm0aZcqUwcXFhcDAQLZv337H9lOmTKFixYq4urpSsmRJ3n77bWJjY23PlylTBpPJlOqnX79+tjZNmjRJ9fzrr7+e6dhzC6vVquV7IiIiIrlJ8kyp3bshPt7YWERERHKpTCelvL292b9/f6rj+/bto0iRIpnqa8mSJQQHBzNq1Ch2795NQEAAQUFBREREpNl+8eLFDB48mFGjRnH48GFmzZrFkiVLGDp0qK3Njh07uHjxou0nJCQEgOeffz5FX7169UrRbsKECZmKPTcJjw7ncsxl7Ex2VPaqbHQ4IiIiIuLnB0WKQFwc7NtndDQiIiK5UqaTUp07d+bNN9/kjz/+IDExkcTERH7//XfeeustXnjhhUz1NXnyZHr16kX37t2pXLkyM2bMwM3NjdmzZ6fZfvPmzTRo0IAXX3yRMmXK0KJFCzp37pxidpWXlxc+Pj62n1WrVuHn50fjxo1T9OXm5painYeHR2aHItfYH56UJCxfuDyujq4GRyMiIiIimEz/LuHbutXYWERERHKpTO++98EHH3Dq1CmaNm2Kg0PS6RaLhS5dumSqplR8fDy7du1iyJAhtmN2dnY0a9aMLVu2pHnOY489xsKFC9m+fTt169blxIkT/PLLL7zyyivpvsbChQsJDg7GZDKleG7RokUsXLgQHx8f2rRpw4gRI3Bzc0s33ri4OOLi4myPo6KiADCbzZjN5gxf938ln3s/fey9uBeAKp5V7qufh01WjL1knsbdGBp3Y2jcjZOdY58VfbZv3/6Oz0dGRt73a0guEBgIv/ySVFfqjTeMjkZERCTXyXRSysnJiSVLljB27Fj27t2Lq6sr1apVo3Tp0pnq5/LlyyQmJlK0aNEUx4sWLcqRI0fSPOfFF1/k8uXLNGzYEKvVSkJCAq+//nqK5Xu3W7FiBZGRkXTr1i1VP6VLl8bX15f9+/czaNAgjh49yvLly9ONd9y4cbz//vupjq9Zs+aOyayMSl5meC9Wn14NgPN1Z20ffQ/uZ+zl3mncjaFxN4bG3TjZMfYxMTH33UeBAgXu+nyXLl3u+3XEYNqBT0RE5I4ynZRKVqFCBSpUqJCVsdzVunXr+Oijj/jyyy8JDAzk2LFjvPXWW3zwwQeMGDEiVftZs2bx1FNP4evrm+J47969bX9Xq1aNYsWK0bRpU44fP46fn1+arz1kyBCCg4Ntj6OioihZsiQtWrS4r6V/ZrOZkJAQmjdvjqOj4z318f7spGRZu8fa0cq/1T3H8rDJirGXzNO4G0PjbgyNu3Gyc+yTZ0vfjzlz5mRBJJLr1a2b9PvYMbh8GdLYwVpERORhlumkVIcOHahbty6DBg1KcXzChAns2LGDpUuXZqgfT09P7O3tCQ8PT3E8PDwcHx+fNM8ZMWIEr7zyCq+++iqQlFCKjo6md+/eDBs2DDu7f0tknT59mrVr195x9lOywP9f73/s2LF0k1LOzs44OzunOu7o6JglN7v32k+iJZHDlw8DUNO3pj703IOseg8lczTuxtC4G0PjbpzsGHu9l5JhBQtCxYpw9Chs3w6t9OWhiIjI7TJd6HzDhg20SuP/UJ966ik2bNiQ4X6cnJyoVasWoaGhtmMWi4XQ0FDq16+f5jkxMTEpEk8A9vb2AFit1hTH58yZg7e3N61bt75rLHv37gWgWLFiGY4/tzh29RixCbG4OrhSrlA5o8MRERERkdslL+FTsXMREZFUMp2UunnzJk5OTqmOOzo6Zno6e3BwMDNnzmTevHkcPnyYPn36EB0dTffu3QHo0qVLikLobdq0Yfr06Xz33XecPHmSkJAQRowYQZs2bWzJKUhKbs2ZM4euXbvairEnO378OB988AG7du3i1KlT/PTTT3Tp0oVGjRpRvXr1TMWfGxyIOABAFe8q2NvZ36W1iIiIiOSohg2Tfn/1FfxnhYCIiMjDLtPL96pVq8aSJUsYOXJkiuPfffcdlStXzlRfnTp14tKlS4wcOZKwsDBq1KjB6tWrbcXPz5w5k2Jm1PDhwzGZTAwfPpzz58/j5eVFmzZt+PDDD1P0u3btWs6cOUOPHj1SvaaTkxNr165lypQpREdHU7JkSTp06MDw4cMzFXtucSA8KSlVzbuawZGIiIiISCovvwyffw4HDkCPHrBqFfxnV2gREZGHVaaTUiNGjKB9+/YcP36cJ598EoDQ0FAWL17MDz/8kOkA+vfvT//+/dN8bt26dSmDdXBg1KhRjBo16o59tmjRItVyvmQlS5Zk/fr1mY4zt0qeKaWklIiIyMNt2rRpTJw4kbCwMAICAvjiiy+om1xo+z9mzpzJ/Pnz+euvvwCoVasWH330UYr2VquVUaNGMXPmTCIjI2nQoAHTp0/P8Y1u8jwXF1i8GGrXhl9+gS+/hH79jI5KREQkV8j08r02bdqwYsUKjh07Rt++fXnnnXc4f/48v//+O+XLl8+OGOUObEmpokpKiYiIPKyWLFlCcHAwo0aNYvfu3QQEBBAUFERERESa7detW0fnzp35448/2LJli21H4fPnz9vaTJgwgc8//5wZM2awbds28uXLR1BQELGxsTl1WQ+OqlVh4sSkv999Fw4dMjYeERGRXCLTSSmA1q1b8+effxIdHc2JEyfo2LEj7777LgEBAVkdn9xBdHw0x68eBzRTSkRE5GE2efJkevXqRffu3alcuTIzZszAzc2N2bNnp9l+0aJF9O3blxo1auDv788333xj23AGkmZJTZkyheHDh/Pss89SvXp15s+fz4ULF1ixYkUOXtkDpH9/aNkSYmPhxRchLs7oiERERAx3T0kpSNqFr2vXrvj6+jJp0iSefPJJtmpXkRx16NIhrFjxzudN0fxFjQ5HREREDBAfH8+uXbto1qyZ7ZidnR3NmjVjy5YtGeojJiYGs9lM4cKFATh58iRhYWEp+ixQoACBgYEZ7lP+w2SCOXPA0xP27YNhw4yOSERExHCZqikVFhbG3LlzmTVrFlFRUXTs2JG4uDhWrFiR6SLncv/2h+8HNEtKRETkYXb58mUSExNtG8UkK1q0KEeOHMlQH4MGDcLX19eWhAoLC7P18d8+k59LS1xcHHG3zQBK3pnZbDZjNpszFEt6ks+/334MVaQIpq+/xqF9e5g0iYRWrbA+/rjRUd3RAzHueZDG3Rgad2No3I2TnWOf0T4znJRq06YNGzZsoHXr1kyZMoWWLVtib2/PjBkz7jlIuT8qci4iIiL36+OPP+a7775j3bp1uLi43Fdf48aN4/333091fM2aNbi5ud1X38lCQkKypB/D2NkR0Lw5ZUJCuPH662yYMCFP7MaX58c9j9K4G0PjbgyNu3GyY+xjYmIy1C7DSalff/2VN998kz59+mjXlVxCRc5FRETE09MTe3t7wsPDUxwPDw/Hx8fnjud+8sknfPzxx6xdu5bq1avbjiefFx4eTrFixVL0WaNGjXT7GzJkCMHBwbbHUVFRtiLqHh4embmsVMxmMyEhITRv3hxHR8f76stwtWtj9fen0D//0DomBuvzzxsdUboeqHHPQzTuxtC4G0PjbpzsHPvk2dJ3k+Gk1KZNm5g1axa1atWiUqVKvPLKK7zwwgv3HKDcvwPhmiklIiLysHNycqJWrVqEhobStm1bAFvR8v79+6d73oQJE/jwww/57bffqF27dornypYti4+PD6GhobYkVFRUFNu2baNPnz7p9uns7Iyzs3Oq446Ojll2s5uVfRmmePGkXfhGj8Zh5Eh47jlwcjI6qjt6IMY9D9K4G0PjbgyNu3GyY+wz2l+GC53Xq1ePmTNncvHiRV577TW+++47fH19sVgshISEcOPGjXsOVjIv/GY4l2IuYcJEFe8qRocjIiIiBgoODmbmzJnMmzePw4cP06dPH6Kjo+nevTsAXbp0YciQIbb248ePZ8SIEcyePZsyZcoQFhZGWFgYN2/eBMBkMjFgwADGjh3LTz/9xIEDB+jSpQu+vr62xJfcp3fegaJF4fhx+Ppro6MRERExRKZ338uXLx89evRg06ZNHDhwgHfeeYePP/4Yb29vnnnmmeyIUdKQvHTPr7Afbo5ZU6NBRERE8qZOnTrxySefMHLkSGrUqMHevXtZvXq1rVD5mTNnuHjxoq399OnTiY+P57nnnqNYsWK2n08++cTWZuDAgbzxxhv07t2bOnXqcPPmTVavXn3fdafk/+XPD6NGJf09ZgxkcJmDiIjIgyTTSanbVaxYkQkTJnDu3Dm+/fbbrIpJMkBL90REROR2/fv35/Tp08TFxbFt2zYCAwNtz61bt465c+faHp86dQqr1ZrqZ/To0bY2JpOJMWPGEBYWRmxsLGvXruWRRx7JwSt6CLz6KlSoAJcuwaRJqZ8/cwZu281QRETkQXNfSalk9vb2tG3blp9++ikrupMM+CviLwCqelc1OBIRERERuSeOjvDRR0l/T5oEYWFw8ybMmgX16kHp0lCrFpw7Z2ycIiIi2STDhc4ld7HtvKeZUiIiIiJ5V4cOEBgI27ZBixZw8mRSYirZwYPQoAH89hv4+xsXp4iISDbIkplSkrMsVgsHLx0EoFpRJaVERERE8iyTCcaPT/r7wIGkhFSFCknHduyARx5JWsbXsCFs325srCIiIllMM6XyoJPXThJjjsHZ3pnyhcsbHY6IiIiI3I/GjZOSUP/8Ay+/DI0aJSWrADZtgtatkxJUTzwBy5dDUJCx8YqIiGQRJaXyoOR6UpW8KuFgp7dQREREJM8bODDt415e8Pvv0L49hITA008nLeV78smcjU9ERCQbaPleHqQi5yIiIiIPkfz5YdWqpMRUQgJMnGh0RCIiIllCSak8KLnIeVUvJaVEREREHgpOTv/WnlqzBi5eNDYeERGRLKCkVB6UPFNKRc5FREREHiLly8Njj4HFAt9+a3Q0IiIi901JqTwmPjGeo1eOAlq+JyIiIvLQeeWVpN/z5xsbh4iISBZQUiqPOXr5KAmWBDycPSjpUdLocEREREQkJ3XsmLSUb98+2L/f6GhERETui5JSecztRc5NyVsFi4iIiMjDoXDhpB34ABYsMDYWERGR+6SkVB6jIuciIiIiD7kuXZJ+L1oEiYnGxiIiInIflJTKY1TkXEREROQh99RTUKRI0g58oaGpn791S8kqERHJE5SUymNuX74nIiIiIg8hJyd44YWkv/9b8HztWiheHBo2BKs152MTERHJBCWl8pAbcTc4GXkSUFJKRERE5KGWvITvxx/hxo2kv+fOTZpFde0abN0KBw4YFp6IiEhGKCmVhxy6dAgAn/w+eLp5GhyNiIiIiBimTh145BGIiYFly2DUKOjeHRISwM0tqc2PPxobo4iIyF0oKZWH2Iqca5aUiIiIyMPNZPp3tlS/fjBmTNLfQ4fCF18k/a2klIiI5HJKSuUhtiLn3ipyLiIiIvLQe/nlpN8xMWBvD19/DR9+CM88A3Z2sG8fnDxpbIwiIiJ3oKRUHqIi5yIiIiJiU7p0UsHzQoVg1Sro1SvpuKcnNGqU9LdmS4mISC6mpFQekrx8TzOlRERERASAb7+FiAho2TLl8Xbtkn4rKSUiIrmYklJ5RER0BBHREQBU9qpscDQiIiIikms4OKQ+1rZt0u8//4Tw8BwNR0REJKOUlMojDkYcBKBcoXLkc8pncDQiIiIikquVKgW1aoHVCj/9ZHQ0IiIiaVJSKo/Q0j0RERERyZT27ZN+awmfiIjkUkpK5REqci4iIiIimZJcV2rtWrh+/e7tb90Cszl7YxKR/2vv3uN0rPM/jr/ue+aekzPDDEWDQuSUwzRoUznWasWW0wo5LBnJbAdkDFlUClthOpD2t+Swq5Ik04RWTjUOhSGHSsk41DLMMDPmvn5/fJubyQyDmfu6h/fz8bgfc93X/b2+9/f6jOrr0/f7uUTkPEpKFRNaKSUiIiIil+XWW6F2bZNoWr78ws8PH4YlSyAmBpo3h1Kl4JZbIDXV+2MVEZHrkpJSxYBlWVopJSIiIiKXL6+n8O3ZAw88AOHh0LUrTJsGX34J2dnwww8we7Y9YxURkeuOklLFwIETBziVeQqX00WtCrXsHo6IiIiIFBc5SamPP4Zjx2DkSKhXDz78EBwOqF8fhgyBefNg8mTTdto0beMTERGvyOP5seJrfjjxAwARZSNw+blsHo2IiIiIFBtNm8INN8DBg1C9Opw6Zc536ADTp5vtfTnOnDEJqR9/hEWLoFcvW4YsIiLXD9tXSs2YMYOIiAiCgoKIjIxk06ZNF20/ffp0ateuTXBwMFWrVmXEiBGcOXPG8/m4ceNwOBy5XnXq1MnVx5kzZxg6dCgVKlSgZMmSdO3alcOHDxfJ/RWG9Kx0AEoGlLR5JCIiIiJSrDid0LmzOT51CmrWNKukli/PnZACCAqCYcPM8ZQpYFleHaqIiFx/bE1KLVy4kJiYGOLi4ti8eTMNGzakffv2HDlyJM/28+fPZ+TIkcTFxZGcnMzs2bNZuHAho0ePztWuXr16HDp0yPNau3Ztrs9HjBjBhx9+yOLFi1mzZg0///wzXXIemeuDcpJSwa5gm0ciIiIiIsXOU0/B/feb7Xk7dsAf/2i27uVlyBAICYFt2yAx0bvjFBGR646tSampU6cycOBA+vXrR926dYmPjyckJIQ5c+bk2X7dunW0bNmSnj17EhERQbt27ejRo8cFq6v8/f0JDw/3vEJDQz2fnThxgtmzZzN16lTuuecemjRpwttvv826devYsGFDkd7vlcpJSoW4QmweiYiIiIgUOzfdBMuWmXpSgYEXb1uhAvTvb46nTCn6sYmIyHXNtppSmZmZJCUlMWrUKM85p9NJmzZtWL9+fZ7XtGjRgn/9619s2rSJ5s2bs3//fpYvX07v3r1ztduzZw9VqlQhKCiIqKgoJk+eTLVq1QBISkoiKyuLNm3aeNrXqVOHatWqsX79eu644448vzsjI4OMjAzP+9TfHpWblZVF1lUUgsy59mJ9nDxzEoAgv6Cr+i7JrSCxl8KnuNtDcbeH4m6fooy9fp9yzRsxAmbMgJUrzYopERGRImJbUurYsWNkZ2cTFhaW63xYWBi7du3K85qePXty7NgxWrVqhWVZnD17lsGDB+favhcZGcncuXOpXbs2hw4dYvz48dx5551s376dUqVKkZKSQkBAAGXLlr3ge1NSUvId7+TJkxk/fvwF51euXElIyNWvYEpISMj3s6SjSQCcOHqC5cuXX/V3SW4Xi70UHcXdHoq7PRR3+xRF7NPT0wu9TxGfUr06/PnPsGgRftOnw0MP2T0iERG5RhWrp++tXr2aSZMmMXPmTCIjI9m7dy/Dhw9nwoQJxMbGAtCxY0dP+wYNGhAZGclNN93EokWL6J+zFPkKjBo1ipiYGM/71NRUqlatSrt27ShduvQV95uVlUVCQgJt27bF5cr7yXrfrPsGDkKNajW47777rvi7JLeCxF4Kn+JuD8XdHoq7fYoy9jmrpUWuaU89BYsW4Vi4kKDWre0ejYiIXKNsS0qFhobi5+d3wVPvDh8+THh4eJ7XxMbG0rt3bwYMGABA/fr1SUtLY9CgQTz77LM4nReWyCpbtiy1atVi7969AISHh5OZmcnx48dzrZa62PcCBAYGEpjHHnyXy1Uok92L9ZORbbYNlgwsqb/UFIHC+h3K5VHc7aG420Nxt09RxF6/S7kuNG0Kd92FY80abl66FPr0yb/t4cOwbx80aXLpmlUiIiLnsa3QeUBAAE2aNCHxvKd6uN1uEhMTiYqKyvOa9PT0CxJPfn5+AFj5PLL21KlT7Nu3j8qVKwPQpEkTXC5Xru/dvXs3Bw4cyPd77Xb67GlAhc5FRERExIueeQaAGh99hGPNmrzbHDpkklEtW0L58ubJfq++Ct9+C/nMz0VERHLY+vS9mJgY3nzzTd555x2Sk5MZMmQIaWlp9OvXD4BHHnkkVyH0Tp06MWvWLBYsWMB3331HQkICsbGxdOrUyZOcevLJJ1mzZg3ff/8969at48EHH8TPz48ePXoAUKZMGfr3709MTAyrVq0iKSmJfv36ERUVlW+Rc7vlPH0v2D/Y5pGIiIiIyHWjQwfcvXvjcLvx693brIg635kz0KULHDwITiekp8NHH8Hjj0Pt2tCzpxJTIiJyUbbWlOrWrRtHjx5l7NixpKSk0KhRI1asWOEpfn7gwIFcK6PGjBmDw+FgzJgxHDx4kIoVK9KpUycmTpzoafPTTz/Ro0cPfvnlFypWrEirVq3YsGEDFStW9LSZNm0aTqeTrl27kpGRQfv27Zk5c6b3bvwy5SSltFJKRERERLzG4SD7lVc4tXo1pX/80SSZVq4EPz+TbBoyBDZsgLJlYeNGk5T65BPz+vxzWLAABg6Ee+6x+05ERMRH2V7oPDo6mujo6Dw/W716da73/v7+xMXFERcXl29/CxYsuOR3BgUFMWPGDGbMmHFZY7WLklIiIiIiYosSJfjy6ae555lncHz2GUyYAOPGwT/+AXPnmhVSixZBrVqmfaNGZtvfsGHw2mvw978rKSUiIvmydfueFIxqSomIiIiIXU5VrUp2zv/Mfe45GDsW/vY38/7ll6Ft2wsveuopcLlg1Sr44gvvDVZERIoVJaWKAU9NKZdqSomIiIiI91m9epmteJZlVku53dC3LwwfnvcF1aqde2LfeaU2REREzqekVDGg7XsiIiJyKTNmzCAiIoKgoCAiIyPZtGlTvm137NhB165diYiIwOFwMH369AvajBs3DofDketVp06dIrwD8Xn/+Ac0bGiOo6IgPh4cjvzbjxxptvd9/DEkJV34eVISvPACnDhRNOMVERGfp6RUMXA6S9v3REREJH8LFy4kJiaGuLg4Nm/eTMOGDWnfvj1HjhzJs316ejo1atTg+eefJzw8PN9+69Wrx6FDhzyvtWvXFtUtSHEQHGyKmL/2GixbBoGBF29fs6Ypjg4waVLuzz74AFq2NImryEj49tuiGbOIiPg0JaWKAa2UEhERkYuZOnUqAwcOpF+/ftStW5f4+HhCQkKYM2dOnu2bNWvGlClT6N69O4EXSSz4+/sTHh7ueYWGhhbVLUhxERYGQ4dC+fIFaz9qlFlNtWQJ7Nhhzs2ZA126QEaGqTu1ezc0bw4rVhTduEVExCfZ/vQ9uTRPTSl/1ZQSERGR3DIzM0lKSmLUqFGec06nkzZt2rB+/fqr6nvPnj1UqVKFoKAgoqKimDx5MtWqVcu3fUZGBhkZGZ73qampAGRlZZGVlXVVY8m5/mr7kctz1XG/5Rb8HnwQ55IluCdMwGrYEL/RowFw9+lD9rhx+PXsiXP9eqz778c9cSLumJiLbwu8DujPuz0Ud3so7vYpytgXtE8lpYoBrZQSERGR/Bw7dozs7GzCwsJynQ8LC2PXrl1X3G9kZCRz586ldu3aHDp0iPHjx3PnnXeyfft2SpUqlec1kydPZvz48RecX7lyJSEhhTOPSUhIKJR+5PJcTdxLt2rF3UuW4Fy4EBYuBGBPly7s7NwZtm3DGRND/TfeICIhAb9Ro/hl4UIO3347/6tVixM1auAOCCikuyh+9OfdHoq7PRR3+xRF7NPT0wvUTkmpYuD0WdWUEhEREe/q2LGj57hBgwZERkZy0003sWjRIvr375/nNaNGjSImJsbzPjU1lapVq9KuXTtKly59VePJysoiISGBtm3b4nK5rqovKbjCirv7009xLl8OQPYLLxAxYgQR5zd44AGy4+NxxsRQaetWKm3dCoDlcmE1aID16KO4+/c3hdOvA/rzbg/F3R6Ku32KMvY5q6UvRUkpH+e23Jw5ewaAYJe274mIiEhuoaGh+Pn5cfjw4VznDx8+fNEi5perbNmy1KpVi7179+bbJjAwMM8aVS6Xq9Amu4XZlxTcVcf9H/8APz/o2RO/7t3xy6vN449D69bw4YewcSNs3IjjyBEcSUmQlITfv/8Ns2dD9epXPo5iRn/e7aG420Nxt09RxL6g/V0f/6uhGMt58h5opZSIiIhcKCAggCZNmpCYmOg553a7SUxMJCoqqtC+59SpU+zbt4/KlSsXWp9yHbn5Zli6FLp3v3i7Bg3g2WdN25QU2L8fXnoJQkJg1SqoXx9mzQK32zvjFhGRIqWklI/L2boHKnQuIiIieYuJieHNN9/knXfeITk5mSFDhpCWlka/fv0AeOSRR3IVQs/MzGTr1q1s3bqVzMxMDh48yNatW3OtgnryySdZs2YN33//PevWrePBBx/Ez8+PHj16eP3+5DrlcJhVUX/7G3z9NfzhD5CWBo89Bm3awMGDdo9QRESukrbv+bicIueBfoH4OfNc6CwiIiLXuW7dunH06FHGjh1LSkoKjRo1YsWKFZ7i5wcOHMB5Xi2en3/+mcaNG3vev/TSS7z00kvcddddrF69GoCffvqJHj168Msvv1CxYkVatWrFhg0bqFixolfvTQSAmjXNSqkZM2DkSHPcrBm8/z40b2736ERE5AopKeXjcpJSqiclIiIiFxMdHU10dHSen+UkmnJERERgWdZF+1uwYEFhDU2kcDidMGwYdOwIDz4I27fDXXfB229felugiIj4JG3f83E5SSnVkxIRERERwdSn+uIL+OMf4cwZ6NEDxo5VnSkRkWJISSkfl1PoXEkpEREREZHflC5ttu499ZR5P2GCWS119qytwxIRkcujpJSP82zfU5FzEREREZFz/PzgxRfN9j2XCxYvNk/qExGRYkNJKR+n7XsiIiIiIhfRty+8+aY5jouD5OSCX5uZCd9/XxSjEhGRAlBSysedPqvteyIiIiIiF/XII6YAemYmPPooZGdf+hq3G+67D2rUgP/+t+jHKCIiF1BSysdppZSIiIiIyCU4HPDGG6bW1IYNMH36pa957TVITATLgvj4Ih/iNWn/fpg0CU6ftnskIlJMKSnl4zw1pVyqKSUiIiIikq8bb4SXXzbHY8bAnj35t927F0aOPPf+vffg5MmiHd+16Mkn4dln4ZVX7B6JiBRTSkr5OK2UEhEREREpoP79oW1bOHPGHLvdF7Zxu80Wv9On4e67oVYtc/yf/3h/vMWZZcH69eb4k0/sHYuIFFtKSvm401m/1ZTyV1JKREREROSiHA5T9LxkSVMn6oUXTPLkfK++aj4rUQJmzzb1qAD+7/+8P97i7OBBSEkxx198Aenp9o5HRIolJaV8nFZKiYiIiIhchptuMskogNGjoXFjWLLErJDaswdGjTKfTZkC1atDr17m/apV8OOPBfuOrCzYssX8vF59+eW548xMWLvWvrGISLGlpJSPU00pEREREZHLNHgwPPecWTG1bRt07QqNGkG3bmar3j33wF//atpGRMBdd5kVVfPmXbrvlBTT/vbbITwcBg6ETz+Fs2eL8o58z/lJKTAxEBG5TEpK+bjTZ3/bvqeVUiIiIiIiBeN0Qmws/PCDKXpeujR8841Z3VSypNm25zzvr0K9e5uf//d/F273O9+WLdCs2blaSr/+Cm+9ZepYVa4MY8fmXcfqWpSTlLrrLvNTSSkRuQJKSvk4bd8TEREREblC5cvDhAnw/fcQFwd165qEVERE7nZ//jMEBcHOnbB5c959LV4MLVvCTz9B7dqQnAyJiWbFVWgoHDtmvmvZsqK+K/tZFnz1lTnOeYrhli0mBiIil0FJKR/n2b7nr+17IiIiIiJXpFw5GDcOduyAhx++8PMyZeBPfzLHvy94np1trn34YbP1r0MH2LAB6tQx2wDj4+HQIRgyxLSPjy/KO/ENe/fC8eMQGAj33gsNGpjzn31m67BEpPhRUsrHaaWUiIiIiIgX5DyFb/78cwXMd+6EO++E8ePN+5gYsxKqbNnc1/r7m88AVqyA77678nGkp+NYuJDyO3ZceR9FLWfrXqNG4HJBmzbmfUKCbUMSkeJJSSkfp5pSIiIiIiJe0K4dVKoER4+axNNzz5kn961fD6VKwdy58PLL4OeX9/U332z6sCx4443L//6tW+Gxx6ByZfx796ZlXFzBnwbobTlJqWbNzM/zk1IXq8klIvI7Skr5OK2UEhERERHxAn9/6NHDHD/0kKlBlZkJf/yjWTHVp8+l+xg82PycPRsyMi7d/vBhmDHDJHcaN4ZZsyA1FcvPD+fZszhnzrzy+ylKv09K3XmnWTH1ww+wf7994xKRYkdJKR/nqSnlUk0pEREREZEilbOFLzsbKlaEd9+FpUvhxhsLdn2nTlClillt9d57ebf59VeTtGrb1rSNjjZFw10u6NYNPv2U7IULAXDOng2nThXCjRWis2fPFYPPSUqVLAlRUeZYT+ETkcugpJSPO52l7XsiIiIiIl7RuLHZtvfEE2Z1VPfu4HAU/Hp/fxg40BzPmnXh53PnQuXKMGCASd643dC8OUydCgcPwoIFcO+9WH/8I6eqVMFx/Li5xpfs3GkKvpcqZZ5CmKNtW/NTSSkRuQxKSvk4bd8TEREREfEShwNiY2HaNAgNvbI+Bg40dac+/9w87S/H/Pnw6KNmS2D9+jB5MuzbBxs3wogRZmVWDqeTfZ06mePp083KLV+Rs3WvSRNwnvfXyZy6Up995lvjFRGfpqSUj/Ns3/PX9j0REREREZ93ww3wwAPm+PXXzc///MdsDbQsU3dq2zYYORJq1Mi3mx/vvhurXDmTuPrwQy8MvIB+X08qR9OmULq02Z64davXhyUixZOSUj7MsiytlBIRERERKW5yCp6/8w4sXGi2AWZnQ9++prB5AbYEZgcF4c7ZCjh1atGN9XLll5Ty94e77zbHCQneHZOIFFtKSvmwzOxMLMwjVZWUEhEREREpJtq0gZo1ITXVJKTOnjVP9nvrrdxb3i7B/dhjpgD6f/9riqHb7cwZ+Pprc/z7pBSc28KnulIiUkBKSvmwnFVSoKSUiIiIiEix4XTCX/967v2DD5pVU35+l9dPlSrmiXxg6lzZbds2k2CrWBFuuunCz3OSUmvXQnr6hZ+LiPyO7UmpGTNmEBERQVBQEJGRkWzatOmi7adPn07t2rUJDg6matWqjBgxgjNnzng+nzx5Ms2aNaNUqVJUqlSJzp07s3v37lx9tG7dGofDkes1OGeJrQ/JSUr5Ofxw+blsHo2IiIiIiBTYgAHmaX49e5qn6rmucD4/YoT5uWgR/Phj4Y3vfM8+a56kt3//xdudv3Uvry2ItWtD9eqQkWG2LYqIXIKtSamFCxcSExNDXFwcmzdvpmHDhrRv354jR47k2X7+/PmMHDmSuLg4kpOTmT17NgsXLmT06NGeNmvWrGHo0KFs2LCBhIQEsrKyaNeuHWlpabn6GjhwIIcOHfK8XnzxxSK91ytx+uxpQKukRERERESKnXLlYPNmmDcPAgKuvJ/bb4fWrc0KpcmTC214Hrt2wfPPw7ffwnl/r8pTfvWkcjgc5+ppvfqqKewuInIRtialpk6dysCBA+nXrx9169YlPj6ekJAQ5syZk2f7devW0bJlS3r27ElERATt2rWjR48euVZXrVixgr59+1KvXj0aNmzI3LlzOXDgAElJSbn6CgkJITw83PMqXbp0kd7rlVCRcxERERER4ZlnzM9Zs2DSpMLt+7nnwO02xwsXwpYt+be9VFIKoH9/CAoy/XzxReGNU0SuSbYlpTIzM0lKSqJNzr5jwOl00qZNG9avX5/nNS1atCApKcmThNq/fz/Lly/nvvvuy/d7Tpw4AUD58uVznZ83bx6hoaHcdtttjBo1inQf3POck5QKdgXbPBIREREREbFNhw5mNROYrXYvvVQ4/e7YYbYWAtxxx7n+83LypFlVBRdPSlWoAL16meNXXy2ccYrINcvfri8+duwY2dnZhIWF5TofFhbGrpx/2f1Oz549OXbsGK1atcKyLM6ePcvgwYNzbd87n9vt5oknnqBly5bcdtttufq56aabqFKlCl9//TXPPPMMu3fvZsmSJfmONyMjg4yMDM/71NRUALKyssjKyirwff9ezrV59ZF62nxHsH/wVX2H5O1isZeio7jbQ3G3h+Jun6KMvX6fImKLZ56BzEwYOxaeesrUqBo+/Or6HD/ebLHr0gVefBHq1IGPPzZP+7vzztxt1641batVg0qVLt7vsGEwezb85z/w009w441XN04RuWbZlpS6EqtXr2bSpEnMnDmTyMhI9u7dy/Dhw5kwYQKxsbEXtB86dCjbt29n7dq1uc4PGjTIc1y/fn0qV67Mvffey759+6hZs2ae3z158mTGjx9/wfmVK1cSEnL12+sSEhIuOPfVCfPY16y0LJYvX37V3yF5yyv2UvQUd3so7vZQ3O1TFLH3xdXVInKdiI2FrCyYMAGeeMIkph57LO+2335rEkPvvgvNm5un/5Uoce7zb76BxYvN8bhxULOmKc4eHw+jRpnEVE4x8+3b4ZFHzPG99156nA0bwh/+AJ9/bvr7+9+v9I5F5BpnW1IqNDQUPz8/Dh8+nOv84cOHCQ8Pz/Oa2NhYevfuzYABAwCTUEpLS2PQoEE8++yzOJ3ndiNGR0ezbNkyPv/8c268RGY+MjISgL179+ablBo1ahQxMTGe96mpqVStWpV27dpdVT2qrKwsEhISaNu2La7fPZEjPTkdvoPKoZUvukVRrszFYi9FR3G3h+JuD8XdPkUZ+5zV0iIithg/3qyYeuEFGDrUbOVr0sQURL/9djhyBN56yySEcvz4Ixw8CMuWme11YBJRAA8/DPXrm+PYWJO8+uILWL4c7r8fdu6Ee+6BY8egaVOYOrVg4xw2zIzhjTdgzBhTZ0pE5HdsS0oFBATQpEkTEhMT6dy5M2C22yUmJhIdHZ3nNenp6bkSTwB+fn4AWL892cGyLIYNG8Z7773H6tWrqV69+iXHsnXrVgAqV66cb5vAwEACAwMvOO9yuQplsptXP5nuTABCAkL0l5kiVFi/Q7k8irs9FHd7KO72KYrY63cpIrZyOMxT+JxOU2fqu+/M69//zt3O6YSOHc0rNhY2bDBb8j75xCSYliwxfcXFnbumShWTTHrxRVNbqkYNk5A6ehQaN4aVK6Fs2YKNs3Nns23vp59g0aJzK61ERM5j6/a9mJgY+vTpQ9OmTWnevDnTp08nLS2Nfv36AfDII49www03MPm3R5926tSJqVOn0rhxY8/2vdjYWDp16uRJTg0dOpT58+fzwQcfUKpUKVJSUgAoU6YMwcHB7Nu3j/nz53PfffdRoUIFvv76a0aMGMEf/vAHGjRoYE8g8qGn74mIiIiIyAUcDvMUviefNE+527wZkpLMTz8/U2i8Xz+44QbTvnVraN8ekpOhRQuIiDDne/SAunVz9/3MM/D667Btm1kZlZ4ODRpAQgKUK1fwMfr7m62Fo0fDK69A797ntgOKiPzG1qRUt27dOHr0KGPHjiUlJYVGjRqxYsUKT/HzAwcO5FoZNWbMGBwOB2PGjOHgwYNUrFiRTp06MXHiRE+bWbNmAdC6detc3/X222/Tt29fAgIC+PTTTz0JsKpVq9K1a1fGjBlT9Dd8mU6fPQ0oKSUiIiIiInkoX97UeLpUnad69WDdOpOY2rXLrF5yOk3R9Lz6fOops+UuPR1uuw0+/fTctr/LMXCg2W6YlGQKqGdlmS19n39+rubVn/98+f2KyDXD9kLn0dHR+W7XW716da73/v7+xMXFEXf+EtPfydnGl5+qVauyZs2ayx6nHbRSSkRERERECkW1aqZ4+R//CBs3mpVLtWvn3Xb4cFMgPTDQJJMqVryy7wwNNaux5s419al+b+xY6NpVK6hErmPOSzcRu+QkpYL9g20eiYiIiIiIFHuhobBqlSli/sYb+bcrWdI8ce+rr6BSpav7zhEjICDAHN96K/z1r+eeBJicDMVkwYCIFA3bV0pJ/k5nafueiIiIiIgUouBgU/y8IApjBVODBqYQu8uVe8XV+vUQHw8zZ5qaVyJyXdJKKR+m7XsiIiIiIlLsValy4RbAIUPMz/feg0OHvD8mEfEJSkr5sPSzv23fc2n7noiIiIiIXEMaNIBWreDsWXjrLbtHIyI2UVLKh2mllIiIiIiIXLNyVku9/rpJTonIdUdJKR+mmlIiIiJSUDNmzCAiIoKgoCAiIyPZtGlTvm137NhB165diYiIwOFwMH369KvuU0TksnXtarb1HTwIH35o92hExAZKSvkwrZQSERGRgli4cCExMTHExcWxefNmGjZsSPv27Tly5Eie7dPT06lRowbPP/884eHhhdKniMhlCwyEAQPM8cyZ9o5FRGyhpJQPy0lKBfurppSIiIjkb+rUqQwcOJB+/fpRt25d4uPjCQkJYc6cOXm2b9asGVOmTKF79+4EBgYWSp8iIlfkr381T/n79FP49lu7RyMiXuZv9wAkf6fPavueiIiIXFxmZiZJSUmMGjXKc87pdNKmTRvWr1/v1T4zMjLIyMjwvE9NTQUgKyuLrKysKxpLjpzrr7YfuTyKuz2uq7hXqYLffffh/OgjsmfOxD1lim1Dua7i7kMUd/sUZewL2qeSUj5M2/dERETkUo4dO0Z2djZhYWG5zoeFhbFr1y6v9jl58mTGjx9/wfmVK1cSElI485mEhIRC6Ucuj+Juj+sl7pVuv52ojz4i+623WBkVRXZQkK3juV7i7msUd/sURezT09ML1E5JKR/m2b7n0vY9ERER8X2jRo0iJibG8z41NZWqVavSrl07SpcufVV9Z2VlkZCQQNu2bXG5XFc7VCkgxd0e113cO3TAmj+fgH37uG/JErL/+U9wer/SzHUXdx+huNunKGOfs1r6UpSU8mFaKSUiIiKXEhoaip+fH4cPH851/vDhw/kWMS+qPgMDA/OsUeVyuQptsluYfUnBKe72uK7i/uab0K4dzkWLcNaqBRMm2DaU6yruPkRxt09RxL6g/anQuQ87naWaUiIiInJxAQEBNGnShMTERM85t9tNYmIiUVFRPtOniMhF3X03vPGGOf773+Gdd+wdj4h4hVZK+ais7Cyy3KYwmJJSIiIicjExMTH06dOHpk2b0rx5c6ZPn05aWhr9+vUD4JFHHuGGG25g8uTJgClkvnPnTs/xwYMH2bp1KyVLluTmm28uUJ8iIoWuXz/YuxcmTYKBA+Gmm6B1a7tHJSJFSEkpH5Xz5D2AYH/VlBIREZH8devWjaNHjzJ27FhSUlJo1KgRK1as8BQqP3DgAM7z6rP8/PPPNG7c2PP+pZde4qWXXuKuu+5i9erVBepTRKRITJgA+/bBwoXQpQusXw+1a9s9KhEpIkpK+aicrXsAQf72Pn1CREREfF90dDTR0dF5fpaTaMoRERGBZVlX1aeISJFwOuHtt+GHH2DDBmjaFDp1gq5doWNHKKQneYqIb1BNKR91fpFzh8Nh82hERERERES8JDgYPvgAGjSAU6fg3Xfhz3+GihXNzw0b7B6hiBQSJaV8lJ68JyIiIiIi161KlWDLFrN978knISIC0tPhP/+BFi0gJsa8z8+hQ/DRR6ZoepcucMstMHw4uN1euwURuTRt3/NROUkp1ZMSEREREZHrktMJd9xhXi++aJJU06fD//0fTJsGS5fCW2+ZYuiWBZs2maTVkiWmLtXvvfIKOBzmWu1GEfEJSkr5qJxC51opJSIiIiIi1z2HA26/Hf75T+jRAwYNMomnu++GP/4Rtm6Fn346197phDp1zDWNG0NWFowcCf/4B5QpA+PH23YrInKOklI+Stv3RERERERE8tCxI+zYAU8/Da+/DsuWmfMlS8L995ui6B06QKlSua8rUQKGDYPnnjOJqZiYi39PaiosXgwpKabAes6rRAmoWdMkvQIDi+YeRa4TSkr5KM/2PZe274mIiIiIiORSujTEx0P37pCQAJGR0K4dBF3kyeXR0XDiBIwZA3/7m0lM9e9/YbstW2D2bJg3D9LS8u/Pzw9q1YLbboOGDeGBB8yxtgaKFJiSUj7qdJa274mIiIiIiFxU69bmVVCjR5vE1JQpMHAgTJ0K5cpB2bL4lSnDH778EteePefa16ljCqufOWMKq6enm+t374bjxyE52bwWLzbJrtq14eGH4aGHlKASKQAlpXyUtu+JiIiIiIgUMocDXngBTp2CWbNg507PR06gHGC5XDi6doXBg+EPf8g7sWRZ8PPPsH07fPMN/Pe/sGKFSVZNmGBeLVqYrYXlyhV8fCdOwLFjZnugyHVASSkfpaSUiIiIiIhIEXA4YOZMePxxk1j63//gf/8j+9gxduzfz61xcbhuuOHSfdxwg3m1bw9PPmkSSh9+aFZNrVgB69aZFVMffwwu16XH9emn0LOnSUrNm2cKuotc45SU8lGemlL+qiklIiIiIiJS6OrUMa/fuLOy+G75cm6tVOnK+itTBv7yF/Patg1atoTERFPLKj4+/618bjdMnAhxcWYFFkDfvnDjjXDnnVc2FpFiwmn3ACRvp8+qppSIiIiIiEix1LAhvPuuSUS98QZMm5Z3u2PH4L77YOxYk5AaMAA6d4bMTPjTn8x2QJFrmJJSPkrb90RERERERIqxTp3g5ZfN8ZNPwtKl5tiyTC2ql1+Gxo3hk08gOBjmzoU33zRb9yIjzbbC++6DI0dsuwWRoqbtez5K2/dERERERESKuSeegG+/Ndv3evaErl3Nlr6DB8+1qVUL/v1vqF/fvA8JMQmsO+6A/fvhgQdg1SqTuBK5xigp5aO0fU9ERERERKSYczjglVdg3z5ISIB//tOcDwqCu+6Cjh3h0UehVKnc11WqZAqkR0XBxo3QqBHUqwdVq5rXTTdBu3amjpVIMaaklI/S9j0REREREZFrgMtlnsj39NNQsqR5Wt+dd1565VPt2vDBByb59O235nW+0FB47jkYOBD89Vd7KZ70J9dHKSklIiIiIiJyjShTBl5//fKvu/NOs8rqyy/hxx/PvTZtMucfewxee83Up+rQofDHLVLElJTyUZ6aUi7tGxYREREREbluValinsR3vqwsk+QaNw527jTbAFu2hIoV4exZ8/nZs1C3LowfD+XKeWeslmW2LIoUkJ6+56NOZ6mmlIiIiIiIiOTB5YLoaNizB/72N/P+iy/g/fdh2TLzRL/ERHj1VWjQAD77rGjHk50NAwZA2bLw979DRkbRfp9cM5SU8lHaviciIiIiIiIXVa4cvPQS7NoFM2fCrFnw1lvwzjswezbcfDP89BPce69JXp05Y647fhzmz4eHHzZJq8mTz312udxuU6x99mxITYXYWFOYffXqQrpJuZZp+56P8mzf89f2PREREREREbmIGjVgyJALzz/8sElGvfEGTJ0KK1dC5cqwapXZ3pfjm29MMmvaNOjUqeBb8NxuGDTIPFXQzw+efBLeftskye6+G/r0gSlTzLZCkTxopZSPOn1W2/dERERERETkKpQsaWpPLV1qEkPbt0NCwrl6U6NHmxVWVarA/v2mdlWHDrBjx6X7tiwYOtSskHI6Yd48eP55k5AaPNgktt55B+rVM0kwkTwoKeWjtH1PRERERERECkWnTiYhNXYsvPAC7N5tEk8TJ5oVVrt3w6hREBBgVlPddhs0bAjPPgvr15uaUTnOnIHvv4dhwyA+/lzyqVs383m5cmYb4bp1UL8+HD0KbduaVViWZcvti++yPSk1Y8YMIiIiCAoKIjIykk2bNl20/fTp06lduzbBwcFUrVqVESNGcOZ3e18v1eeZM2cYOnQoFSpUoGTJknTt2pXDhw8X+r1dDSWlREREREREpNBUqmSexPf001CrVu7PSpaESZPMk/wefNCsfPr6a3OuRQuz5a9ePShfHoKDoXp1mDHDXDtnDvzlLxd+3x13wIYN0Lu3SWrFxECvXpCWdumxbtoEc+dCZuZV37b4NluTUgsXLiQmJoa4uDg2b95Mw4YNad++PUeOHMmz/fz58xk5ciRxcXEkJycze/ZsFi5cyOjRoy+rzxEjRvDhhx+yePFi1qxZw88//0yXLl2K/H4Lym25OXPWJNqCXaopJSIiIiIiIl5QsyYsWQJHjsC//gXdu0OZMma1086d8L//mXYBAabtP/8Jffvm319IiFlF9cor4O8P775rklz79+d/zVdfwV13Qb9+0LixeaqgXLNsTUpNnTqVgQMH0q9fP+rWrUt8fDwhISHMmTMnz/br1q2jZcuW9OzZk4iICNq1a0ePHj1yrYS6VJ8nTpxg9uzZTJ06lXvuuYcmTZrw9ttvs27dOjZs2OCV+76UnIQUaKWUiIiIiIiIeFmFCmZV07vvmoTUf/8Ln35qtvz98ovZwrd3r1kFdSkOh9nq99lnEBZmVmC1bGmSXL936BB07mz6dzhMm1atzBbD48cL7/7O345YUBkZZgXX0aOFNw6xLymVmZlJUlISbdq0OTcYp5M2bdqwfv36PK9p0aIFSUlJniTU/v37Wb58Offdd1+B+0xKSiIrKytXmzp16lCtWrV8v9fbcrbugZ6+JyIiIiIiIjZyuUxi6N57TXH08uUL/nS+8915JyQlQYMGkJICrVubOlc5zpwxWwcPHoRbbzWrqR591HwWH2/OLV589XWpPvsMQkOhY0e4WBmfzEz4/HOYMMHce9myEBkJzZrBiRNXNwbx8Lfri48dO0Z2djZhYWG5zoeFhbFr1648r+nZsyfHjh2jVatWWJbF2bNnGTx4sGf7XkH6TElJISAggLJly17QJiUlJd/xZmRkkJGR4XmfmpoKQFZWFllZWQW76TzkXHt+HyfSzR/wQL9A3Nlu3NnuK+5f8pdX7KXoKe72UNztobjbpyhjr9+niIjIFbrhBpMUatsWtmwxiakVK8Cy8Bs6FDZuNIXSly6FiAjzZL/eveGvf4Vvv4WHHzbJpNdegxo1Lv/79++Hhx4yq65WrDDF3OfNM0mnHNnZZutibCz8+GPu6x0O+OEH+Nvf4K23riIQksO2pNSVWL16NZMmTWLmzJlERkayd+9ehg8fzoQJE4iNjS3S7548eTLjx4+/4PzKlSsJCbn6LXYJCQme44NnDgLgjz/Lly+/6r7l4s6PvXiP4m4Pxd0eirt9iiL26enpl24kIiIieatQARIToV07+Oor/Nu1o35UFM7ly8HPDxYtgptvPte+dWvYtg2efx4mT4aPPzZF18eONcmhgICCfe/Jk/CnP8Gvv8Ltt5vteDt2mARZbKzpb+VKeOYZ+OYbc01oKNxzjxlD69Zm617r1iZZ1rWrSZDJVbEtKRUaGoqfn98FT707fPgw4eHheV4TGxtL7969GTBgAAD169cnLS2NQYMG8eyzzxaoz/DwcDIzMzl+/Hiu1VIX+16AUaNGERMT43mfmppK1apVadeuHaVLl76sez9fVlYWCQkJtG3bFpfLBcCWlC2wC8oEl/FsTZTCl1fspegp7vZQ3O2huNunKGOfs1paRERErlC5cpCQAB064Ni4kRo5izGmToXzSu14BAXBuHHQowc89phZbTV6NPzf/5li602bXvz73G7o08dsFwwPNyuxypWD4cPNiqfnnoM33zQ1rcBs1Rs9GqKjzdMGc9x6q7lm+nQYMMD0V65cIQTk+mVbUiogIIAmTZqQmJhI586dAXC73SQmJhIdHZ3nNenp6Tiductg+fn5AWBZVoH6bNKkCS6Xi8TERLp27QrA7t27OXDgAFFRUfmONzAwkMDAwAvOu1yuQpnsnt9PlmW2BYQEhOgvMV5QWL9DuTyKuz0Ud3so7vYpitjrdykiIlIIypaFlStxd+yIc9063I8+inPYsItfU7u2Kbg+bx7ExEBysqlVNXs29OyZ/3UTJsB775lVVUuWmG2EYBJRd99ttgceOgSBgaYo+6hRpnZWXiZOhI8+gj174IknzNMF5YrZ+vS9mJgY3nzzTd555x2Sk5MZMmQIaWlp9OvXD4BHHnmEUaNGedp36tSJWbNmsWDBAr777jsSEhKIjY2lU6dOnuTUpfosU6YM/fv3JyYmhlWrVpGUlES/fv2Iiorijjvu8H4Q8pBT6FxFzkVEREREROSaVbo02StXsmbKFLJnzSpYAXWHA/7yF9i1Czp1MgXSe/WCkSMvfKqeZZntgOPGmffx8fD7xSg9e5r6Vi++CLt3w5Qp+SekAEJCTCLK6TSrtJYuvaxbltxsrSnVrVs3jh49ytixY0lJSaFRo0asWLHCU6j8wIEDuVZGjRkzBofDwZgxYzh48CAVK1akU6dOTJw4scB9AkybNg2n00nXrl3JyMigffv2zJw503s3fgmnz54GIMR19bWqRERERERERHxWQADHb7nl8p/oV748vP++qQc1aRK88ILZTjdvnlnFtGSJee3ebdo//jj8tljlAjffDE89VfDvjooy9aymTIFBg6BlS1MrSy6b7YXOo6Oj892ut3r16lzv/f39iYuLIy4u7or7BAgKCmLGjBnMmDHjssfrDTkrpZSUEhEREREREcmH02m20912Gzz6qNlWV6kSZGaeaxMQYJ7g9/LLhfvdzz0Hy5aZLYTR0fDuu4Xb/3XC1u17kjclpUREREREREQKqEcPWLsWbrzRJKRKlICHHoIFC8wT8956C/wLeU1OUJDZxufnZ75nyZLC7f86oaSUDzqdZbbvBbtUU0pERERERETkkpo0gW3bIDHRJKIWLYJu3aB06aL7zmbN4OmnzfHgweZ75bIoKeWDtFJKRERERERE5DKVLw/33APBXlzgERcH9eqZhNRFyghJ3pSU8kGepJS/klIiIiIiIiIiPisw8Nw2vkWL4N//tntExYqSUj4oJyml7XsiIiIiIiIiPq5JExg50hwPGQJHjtg7nmJESSkfdPqsqSml7XsiIiIiIiIixUBsLNSvD8eOwWOPQVaW3SMqFpSU8kGqKSUiIiIiIiJSjAQGwty5Zhvff/5j6ls98AC8+irs3g2WZfcIfZKSUj5ISSkRERG5XDNmzCAiIoKgoCAiIyPZtGnTRdsvXryYOnXqEBQURP369Vm+fHmuz/v27YvD4cj16tChQ1HegoiISPF2++0QHw8VKsCpU/Dhh/D441CnjimGPm8enD1r9yh9ipJSPihn+16wv2pKiYiIyKUtXLiQmJgY4uLi2Lx5Mw0bNqR9+/Ycyaemxbp16+jRowf9+/dny5YtdO7cmc6dO7N9+/Zc7Tp06MChQ4c8r3fffdcbtyMiIlJ8DRhgakolJcHzz5unAQYEQHIy/OUvULcu/POfl05OHTwIr70G48bBBx/Azz97Zfje5m/3AORCWiklIiIil2Pq1KkMHDiQfv36ARAfH89HH33EnDlzGJlTePU8//jHP+jQoQNPPfUUABMmTCAhIYHXXnuN+Ph4T7vAwEDCw8O9cxMiIiLXCqfTrJq6/XZ45hlITTUJppdfhj17oE8feO456NQJataEGjXMy+WCpUvNE/zWrbuw3ypVoFkz6NEDHn4YHA7v31sh00opH6SklIiIiBRUZmYmSUlJtGnTxnPO6XTSpk0b1q9fn+c169evz9UeoH379he0X716NZUqVaJ27doMGTKEX375pfBvQERE5FpXujSMHg3ff29WT4WGwr59MH06DBsG998Pt94KN98MMTHnElItWkDfvqaAutNpVkt98AF07w6dO0NKin33VEi0UsoHKSklIiIiBXXs2DGys7MJCwvLdT4sLIxdu3bleU1KSkqe7VPOm9x26NCBLl26UL16dfbt28fo0aPp2LEj69evx8/PL89+MzIyyMjI8LxPTU0FICsri6yrfApRzvVX249cHsXdHoq7PRR3e1xXcQ8KMkmnv/4Vx+LFOJKTcezfj+O772D/fkhLw2rVCqtLF9ydO8MNN5y7Ni0Nx5YtOFaswDltGo6lS7H++1+yp03D6tHDrJr66Secy5bhWLoUx9dfQ3a2KbDudoPbjdWkCdmvvAK1awNFG/uC9qmklA86nfVbTSmXakqJiIiIPbp37+45rl+/Pg0aNKBmzZqsXr2ae++9N89rJk+ezPjx4y84v3LlSkJCCud/tiUkJBRKP3J5FHd7KO72UNztcd3FvVIl87rrLvPesnCcPYvlcpn327aZ1++1aEHpKlVo/MorlN2/H/++fTkybRqutDTK7d170a90rFqFu0kTdvbpw3cdO5rVVxRN7NPT0wvUTkkpH6SVUiIiIlJQoaGh+Pn5cfjw4VznDx8+nG89qPDw8MtqD1CjRg1CQ0PZu3dvvkmpUaNGERMT43mfmppK1apVadeuHaVLly7oLeUpKyuLhIQE2rZtiytnwi5FTnG3h+JuD8XdHor7FRo4kOwXX8Q5aRKVfkteWQ4H1h13YD3wAO677zYrs5xOs4oqPR2/0aPxT0ykwZtvctv+/WTMnMnK5OQiiX3OaulLUVLKBykpJSIiIgUVEBBAkyZNSExMpHPnzgC43W4SExOJjo7O85qoqCgSExN54oknPOcSEhKIiorK93t++uknfvnlFypXrpxvm8DAQAIDAy8473K5Cm2yW5h9ScEp7vZQ3O2huNtDcb9MLpd5Ml+XLvCvf0GtWjg6dcLx2/b8PDfar1wJM2fC00/jTEwkqHlzbnz0UVwdOxZ67Avanwqd+6DTZ3/bvuev7XsiIiJyaTExMbz55pu88847JCcnM2TIENLS0jxP43vkkUcYNWqUp/3w4cNZsWIFL7/8Mrt27WLcuHF89dVXniTWqVOneOqpp9iwYQPff/89iYmJ/OlPf+Lmm2+mffv2ttyjiIiI5KFBA3jxRRgwAH5XL/ICTidER8PWrRAZiePECWq+/z6cPeuNkeZJK6V8UPz98aRlpRFW8hJ/oERERESAbt26cfToUcaOHUtKSgqNGjVixYoVnmLmBw4cwOk89/8iW7Rowfz58xkzZgyjR4/mlltu4f333+e2224DwM/Pj6+//pp33nmH48ePU6VKFdq1a8eECRPyXAklIiIixUitWrB2LdmTJrG5bFnutHGFmpJSPqhXg152D0FERESKmejo6Hy3661evfqCcw899BAPPfRQnu2Dg4P55JNPCnN4IiIi4kv8/XGPGsXJ5cttHYa274mIiIiIiIiIiNcpKSUiIiIiIiIiIl6npJSIiIiIiIiIiHidklIiIiIiIiIiIuJ1SkqJiIiIiIiIiIjXKSklIiIiIiIiIiJep6SUiIiIiIiIiIh4nZJSIiIiIiIiIiLidUpKiYiIiIiIiIiI1ykpJSIiIiIiIiIiXqeklIiIiIiIiIiIeJ2SUiIiIiIiIiIi4nVKSomIiIiIiIiIiNcpKSUiIiIiIiIiIl6npJSIiIiIiIiIiHidv90DKK4sywIgNTX1qvrJysoiPT2d1NRUXC5XYQxNCkixt4fibg/F3R6Ku32KMvY5/+3PmQtI/gprvgT658kuirs9FHd7KO72UNzt4wvzJSWlrtDJkycBqFq1qs0jERERETucPHmSMmXK2D0Mn6b5koiIyPXtUvMlh6X/zXdF3G43P//8M6VKlcLhcFxxP6mpqVStWpUff/yR0qVLF+II5VIUe3so7vZQ3O2huNunKGNvWRYnT56kSpUqOJ2qhHAxhTVfAv3zZBfF3R6Kuz0Ud3so7vbxhfmSVkpdIafTyY033lho/ZUuXVr/ANpEsbeH4m4Pxd0eirt9iir2WiFVMIU9XwL982QXxd0eirs9FHd7KO72sXO+pP+9JyIiIiIiIiIiXqeklIiIiIiIiIiIeJ2SUjYLDAwkLi6OwMBAu4dy3VHs7aG420Nxt4fibh/F/tqj36k9FHd7KO72UNztobjbxxdir0LnIiIiIiIiIiLidVopJSIiIiIiIiIiXqeklIiIiIiIiIiIeJ2SUiIiIiIiIiIi4nVKStlsxowZREREEBQURGRkJJs2bbJ7SNeUyZMn06xZM0qVKkWlSpXo3Lkzu3fvztXmzJkzDB06lAoVKlCyZEm6du3K4cOHbRrxten555/H4XDwxBNPeM4p7kXj4MGD/OUvf6FChQoEBwdTv359vvrqK8/nlmUxduxYKleuTHBwMG3atGHPnj02jvjakJ2dTWxsLNWrVyc4OJiaNWsyYcIEzi/bqNhfvc8//5xOnTpRpUoVHA4H77//fq7PCxLjX3/9lV69elG6dGnKli1L//79OXXqlBfvQq6E5ktFS/Ml36D5kvdovmQPzZe8o7jNl5SUstHChQuJiYkhLi6OzZs307BhQ9q3b8+RI0fsHto1Y82aNQwdOpQNGzaQkJBAVlYW7dq1Iy0tzdNmxIgRfPjhhyxevJg1a9bw888/06VLFxtHfW358ssvef3112nQoEGu84p74fvf//5Hy5YtcblcfPzxx+zcuZOXX36ZcuXKedq8+OKLvPLKK8THx7Nx40ZKlChB+/btOXPmjI0jL/5eeOEFZs2axWuvvUZycjIvvPACL774Iq+++qqnjWJ/9dLS0mjYsCEzZszI8/OCxLhXr17s2LGDhIQEli1bxueff86gQYO8dQtyBTRfKnqaL9lP8yXv0XzJPpoveUexmy9ZYpvmzZtbQ4cO9bzPzs62qlSpYk2ePNnGUV3bjhw5YgHWmjVrLMuyrOPHj1sul8tavHixp01ycrIFWOvXr7drmNeMkydPWrfccouVkJBg3XXXXdbw4cMty1Lci8ozzzxjtWrVKt/P3W63FR4ebk2ZMsVz7vjx41ZgYKD17rvvemOI16z777/fevTRR3Od69Kli9WrVy/LshT7ogBY7733nud9QWK8c+dOC7C+/PJLT5uPP/7Ycjgc1sGDB702drk8mi95n+ZL3qX5kndpvmQfzZe8rzjMl7RSyiaZmZkkJSXRpk0bzzmn00mbNm1Yv369jSO7tp04cQKA8uXLA5CUlERWVlau30OdOnWoVq2afg+FYOjQodx///254guKe1FZunQpTZs25aGHHqJSpUo0btyYN9980/P5d999R0pKSq64lylThsjISMX9KrVo0YLExES+/fZbALZt28batWvp2LEjoNh7Q0FivH79esqWLUvTpk09bdq0aYPT6WTjxo1eH7NcmuZL9tB8ybs0X/IuzZfso/mS/XxxvuRf6D1KgRw7dozs7GzCwsJynQ8LC2PXrl02jera5na7eeKJJ2jZsiW33XYbACkpKQQEBFC2bNlcbcPCwkhJSbFhlNeOBQsWsHnzZr788ssLPlPci8b+/fuZNWsWMTExjB49mi+//JLHH3+cgIAA+vTp44ltXv/eUdyvzsiRI0lNTaVOnTr4+fmRnZ3NxIkT6dWrF4Bi7wUFiXFKSgqVKlXK9bm/vz/ly5fX78FHab7kfZoveZfmS96n+ZJ9NF+yny/Ol5SUkuvG0KFD2b59O2vXrrV7KNe8H3/8keHDh5OQkEBQUJDdw7luuN1umjZtyqRJkwBo3Lgx27dvJz4+nj59+tg8umvbokWLmDdvHvPnz6devXps3bqVJ554gipVqij2IlKsaL7kPZov2UPzJftoviR50fY9m4SGhuLn53fB0zMOHz5MeHi4TaO6dkVHR7Ns2TJWrVrFjTfe6DkfHh5OZmYmx48fz9Vev4erk5SUxJEjR7j99tvx9/fH39+fNWvW8Morr+Dv709YWJjiXgQqV65M3bp1c5279dZbOXDgAIAntvr3TuF76qmnGDlyJN27d6d+/fr07t2bESNGMHnyZECx94aCxDg8PPyC4thnz57l119/1e/BR2m+5F2aL3mX5kv20HzJPpov2c8X50tKStkkICCAJk2akJiY6DnndrtJTEwkKirKxpFdWyzLIjo6mvfee4/PPvuM6tWr5/q8SZMmuFyuXL+H3bt3c+DAAf0ersK9997LN998w9atWz2vpk2b0qtXL8+x4l74WrZsecEjvL/99ltuuukmAKpXr054eHiuuKemprJx40bF/Sqlp6fjdOb+T6qfnx9utxtQ7L2hIDGOiori+PHjJCUledp89tlnuN1uIiMjvT5muTTNl7xD8yV7aL5kD82X7KP5kv18cr5U6KXTpcAWLFhgBQYGWnPnzrV27txpDRo0yCpbtqyVkpJi99CuGUOGDLHKlCljrV692jp06JDnlZ6e7mkzePBgq1q1atZnn31mffXVV1ZUVJQVFRVl46ivTec/TcayFPeisGnTJsvf39+aOHGitWfPHmvevHlWSEiI9a9//cvT5vnnn7fKli1rffDBB9bXX39t/elPf7KqV69unT592saRF399+vSxbrjhBmvZsmXWd999Zy1ZssQKDQ21nn76aU8bxf7qnTx50tqyZYu1ZcsWC7CmTp1qbdmyxfrhhx8syypYjDt06GA1btzY2rhxo7V27VrrlltusXr06GHXLUkBaL5U9DRf8h2aLxU9zZfso/mSdxS3+ZKSUjZ79dVXrWrVqlkBAQFW8+bNrQ0bNtg9pGsKkOfr7bff9rQ5ffq09dhjj1nlypWzQkJCrAcffNA6dOiQfYO+Rv1+kqW4F40PP/zQuu2226zAwECrTp061htvvJHrc7fbbcXGxlphYWFWYGCgde+991q7d++2abTXjtTUVGv48OFWtWrVrKCgIKtGjRrWs88+a2VkZHjaKPZXb9WqVXn+O71Pnz6WZRUsxr/88ovVo0cPq2TJklbp0qWtfv36WSdPnrThbuRyaL5UtDRf8h2aL3mH5kv20HzJO4rbfMlhWZZV+OuvRERERERERERE8qeaUiIiIiIiIiIi4nVKSomIiIiIiIiIiNcpKSUiIiIiIiIiIl6npJSIiIiIiIiIiHidklIiIiIiIiIiIuJ1SkqJiIiIiIiIiIjXKSklIiIiIiIiIiJep6SUiIiIiIiIiIh4nZJSIiJe4nA4eP/99+0ehoiIiIhP05xJ5PqhpJSIXBf69u2Lw+G44NWhQwe7hyYiIiLiMzRnEhFv8rd7ACIi3tKhQwfefvvtXOcCAwNtGo2IiIiIb9KcSUS8RSulROS6ERgYSHh4eK5XuXLlALNMfNasWXTs2JHg4GBq1KjBv//971zXf/PNN9xzzz0EBwdToUIFBg0axKlTp3K1mTNnDvXq1SMwMJDKlSsTHR2d6/Njx47x4IMPEhISwi233MLSpUuL9qZFRERELpPmTCLiLUpKiYj8JjY2lq5du7Jt2zZ69epF9+7dSU5OBiAtLY327dtTrlw5vvzySxYvXsynn36aawI1a9Yshg4dyqBBg/jmm29YunQpN998c67vGD9+PA8//DBff/019913H7169eLXX3/16n2KiIiIXA3NmUSk0FgiIteBPn36WH5+flaJEiVyvSZOnGhZlmUB1uDBg3NdExkZaQ0ZMsSyLMt64403rHLlylmnTp3yfP7RRx9ZTqfTSklJsSzLsqpUqWI9++yz+Y4BsMaMGeN5f+rUKQuwPv7440K7TxEREZGroTmTiHiTakqJyHXj7rvvZtasWbnOlS9f3nMcFRWV67OoqCi2bt0KQHJyMg0bNqREiRKez1u2bInb7Wb37t04HA5+/vln7r333ouOoUGDBp7jEiVKULp0aY4cOXKltyQiIiJS6DRnEhFvUVJKRK4bJUqUuGBpeGEJDg4uUDuXy5XrvcPhwO12F8WQRERERK6I5kwi4i2qKSUi8psNGzZc8P7WW28F4NZbb2Xbtm2kpaV5Pv/iiy9wOp3Url2bUqVKERERQWJiolfHLCIiIuJtmjOJSGHRSikRuW5kZGSQkpKS65y/vz+hoaEALF68mKZNm9KqVSvmzZvHpk2bmD17NgC9evUiLi6OPn36MG7cOI4ePcqwYcPo3bs3YWFhAIwbN47BgwdTqVIlOnbsyMmTJ/niiy8YNmyYd29URERE5CpoziQi3qKklIhcN1asWEHlypVznatduza7du0CzFNeFixYwGOPPUblypV59913qVu3LgAhISF88sknDB8+nGbNmhESEkLXrl2ZOnWqp68+ffpw5swZpk2bxpNPPkloaCh//vOfvXeDIiIiIoVAcyYR8RaHZVmW3YMQEbGbw+Hgvffeo3PnznYPRURERMRnac4kIoVJNaVERERERERERMTrlJQSERERERERERGv0/Y9ERERERERERHxOq2UEhERERERERERr1NSSkREREREREREvE5JKRERERERERER8TolpURERERERERExOuUlBIREREREREREa9TUkpERERERERERLxOSSkREREREREREfE6JaVERERERERERMTrlJQSERERERERERGv+38XzWFOC9IvZQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Trích xuất dữ liệu từ lịch sử huấn luyện\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "# Vẽ biểu đồ Accuracy và Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Accuracy', color='green')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Loss', color='red')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Lưu hình ảnh vào file PNG\n",
        "plt.savefig('begin_2750.png', dpi=300)\n",
        "\n",
        "# Hiển thị biểu đồ\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T21:24:37.609115Z",
          "iopub.status.busy": "2025-06-01T21:24:37.608780Z",
          "iopub.status.idle": "2025-06-01T21:25:05.312448Z",
          "shell.execute_reply": "2025-06-01T21:25:05.311637Z",
          "shell.execute_reply.started": "2025-06-01T21:24:37.609089Z"
        },
        "id": "v2a4RR5VxQBJ",
        "outputId": "d99218c8-5316-4025-f517-3f4f668108be",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Đánh giá không hậu xử lý...\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.9266 - jaccard_coefficient: 0.7197 - loss: 0.1668 \n",
            "Không hậu xử lý - Dice Loss: 0.1974, Accuracy: 91.89%, Jaccard: 67.69%\n",
            "\n",
            "🔧 Đánh giá sau Morphology...\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 548ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 272/272 [00:00<00:00, 1557.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sau Morphology - Dice Loss: 0.1816, Accuracy: 91.89%, Jaccard: 69.26%\n"
          ]
        }
      ],
      "source": [
        "# Hàm hậu xử lý bằng Morphological Operations\n",
        "def apply_morphology(mask, kernel_size=3, iterations=1):\n",
        "    \"\"\"\n",
        "    Morphological post-processing: closing -> opening để loại bỏ nhiễu và lỗ hổng.\n",
        "    - kernel_size: Kích thước kernel (7).\n",
        "    - iterations: Số lần áp dụng phép toán (1 or 2).\n",
        "    \"\"\"\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
        "    mask = (mask > 0.5).astype(np.uint8)  # Ngưỡng hóa trước\n",
        "\n",
        "    # Closing để lấp lỗ hổng nhỏ\n",
        "    closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=iterations)\n",
        "\n",
        "    # Opening để loại bỏ nhiễu\n",
        "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=iterations)\n",
        "\n",
        "    return opened.astype(np.float32)  # Chuyển về float để tính toán metrics\n",
        "\n",
        "\n",
        "print(\"🔍 Đánh giá không hậu xử lý...\")\n",
        "results = segunet.evaluate(test_images_gray_clahe, test_masks, verbose=1)\n",
        "loss, accuracy, jaccard = results\n",
        "print(f\"Không hậu xử lý - Dice Loss: {loss:.4f}, Accuracy: {accuracy*100:.2f}%, Jaccard: {jaccard*100:.2f}%\")\n",
        "\n",
        "# Dự đoán và hậu xử lý chỉ với Morphological Operations\n",
        "print(\"\\n🔧 Đánh giá sau Morphology...\")\n",
        "predictions1 = segunet.predict(test_images_gray_clahe)\n",
        "refined_predictions1 = []\n",
        "\n",
        "for i in tqdm(range(len(test_images_gray_clahe))):\n",
        "    pred = predictions1[i].squeeze()\n",
        "\n",
        "    # Áp dụng Morphological Operations\n",
        "    morph_pred = apply_morphology(pred, kernel_size=7, iterations=2)\n",
        "\n",
        "    refined_predictions1.append(morph_pred)\n",
        "\n",
        "    # Lưu ảnh mẫu để so sánh\n",
        "    # if i < 3:\n",
        "    #     cv2.imwrite(f'before_morph_{i}.png', (pred > 0.5).astype(np.uint8) * 255)\n",
        "    #     cv2.imwrite(f'after_morph_{i}.png', morph_pred * 255)\n",
        "\n",
        "# Chuyển sang numpy array và thêm chiều channel nếu cần\n",
        "refined_predictions1 = np.expand_dims(np.array(refined_predictions1), axis=-1)\n",
        "\n",
        "# Tính toán metrics\n",
        "accuracy_after = np_accuracy(test_masks, refined_predictions1)\n",
        "jaccard_after = np_jaccard_coefficient(test_masks, refined_predictions1)\n",
        "loss_after = np_dice_loss(test_masks, refined_predictions1)\n",
        "\n",
        "print(f\"Sau Morphology - Dice Loss: {loss_after:.4f}, Accuracy: {accuracy_after*100:.2f}%, Jaccard: {jaccard_after*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7240504,
          "sourceId": 11545735,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7437544,
          "sourceId": 11838052,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7462356,
          "sourceId": 11874149,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
